<!DOCTYPE html><html><head><meta charSet="utf-8" class="next-head"/><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" class="next-head"/><meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" class="next-head"/><meta name="google-site-verification" content="NXbTi7gyLQESV4NIskeE9Ka0Am8KjAtzg5gm8g38HbU" class="next-head"/><meta name="keywords" content="Python EDA tutorial" class="next-head"/><meta name="description" content="Learn the basics of Exploratory Data Analysis (EDA) in Python with Pandas, Matplotlib and NumPy, such as sampling, feature engineering, correlation, etc." class="next-head"/><title class="next-head">Python Exploratory Data Analysis Tutorial (article) - DataCamp</title><link rel="canonical" href="https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" class="next-head"/><link rel="author" href="https://plus.google.com/u/0/+Datacamp/" class="next-head"/><link rel="shortcut icon" type="image/x-icon" href="https://cdn.datacamp.com/main-app/assets/favicon-335cd0394b32102a39221d79e5fd7e51078e6d32a0c8aea59676a6869f84e9d8.ico" class="next-head"/><link rel="chrome-webstore-item" href="https://chrome.google.com/webstore/detail/lbbhbkehmgbndgfdbncbmikooblghdbi" class="next-head"/><meta property="og:title" content="Python Exploratory Data Analysis Tutorial" class="next-head"/><meta property="og:image" content="https://s3.amazonaws.com/datacamp-community-prod/social-share-tutorials.jpg" class="next-head"/><meta property="og:url" content="https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" class="next-head"/><meta property="og:type" content="article" class="next-head"/><meta property="og:published_time" content="2017-03-15T18:59:41.000Z" class="next-head"/><meta property="og:author" content="Karlijn Willems" class="next-head"/><meta property="og:description" content="Learn the basics of Exploratory Data Analysis (EDA) in Python with Pandas, Matplotlib and NumPy, such as sampling, feature engineering, correlation, etc." class="next-head"/><meta property="og:site_name" content="DataCamp Community" class="next-head"/><meta name="twitter:title" content="Python Exploratory Data Analysis Tutorial" class="next-head"/><meta name="twitter:description" content="Learn the basics of Exploratory Data Analysis (EDA) in Python with Pandas, Matplotlib and NumPy, such as sampling, feature engineering, correlation, etc." class="next-head"/><meta name="twitter:card" content="summary" class="next-head"/><meta name="twitter:site" content="@DataCamp" class="next-head"/><meta name="twitter:creator" content="@DataCamp" class="next-head"/><meta name="twitter:domain" content="www.datacamp.com" class="next-head"/><meta name="twitter:image" content="https://s3.amazonaws.com/datacamp-community-prod/social-share-tutorials.jpg" class="next-head"/><meta name="twitter:image:width" content="1200" class="next-head"/><meta name="twitter:image:height" content="628" class="next-head"/><meta name="twitter:image:alt" content="Python Exploratory Data Analysis Tutorial" class="next-head"/><meta name="article:publisher" content="https://www.facebook.com/DataCamp-726282547396228" class="next-head"/><meta name="fb:app_id" content="726282547396228" class="next-head"/><script class="next-head">
      (function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
      new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
      j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
      'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
      })(window,document,'script','dataLayer','GTM-TGGWB2P');
    </script><link rel="preload" href="/community/_next/f80eab32-3c58-4b52-a08c-d754687b7a03/page/community/tutorial.js" as="script"/><link rel="preload" href="/community/_next/f80eab32-3c58-4b52-a08c-d754687b7a03/page/_error.js" as="script"/><link rel="preload" href="/community/_next/b782294ddb8d954b4c94ee4c23476b23/app.js" as="script"/><style id="__jsx-396080995">.Logo.jsx-396080995{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.Logo__image.jsx-396080995{display:block;width:122px;height:28px;margin-left:8px;}
.Logo__image.jsx-396080995 svg{fill:#FFFFFF;}
@media (min-width:800px){.Logo.jsx-396080995{height:59px;}.Logo__image.jsx-396080995{margin:17px auto 0;}}</style><style id="__jsx-499055511">.SidebarMenu.jsx-499055511{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:fixed;z-index:300;width:100vw;height:50px;background-image: linear-gradient(207deg, #2388B0, #33AACC);}
.Layout--banner .SidebarMenu.jsx-499055511{top:55px;}
.icon.jsx-499055511{text-align:right;}
.icon.jsx-499055511 svg{margin-right:9px;width:20px;height:20px;fill:#FFFFFF;}
@media (min-width:800px){.SidebarMenu.jsx-499055511{z-index:200;width:220px;top:0;left:0;background-image:none;}.Layout--banner .SidebarMenu.jsx-499055511{top:80px;}}</style><style id="__jsx-2769082546">.Menu.jsx-2769082546{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin-top:50px;}
.Layout--banner .Menu.jsx-2769082546{margin-top:105px;}
.Layout--openMenu .Menu.jsx-2769082546{min-height:calc(100vh - 50px - 134px);}
.Layout--openMenu.Layout--banner .Menu.jsx-2769082546{min-height:calc(100vh - 105px - 134px);}
.section.jsx-2769082546{margin-bottom:20px;}
.section.jsx-2769082546 h5.jsx-2769082546{margin:0;padding-left:17px;font-size:13px;-webkit-letter-spacing:3.3px;-moz-letter-spacing:3.3px;-ms-letter-spacing:3.3px;letter-spacing:3.3px;line-height:36px;text-align:left;text-transform:uppercase;background-color:#195B73;color:#7ECCE2;}
.item.jsx-2769082546{margin-bottom:1px;padding-left:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-content:center;-ms-flex-line-pack:center;align-content:center;font-size:15px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:40px;text-decoration:none;color:#FFFFFF;}
.statusIcon.jsx-2769082546{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;padding:10px;}
.active.jsx-2769082546{background-color:#55AECB;}
a.jsx-2769082546:hover{background-color:#55AECB;}
.image.jsx-2769082546{margin-top:2px;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;width:30px;height:30px;text-align:center;}
.image.jsx-2769082546 svg{fill:#195B73;}
.active.jsx-2769082546 svg,a.jsx-2769082546:hover svg{fill:#FFFFFF;}
.text.jsx-2769082546{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.subMenu.jsx-2769082546{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}
@media (min-width:800px){.Menu.jsx-2769082546{position:fixed;width:220px;margin-top:50px;}.Layout--banner .Menu.jsx-2769082546{margin-top:130px;}.section.jsx-2769082546 h5.jsx-2769082546{padding-left:0;text-align:center;}}</style><style id="__jsx-1844558338">.Button.jsx-1844558338{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;height:33px;margin:auto 5px;padding:0 15px;font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;white-space:nowrap;color:#3A3A3A;border:1px solid transparent;border-radius:4px;background-color:transparent;cursor:pointer;outline:none;}
.Button.jsx-1844558338::before,.Button.jsx-1844558338::after{content:'';-webkit-flex:1 0 auto;-ms-flex:1 0 auto;flex:1 0 auto;}
.icon.jsx-1844558338{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-height:20px;}
.icon.jsx-1844558338 svg{-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;height:20px;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;fill:#33AACC;}
.greyIcon.jsx-1844558338 .icon.jsx-1844558338 svg{min-width:16px;min-height:16px;fill:#3A3A3A;}
.same.jsx-1844558338 .icon.jsx-1844558338{min-width:13px;height:13px;margin-right:5px;}
.same.jsx-1844558338 .icon.jsx-1844558338 svg{height:13px;}
.Button.jsx-1844558338:disabled,.Button.jsx-1844558338:hover.jsx-1844558338:disabled{color:#D1D3D8;background-color:#E6EAEB;}
.primary.jsx-1844558338{background-color:#FFC844;}
.primary.jsx-1844558338:hover{background-color:#FBE28D;}
.secondary.jsx-1844558338{color:#FFFFFF;background-color:#33AACC;}
.secondary.jsx-1844558338:hover{background-color:#7ECCE2;}
.red.jsx-1844558338{color:#FFFFFF;background-color:#FE5C5C;}
.green.jsx-1844558338{height:35px;color:#FFFFFF;background-color:#FFFFFF;}
.green.jsx-1844558338 .icon.jsx-1844558338 svg{fill:#36D57D;width:35px;height:35px;}
.grey.jsx-1844558338{color:#3D4251;background-color:#D1D3D8;}
.grey.jsx-1844558338:hover{color:#3D4251;background-color:#E6EAEB;}
.big.jsx-1844558338{font-size:15px;height:42px;}
.extra.jsx-1844558338{font-size:17px;height:45px;}
.border.jsx-1844558338{border:1px solid #E3E7E8;}
.border.jsx-1844558338:hover{border:1px solid #33AACC;}
.seeAll.jsx-1844558338{border:1px solid #33AACC;}
.seeAll.jsx-1844558338:hover{border:1px solid #FFC844;}
.iconButton.jsx-1844558338:hover{color:#33AACC;}
.minWidth.jsx-1844558338{min-width:85px;}
.noPadding.jsx-1844558338{padding:0;}
@media (min-width:800px){.icon.jsx-1844558338{min-width:13px;height:13px;margin-right:5px;}.icon.jsx-1844558338 svg{height:13px;}.big.jsx-1844558338 .icon.jsx-1844558338{min-width:15px;height:15px;}.big.jsx-1844558338 svg{height:15px;}.extra.jsx-1844558338 .icon.jsx-1844558338,.extraIcon.jsx-1844558338{min-width:17px;height:17px;}.extra.jsx-1844558338 svg,.extraIcon.jsx-1844558338 svg{height:17px;}.green.jsx-1844558338{padding:0 15px;color:#FFFFFF;background-color:#36D57D;}.green.jsx-1844558338 .icon.jsx-1844558338 svg{width:13px;height:13px;fill:#FFFFFF;}.forcePadding.jsx-1844558338{padding:0 15px;}}</style><style id="__jsx-3863678361">.ActionBarSearch.jsx-3863678361{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;}</style><style id="__jsx-728636942">.SubmitAnArticleButton.jsx-728636942{margin-left:5px;}
.mobileButton.jsx-728636942{display:block !important;}
.mobileButton.jsx-728636942 svg{fill:#36D57D;width:35px;height:35px;}
.SubmitAnArticleButton.jsx-728636942 .desktopButton{display:none !important;}
@media (min-width:800px){.mobileButton.jsx-728636942{display:none !important;}.SubmitAnArticleButton.jsx-728636942 .desktopButton{display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;}}</style><style id="__jsx-3196442269">.ActionBarAuth.jsx-3196442269{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}
.wrapper.jsx-3196442269{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:pointer;}
.name.jsx-3196442269{margin-right:9px;font-size:13px;font-weight:bold;color:#3D4251;text-decoration:none;}
.name.jsx-3196442269:hover{color:#33AACC;}
.logout.jsx-3196442269{font-size:15px;padding:10px;color:#3D4251;display:inline-block;min-width:100px;}
.logout.jsx-3196442269:hover{background-color:#F0F4F5;border-bottom:solid 1px #E3E7E8;}
.menuList.jsx-3196442269 a.jsx-3196442269{display:block;}</style><style id="__jsx-2159026896">.ActionBar.jsx-2159026896{height:50px;margin-top:50px;padding:0 5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;}
.authBlock.jsx-2159026896{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-fles-direction:row;-ms-fles-direction:row;fles-direction:row;}
.Page.content .ActionBar{margin-bottom:10px;}
@media (min-width:800px){.ActionBar.jsx-2159026896{width:calc(100% - 220px);height:50px;margin-top:0;margin-bottom:0;padding:0 25px;position:fixed;z-index:300;}}</style><style id="__jsx-3889859319">.Title.jsx-3889859319{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.Title.jsx-3889859319 .icon.jsx-3889859319{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;min-width:18px;height:18px;}
.icon.jsx-3889859319 svg{-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;height:18px;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;fill:#33AACC;}
.Title.jsx-3889859319 .h1.jsx-3889859319,.Title.jsx-3889859319 h1.jsx-3889859319{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;margin:auto 0 auto 9px;font-size:22px;text-transform:capitalize;}
.Title.jsx-3889859319 .status.jsx-3889859319{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;padding:10px;}</style><style id="__jsx-1514242801">.TitleBar.jsx-1514242801{height:50px;padding:0 5px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:wrap;-ms-flex-wrap:wrap;flex-wrap:wrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:50px;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;margin-bottom:65px;}
.filter.jsx-1514242801{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:48px;}
.action.jsx-1514242801{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;line-height:normal;}
.title.jsx-1514242801{height:65px;line-height:65px;-webkit-flex:0 0 100%;-ms-flex:0 0 100%;flex:0 0 100%;-webkit-order:1;-ms-flex-order:1;order:1;text-align:center;}
h1.jsx-1514242801{margin:0 0;}
.Page.content .TitleBar{display:none;}
@media (min-width:800px){.TitleBar.jsx-1514242801{height:50px;padding:0 25px;display:-webkit-box !important;display:-webkit-flex !important;display:-ms-flexbox !important;display:flex !important;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-flex-wrap:nowrap;-ms-flex-wrap:nowrap;flex-wrap:nowrap;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-bottom:29px;margin-top:50px;background-color:#FFFFFF;border-bottom:1px solid #E3E7E8;}.filter.jsx-1514242801{-webkit-flex:0 0 33%;-ms-flex:0 0 33%;flex:0 0 33%;line-height:normal;}.action.jsx-1514242801{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;line-height:normal;-webkit-flex:0 0 33%;-ms-flex:0 0 33%;flex:0 0 33%;}.action.jsx-1514242801 a{line-height:0;}.title.jsx-1514242801{-webkit-order:0;-ms-flex-order:0;order:0;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;text-align:center;}h1.jsx-1514242801{margin:0 0;}}</style><style id="__jsx-3293774837">.CommentCounter.jsx-3293774837{width:54px;height:54px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-radius:4px;border:1px solid #E6EAEB;background-color:#F0F4F5;cursor:pointer;}
.CommentCounter.jsx-3293774837 .icon.jsx-3293774837{font-size:13px;line-height:0;color:#33AACC;}
.CommentCounter.jsx-3293774837 .icon.jsx-3293774837 svg{width:16px;height:16px;fill:#33AACC;}
.CommentCounter.jsx-3293774837 .count.jsx-3293774837{font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;}
.CommentCounter.jsx-3293774837:hover{background-color:#FFFFFF;}</style><style id="__jsx-1972554161">.Upvote.jsx-1972554161{position:relative;width:54px;height:54px;overflow:hidden;border-radius:4px;border:1px solid #E6EAEB;background-color:#F0F4F5;cursor:pointer;}
.Upvote.news.jsx-1972554161{width:45px;height:35px;border:none;background-color:transparent;}
.Upvote.comment.jsx-1972554161{width:45px;height:25px;border:none;background-color:transparent;}
.Upvote.jsx-1972554161>div.jsx-1972554161{position:absolute;top:0;-webkit-transition:all 0.15s ease-in-out;transition:all 0.15s ease-in-out;}
.Upvote.upvoted.jsx-1972554161>div.jsx-1972554161{top:-54px;}
.Upvote.upvoted.news.jsx-1972554161>div.jsx-1972554161{top:-35px;}
.Upvote.upvoted.comment.jsx-1972554161>div.jsx-1972554161{top:-25px;}
.Upvote.jsx-1972554161>div.jsx-1972554161>div.jsx-1972554161{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;width:54px;height:54px;}
.Upvote.news.jsx-1972554161>div.jsx-1972554161>div.jsx-1972554161{width:45px;height:35px;}
.Upvote.comment.jsx-1972554161>div.jsx-1972554161>div.jsx-1972554161{width:45px;height:25px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;}
.Upvote.jsx-1972554161 .icon.jsx-1972554161{font-size:13px;line-height:0;color:#33AACC;}
.Upvote.comment.jsx-1972554161 .icon.jsx-1972554161{padding-right:5px;}
.Upvote.comment.jsx-1972554161 .count.jsx-1972554161{padding-bottom:1px;}
.Upvote.jsx-1972554161 .icon.jsx-1972554161 svg{width:12px;height:12px;fill:#33AACC;}
.Upvote.jsx-1972554161 .count.jsx-1972554161{font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;}
.Upvote.jsx-1972554161:hover{background-color:#FFFFFF;}
.Upvote.news.jsx-1972554161:hover,.Upvote.comment.jsx-1972554161:hover{background-color:#EBF4F7;}
.Upvote.news.jsx-1972554161:hover .count.jsx-1972554161,.Upvote.comment.jsx-1972554161:hover .count.jsx-1972554161{color:#33AACC;}
.Upvote.jsx-1972554161 .voted.jsx-1972554161{background-color:#33AACC;border-color:#33AACC;}
.Upvote.news.jsx-1972554161 .voted.jsx-1972554161,.Upvote.comment.jsx-1972554161 .voted.jsx-1972554161{background-color:#FFFFFF;border:none;}
.Upvote.jsx-1972554161 .voted.jsx-1972554161 .icon.jsx-1972554161 svg{fill:#195B73;}
.Upvote.news.jsx-1972554161 .voted.jsx-1972554161 .icon.jsx-1972554161 svg,.Upvote.comment.jsx-1972554161 .voted.jsx-1972554161 .icon.jsx-1972554161 svg{fill:#36D57D;}
.Upvote.jsx-1972554161 .voted.jsx-1972554161 .count.jsx-1972554161{color:#FFFFFF;}
.Upvote.news.jsx-1972554161 .voted.jsx-1972554161 .count.jsx-1972554161,.Upvote.comment.jsx-1972554161 .voted.jsx-1972554161 .count.jsx-1972554161{color:#36D57D;}
@media (min-width:800px){.Upvote.news.jsx-1972554161{height:45px;}.Upvote.comment.jsx-1972554161{height:25px;}.Upvote.upvoted.news.jsx-1972554161>div.jsx-1972554161{top:-45px;}.Upvote.upvoted.comment.jsx-1972554161>div.jsx-1972554161{top:-25px;}.Upvote.news.jsx-1972554161>div.jsx-1972554161>div.jsx-1972554161{height:45px;}.Upvote.comment.jsx-1972554161>div.jsx-1972554161>div.jsx-1972554161{height:25px;}}</style><style id="__jsx-494086174">.Social.jsx-494086174{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;}
.icons.jsx-494086174{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.icon.jsx-494086174{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:28px;height:28px;border:1px solid #E3E7E8;background-color:#FFFFFF;border-radius:50%;}
.icon.jsx-494086174:hover{background-color:#F0F4F5;}
.centerIcon.jsx-494086174{margin:0 10px;}
.icon.jsx-494086174 svg{fill:#686F75;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
@media (min-width:800px){.Social.jsx-494086174{margin-top:18px;}.vertical.jsx-494086174{margin-top:10px;}.vertical.jsx-494086174 .icons.jsx-494086174{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.vertical.jsx-494086174 .centerIcon.jsx-494086174{margin:10px 0;}}</style><style id="__jsx-3208234818">.Avatar.jsx-3208234818{display:inline-block;background-size:cover;background-color:#E6EAEB;background-repeat:no-repeat;}</style><style id="__jsx-566588255">.Author.jsx-566588255 a.jsx-566588255{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;cursor:pointer;}
.info.jsx-566588255{margin-left:9px;white-space:nowrap;}
.mirrored.jsx-566588255 .info.jsx-566588255{margin:0 9px 0 0;-webkit-order:-1;-ms-flex-order:-1;order:-1;}
.name.jsx-566588255{font-size:13px;font-weight:bold;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#3D4251;text-decoration:none;}
.name.jsx-566588255:hover{color:#33AACC;}
.date.jsx-566588255{font-size:11px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;}</style><style id="__jsx-1764811326">.Tag.jsx-1764811326{display:inline-block;border-radius:4px;background-color:#F0F4F5;border:solid 1px #E6EAEB;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;color:#686F75;cursor:default;}
.title.jsx-1764811326{line-height:20px;padding:0 8px;font-size:11px;text-transform:uppercase;}
.Tag.mustRead.jsx-1764811326{background-color:#AD86CE;border-color:#AD86CE;color:#FFFFFF;font-weight:bold;}
.Tag.jsx-1764811326:hover{background-color:#FFFFFF;}
.Tag.mustRead.jsx-1764811326:hover{background-color:#CEABEC;border-color:#CEABEC;}</style><style id="__jsx-1022557955">.more.jsx-1022557955{font-size:11px;cursor:default;color:#686F75;}
.more.jsx-1022557955:hover{text-decoration:underline;}</style><style id="__jsx-422934526">.tooltipInner .Tag{margin:4px;}
.rc-tooltip{position:absolute;z-index:200;display:block;visibility:visible;line-height:1.5;font-size:12px;border-radius:4px;}
.rc-tooltip-hidden{display:none;}
.rc-tooltip-inner{padding:12px;color:#333333;text-align:left;text-decoration:none;background-color:#ffffff;border-radius:4px;min-height:34px;border:1px solid #e3e7e8;}
.rc-tooltip-arrow,.rc-tooltip-arrow-inner{position:absolute;width:0;height:0;border-color:transparent;border-style:solid;}
.rc-tooltip-placement-top .rc-tooltip-arrow,.rc-tooltip-placement-topLeft .rc-tooltip-arrow,.rc-tooltip-placement-topRight .rc-tooltip-arrow{bottom:-5px;margin-left:-6px;border-width:6px 6px 0;border-top-color:#e3e7e8;}
.rc-tooltip-placement-top .rc-tooltip-arrow-inner,.rc-tooltip-placement-topLeft .rc-tooltip-arrow-inner,.rc-tooltip-placement-topRight .rc-tooltip-arrow-inner{bottom:1px;margin-left:-6px;border-width:6px 6px 0;border-top-color:#ffffff;}
.rc-tooltip-placement-top .rc-tooltip-arrow{left:50%;}
.rc-tooltip-placement-topLeft .rc-tooltip-arrow{left:15%;}
.rc-tooltip-placement-topRight .rc-tooltip-arrow{right:15%;}
.rc-tooltip-placement-right .rc-tooltip-arrow,.rc-tooltip-placement-rightTop .rc-tooltip-arrow,.rc-tooltip-placement-rightBottom .rc-tooltip-arrow{left:-5px;margin-top:-6px;border-width:6px 6px 6px 0;border-right-color:#e3e7e8;}
.rc-tooltip-placement-right .rc-tooltip-arrow-inner,.rc-tooltip-placement-rightTop .rc-tooltip-arrow-inner,.rc-tooltip-placement-rightBottom .rc-tooltip-arrow-inner{left:1px;margin-top:-6px;border-width:6px 6px 6px 0;border-right-color:#ffffff;}
.rc-tooltip-placement-right .rc-tooltip-arrow{top:50%;}
.rc-tooltip-placement-rightTop .rc-tooltip-arrow{top:15%;margin-top:0;}
.rc-tooltip-placement-rightBottom .rc-tooltip-arrow{bottom:15%;}
.rc-tooltip-placement-left .rc-tooltip-arrow,.rc-tooltip-placement-leftTop .rc-tooltip-arrow,.rc-tooltip-placement-leftBottom .rc-tooltip-arrow{right:-5px;margin-top:-6px;border-width:6px 0 6px 6px;border-left-color:#e3e7e8;}
.rc-tooltip-placement-left .rc-tooltip-arrow-inner,.rc-tooltip-placement-leftTop .rc-tooltip-arrow-inner,.rc-tooltip-placement-leftBottom .rc-tooltip-arrow-inner{right:1px;margin-top:-6px;border-width:6px 0 6px 6px;border-left-color:#ffffff;}
.rc-tooltip-placement-left .rc-tooltip-arrow{top:50%;}
.rc-tooltip-placement-leftTop .rc-tooltip-arrow{top:15%;margin-top:0;}
.rc-tooltip-placement-leftBottom .rc-tooltip-arrow{bottom:15%;}
.rc-tooltip-placement-bottom .rc-tooltip-arrow,.rc-tooltip-placement-bottomLeft .rc-tooltip-arrow,.rc-tooltip-placement-bottomRight .rc-tooltip-arrow{top:-5px;margin-left:-6px;border-width:0 6px 6px;border-bottom-color:#e3e7e8;}
.rc-tooltip-placement-bottom .rc-tooltip-arrow-inner,.rc-tooltip-placement-bottomLeft .rc-tooltip-arrow-inner,.rc-tooltip-placement-bottomRight .rc-tooltip-arrow-inner{top:1px;margin-left:-6px;border-width:0 6px 6px;border-bottom-color:#ffffff;}
.rc-tooltip-placement-bottom .rc-tooltip-arrow{left:50%;}
.rc-tooltip-placement-bottomLeft .rc-tooltip-arrow{left:15%;}
.rc-tooltip-placement-bottomRight .rc-tooltip-arrow{right:15%;}
.rc-tooltip.rc-tooltip-zoom-enter,.rc-tooltip.rc-tooltip-zoom-leave{display:block;}
.rc-tooltip-zoom-enter,.rc-tooltip-zoom-appear{opacity:0;-webkit-animation-duration:0.3s;-webkit-animation-duration:0.3s;animation-duration:0.3s;-webkit-animation-fill-mode:both;-webkit-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-timing-function:cubic-bezier(0.18,0.89,0.32,1.28);-webkit-animation-timing-function:cubic-bezier(0.18,0.89,0.32,1.28);animation-timing-function:cubic-bezier(0.18,0.89,0.32,1.28);-webkit-animation-play-state:paused;-webkit-animation-play-state:paused;animation-play-state:paused;}
.rc-tooltip-zoom-leave{-webkit-animation-duration:0.3s;-webkit-animation-duration:0.3s;animation-duration:0.3s;-webkit-animation-fill-mode:both;-webkit-animation-fill-mode:both;animation-fill-mode:both;-webkit-animation-timing-function:cubic-bezier(0.6,-0.3,0.74,0.05);-webkit-animation-timing-function:cubic-bezier(0.6,-0.3,0.74,0.05);animation-timing-function:cubic-bezier(0.6,-0.3,0.74,0.05);-webkit-animation-play-state:paused;-webkit-animation-play-state:paused;animation-play-state:paused;}
.rc-tooltip-zoom-enter.rc-tooltip-zoom-enter-active,.rc-tooltip-zoom-appear.rc-tooltip-zoom-appear-active{-webkit-animation-name:rcToolTipZoomIn;-webkit-animation-name:rcToolTipZoomIn;animation-name:rcToolTipZoomIn;-webkit-animation-play-state:running;-webkit-animation-play-state:running;animation-play-state:running;}
.rc-tooltip-zoom-leave.rc-tooltip-zoom-leave-active{-webkit-animation-name:rcToolTipZoomOut;-webkit-animation-name:rcToolTipZoomOut;animation-name:rcToolTipZoomOut;-webkit-animation-play-state:running;-webkit-animation-play-state:running;animation-play-state:running;}
@-webkit-keyframes rcToolTipZoomIn{0%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}100%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}}
@-webkit-keyframes rcToolTipZoomIn{0%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}100%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}}
@keyframes rcToolTipZoomIn{0%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}100%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}}
@-webkit-keyframes rcToolTipZoomOut{0%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}100%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}}
@-webkit-keyframes rcToolTipZoomOut{0%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}100%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}}
@keyframes rcToolTipZoomOut{0%{opacity:1;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(1,1);-webkit-transform:scale(1,1);-ms-transform:scale(1,1);transform:scale(1,1);}100%{opacity:0;-webkit-transform-origin:50% 50%;-webkit-transform-origin:50% 50%;-ms-transform-origin:50% 50%;transform-origin:50% 50%;-webkit-transform:scale(0,0);-webkit-transform:scale(0,0);-ms-transform:scale(0,0);transform:scale(0,0);}}</style><style id="__jsx-2792531181">.TagLine.jsx-2792531181{display:inline-block;white-space:nowrap;}
.TagLine.jsx-2792531181>.Tag{margin-right:10px;}
.more.jsx-2792531181{font-size:11px;}</style><style id="__jsx-1091791248">.markdown{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;font-family:'Lora',serif;font-size:16px;padding:1.5em;}
.markdown [data-datacamp-exercise]{overflow:hidden;}
.markdown>div{width:100%;}
.markdown div{outline:none;}
.markdown hr{border:0;border-bottom:1px solid #E6EAEB;margin:3em 0;}
.markdown div[data-type="mathjax"]{margin:1.5em 0;}
.markdown p{font-family:'Lora',serif;font-size:1em;line-height:1.8em;color:#3D4251;}
.markdown .powered-by-datacamp+p{margin-top:1.5em !important;}
.markdown p+p,.markdown p+img,.markdown p+div,.markdown p+table,.markdown p+ol,.markdown p+ul,.markdown p+nav,.markdown div+p,.markdown p+iframe,.markdown iframe+p,.markdown pre+img,.markdown pre+p{margin-top:1.5em !important;}
.markdown h2{font-family:'Lato',sans-serif;font-size:1.5em;font-weight:700;color:#3D4251;line-height:1.3em;margin:1.5em 0 0.5em;}
.markdown h3{font-family:'Lato',sans-serif;font-size:1.1em;font-weight:700;color:#3D4251;line-height:1.2em;margin:1.5em 0 0.5em;}
.markdown h4{font-family:'Lato',sans-serif;font-size:1em;font-weight:700;color:#3D4251;line-height:1.2em;margin:1.5em 0 0.5em;}
.markdown .videoWrapper{position:relative;padding-bottom:47.25%;padding-top:25px;height:0;margin-bottom:1.5em;}
.markdown .videoWrapper iframe{position:absolute;top:0;left:0;width:100%;height:100%;}
.markdown p code,.markdown li code{display:inline-block;padding:0 5px;border-radius:4px;font-family:'Roboto Mono',monospace;font-size:0.9em;line-height:1.6em;color:#3D4251;background-color:#E6EAEB;}
.markdown a code{color:#33AACC;}
.markdown pre{padding:1em 1.5em;font-family:'Roboto Mono',monospace;font-size:0.9em;background-color:#002B36 !important;border-radius:4px;overflow-x:auto;-webkit-overflow-scrolling:touch;}
.markdown pre code{padding:0;font-size:0.9em;line-height:2em;background-color:#002B36;overflow-x:visible;-webkit-overflow-scrolling:touch;}
.markdown img{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;margin:auto;max-width:100%;height:auto !important;}
.markdown img+p{margin-top:1.5em !important;}
.markdown nav+p,.markdown nav+div{margin-top:1.5em !important;}
.markdown iframe{width:100%;}
.markdown ul,.markdown ol{font-family:'Lora',serif;color:#3D4251;padding:0 0 0 1em;}
.markdown ul+p,.markdown ol+p,.markdown ul+div,.markdown ol+div,.markdown ul+pre,.markdown ol+pre{margin-top:1.5em !important;}
.markdown div.datacamp-exercise ul,.markdown div.datacamp-exercise ol{background-color:initial;margin:initial;padding:initial;width:initial;list-style-position:initial;line-height:initial;}
.markdown ul.oneliner,.markdown ol.oneliner{padding:0;list-style-position:inside;line-height:1.5em;}
.markdown li{line-height:1.8em;}
.markdown li+li{margin-top:1em;}
.markdown div.datacamp-exercise li{padding-left:initial;background-color:initial;font-size:initial;font-weight:initial;line-height:initial;}
.markdown li p{margin:0;font-size:1em;line-height:1.8em;}
.markdown ul.oneliner li,.markdown ol.oneliner li{padding-left:0;white-space:nowrap;text-overflow:ellipsis;overflow:hidden;}
.markdown ul ul{margin:0;list-style:circle;}
.markdown ol ol{margin:0;}
.markdown ol ul,.markdown ul ol{margin:0;}
.markdown a{font-weight:400;text-decoration:none;color:#33AACC;}
.markdown a:hover{text-decoration:underline;}
.markdown div.datacamp-exercise a{font-weight:initial;text-decoration:initial;}
.markdown div.datacamp-exercise a:hover{text-decoration:initial;}
.markdown div.datacamp-exercise li+li{margin-top:unset;}
.markdown blockquote{margin:1.5em 0;font-family:'Lato',sans-serif;color:#3D4251;font-weight:300;font-size:1.5em;font-style:italic;line-height:2em;}
.markdown blockquote::before{display:block;margin-bottom:15px;width:35px;height:35px;font-family:'Lora',serif;font-size:36px;font-weight:bold;font-style:normal;line-height:60px;text-align:center;color:#33AACC;content:'â€œ';border:1px solid #E3E7E8;border-radius:50%;}
.markdown table{width:100% !important;border:1px solid #E3E7E8;border-radius:4px;overflow:hidden;border-collapse:separate;border-spacing:0;}
.markdown table th,.markdown table td{padding:0.75em;}
.markdown table tr th,.markdown table tr td{border:1px solid #E3E7E8;vertical-align:middle;}
.markdown table thead tr th{font-family:'Lato',sans-serif;background-color:#F0F4F5;}
.markdown table tr:nth-child(even){background-color:#F0F4F5;}
.markdown table+p{margin-top:1.5em !important;}
.markdown table+img{margin-top:1.5em !important;}
.markdown table+div{margin-top:1.5em !important;}
.markdown .dcl-content--tab-body{margin-top:0 !important;}
@media (min-width:800px){.markdown{font-size:20px;padding:0;}.markdown h2,.markdown h3,.markdown h4{margin:1.5em 0 0.5em;}.markdown p{margin:0;}.markdown li p{font-size:inherit;line-height:inherit;}.markdown ul+p,.markdown ol+p,.markdown ul+div,.markdown ol+div,.markdown ul+pre,.markdown ol+pre{margin-top:1.5em !important;}.markdown blockquote{position:relative;margin:50px 55px;}.markdown blockquote::before{position:absolute;left:-55px;}}
.output_wrapper{overflow-x:auto;-webkit-overflow-scrolling:touch;}</style><style id="__jsx-1426450779">.RecommendedCard.jsx-1426450779{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;background-color:#FFFFFF;border-radius:4px;border:solid 1px #e3e7e8;overflow:hidden;cursor:pointer;-webkit-transition:all 0.15s ease-in-out;transition:all 0.15s ease-in-out;}
.RecommendedCard.jsx-1426450779:hover{box-shadow: 0 18px 21px 0 rgba(22, 63, 82, 0.15);transform: translate(0,-5px);transition: all 0.2s ease-in-out;}
h2.jsx-1426450779{height:52px;overflow:hidden;font-size:20px;}
.image.jsx-1426450779{background-size:cover;background-position:center;height:144px;}
.info.jsx-1426450779{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:20px;}
.space.jsx-1426450779{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.authorWrapper.jsx-1426450779{margin:16px 0;}
@media (min-width:800px){.info.noImage.jsx-1426450779{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}h2.jsx-1426450779{margin-bottom:0px;}.topCard.jsx-1426450779 .image.jsx-1426450779{height:170px;}}</style><style id="__jsx-2205214625">.RecommendedArticles.jsx-2205214625{margin:0 10px 30px;}
.articleWrapper.jsx-2205214625{margin-bottom:20px;}
.title.jsx-2205214625{text-transform:uppercase;font-size:13px;font-weight:bold;-webkit-letter-spacing:1px;-moz-letter-spacing:1px;-ms-letter-spacing:1px;letter-spacing:1px;text-align:left;color:#686F75;margin-bottom:10px;}
.articleWrapper.jsx-2205214625 .description{display:none !important;}
@media (min-width:800px){.articleWrapper.jsx-2205214625 .description{display:inline-block;}.RecommendedArticles.jsx-2205214625{max-width:1120px;margin:0 auto;padding-bottom:30px;}.articleLayout.jsx-2205214625{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}.articleWrapper.jsx-2205214625{margin:0;-webkit-flex-basis:346px;-ms-flex-preferred-size:346px;flex-basis:346px;}.articleWrapper.jsx-2205214625:nth-child(2){margin:0 41px;}.articleWrapper.jsx-2205214625>div{height:100%;}}</style><style id="__jsx-3956319705">.PostAComment.jsx-3956319705{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;padding:0 0 60px;}</style><style id="__jsx-2506565400">.SidebarSocial.jsx-2506565400{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;font-size:11px;font-weight:bold;}
.rss.jsx-2506565400{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:50px;}
.rss.jsx-2506565400 svg{padding-right:7px;fill:#FFC844;}
.rss.jsx-2506565400 a.jsx-2506565400{text-decoration:none;color:#FFFFFF;}
.rss.jsx-2506565400 a.jsx-2506565400:hover{text-decoration:none;color:#FFC844;}
.icons.jsx-2506565400{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.icon.jsx-2506565400{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:0 7px;width:30px;height:30px;background-color:#195B73;border-radius:50%;}
.icon.jsx-2506565400 svg{fill:#7ECCE2;-webkit-align-self:center;-ms-flex-item-align:center;align-self:center;-webkit-flex:1 1 0;-ms-flex:1 1 0;flex:1 1 0;}
.icon.jsx-2506565400:hover svg{fill:#FFFFFF;}
.menu.jsx-2506565400{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;line-height:44px;}
.menuItem.jsx-2506565400{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;padding:5px;text-decoration:none;color:#195B73;}
.menuItem--active.jsx-2506565400,a.jsx-2506565400:hover{color:#F0F4F5;}
@media (min-width:800px) and (min-height:585px){.SidebarSocial.jsx-2506565400{width:220px;position:fixed;bottom:0;left:0;}}</style><style id="__jsx-879378290">.BottomBar.jsx-879378290{position:fixed;bottom:0;width:100vw;padding:15px;z-index:300;background-color:#FFFFFF;box-shadow:0 -2px 26px 0 rgba(168,168,168,0.5);}
.BottomBar.editor.jsx-879378290{padding-top:5px;}
.barView.jsx-879378290{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.editor.jsx-879378290 .barView.jsx-879378290{display:none;}
.blueBar.jsx-879378290{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;height:50px;margin-left:15px;padding:0 15px;color:#33AACC;line-height:50px;border-radius:4px;background-color:#ebf4f7;}
.editorView.jsx-879378290{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;}
.editorView.jsx-879378290 .avatar{display:none;}
.bar.jsx-879378290 .editorView.jsx-879378290{display:none;}
.hideBar.jsx-879378290{display:none;}
@media (min-width:800px){.BottomBar.jsx-879378290{width:calc(100% - 220px);margin-left:220px;}.editorView.jsx-879378290 .avatar{display:block;}}</style><style id="__jsx-1028385822">.Layout.jsx-1028385822{-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:stretch;-webkit-box-align:stretch;-ms-flex-align:stretch;align-items:stretch;}
.Layout--openMenu.jsx-1028385822{min-height:100vh;}
.Main.jsx-1028385822{min-height:100vh;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;background-color:#F0F4F5;}
.Layout--banner.jsx-1028385822 .Main.jsx-1028385822{margin-top:55px;min-height:calc(100vh - 55px);}
.Layout.bar.jsx-1028385822:not(.Layout--openMenu) .SidebarSocial{margin-bottom:90px;}
.Layout.editor.jsx-1028385822:not(.Layout--openMenu) .SidebarSocial{margin-bottom:300px;}
@media (min-width:800px){.Main.jsx-1028385822{margin-left:220px;}.Layout--banner.jsx-1028385822 .Main.jsx-1028385822{margin-top:80px;min-height:calc(100vh - 80px);}.Layout.bar.jsx-1028385822:not(.Layout--openMenu) .SidebarSocial,.Layout.editor.jsx-1028385822:not(.Layout--openMenu) .SidebarSocial{margin-bottom:0;}.Layout.bar.jsx-1028385822 .Main > div:last-child{margin-bottom:90px;}.Layout.editor.jsx-1028385822 .Main > div:last-child{margin-bottom:300px;}}</style><style id="__jsx-1464850800">.Tutorial.jsx-1464850800{margin:0 0px 30px;padding:20px 0 0;background-color:#FFFFFF;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}
.preface.jsx-1464850800{margin:0 20px;}
.author.jsx-1464850800{margin-bottom:10px;}
h1.jsx-1464850800{margin-top:20px;}
.illustration.jsx-1464850800{margin-bottom:30px;}
.illustration.jsx-1464850800 img.jsx-1464850800{max-width:100%;}
.Tutorial.jsx-1464850800 .social__top .voteAndSocial,.social__bottom.jsx-1464850800 .voteAndSocial.jsx-1464850800{padding:40px 20px 20px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;}
.Tutorial.jsx-1464850800 .voteAndSocial.jsx-1464850800>div.jsx-1464850800{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}
.Tutorial.jsx-1464850800 .voteAndSocial.jsx-1464850800>div.jsx-1464850800 .CommentCounter{margin-left:10px;}
@media (min-width:800px){.Tutorial.jsx-1464850800{margin:0 auto 30px;padding:30px 100px 100px;max-width:1120px;border-radius:4px;border:1px solid #E3E7E8;}.preface.jsx-1464850800{margin:0;}.Tutorial.jsx-1464850800 .social__top{position:absolute;margin-top:220px;}.Tutorial.jsx-1464850800 .social__top .voteAndSocial{position:absolute;left:-100px;top:0;width:100px;height:auto;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:start;-webkit-justify-content:flex-start;-ms-flex-pack:start;justify-content:flex-start;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}.Tutorial.jsx-1464850800 .voteAndSocial.jsx-1464850800>div.jsx-1464850800{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.Tutorial.jsx-1464850800 .voteAndSocial > div .CommentCounter{margin-left:0;margin-bottom:10px;}}</style><style id="__jsx-2612661084">*{box-sizing:border-box;}
html,body{min-height:100vh;margin:0;padding:0;background-image: linear-gradient(207deg, #2388B0, #33AACC); background-size: 100vw 100vh; background-attachment: fixed; background-repeat: no-repeat;}
body.ReactModal__Body--open{overflow:hidden;}
.ReactModal__Content{width:100%;}
img{margin:auto;}
.mobileOnlyShow{display:block !important;}
.mobileOnlyHide{display:none !important;}
.mobileOnly{display:block !important;}
.desktopOnly{display:none !important;}
@media (min-width:800px){body{background-image: linear-gradient(207deg, #2388B0, #33AACC); background-size: 220px 100vh; background-attachment: fixed; background-repeat: no-repeat;}.ReactModal__Content{width:auto;}.mobileOnlyShow{display:block !important;}.mobileOnlyHide{display:block !important;}.mobileOnly{display:none !important;}.desktopOnly{display:block !important;}}</style><style id="__jsx-63629563">body,input,button,select,textarea{font-family:'Lato',sans-serif;color:#686F75;font-size:15px;}
h1,.h1,h2,h3,h4,h5{font-family:'Lato',sans-serif;}
.pageTitle{font-family:'Lato',sans-serif;font-size:32px;font-weight:bold;line-height:1.3em;margin-bottom:0.5em;}
.pageDescription{font-family:'Lora',serif;font-size:20.8px;line-height:1.5em;margin-bottom:1.4em;color:#3D4251;}
h1,.h1{font-size:29px;color:#3D4251;font-weight:bold;}
h2{font-size:20px;-webkit-letter-spacing:0.3px;-moz-letter-spacing:0.3px;-ms-letter-spacing:0.3px;letter-spacing:0.3px;line-height:1.33;font-weight:bold;margin:18px 0px;color:#3D4251;}
h2.blue{color:#33AACC;}
a{color:#33AACC;text-decoration:none;}
.blocText{font-size:15px;-webkit-letter-spacing:0.2px;-moz-letter-spacing:0.2px;-ms-letter-spacing:0.2px;letter-spacing:0.2px;line-height:1.47;color:#686F75;}
label{display:block;width:100%;margin-bottom:8px;font-size:13px;}
label span{float:right;font-weight:300;}
input,textarea{padding:15px;font-weight:300;color:#3D4251;background-color:#F0F4F5;border:1px solid transparent;border-radius:4px;outline-style:none;}
input:disabled,textarea:disabled{color:#686F75;background-color:#E6EAEB;}
input.error,textarea.error{border:1px solid #FE5C5C;}
input:focus,textarea:focus{border:1px solid #33AACC;-webkit-transition:border 150ms ease-out;transition:border 150ms ease-out;}
input::-webkit-input-placeholder,textarea::-webkit-input-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input::-moz-placeholder,textarea::-moz-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input:-ms-input-placeholder,textarea:-ms-input-placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input::placeholder,textarea::placeholder{color:#33AACC;-webkit-transition:color 150ms ease-out;transition:color 150ms ease-out;}
input:focus::-webkit-input-placeholder,textarea:focus::-webkit-input-placeholder{color:transparent;}
input:focus::-moz-placeholder,textarea:focus::-moz-placeholder{color:transparent;}
input:focus:-ms-input-placeholder,textarea:focus:-ms-input-placeholder{color:transparent;}
input:focus::placeholder,textarea:focus::placeholder{color:transparent;}
input.small,textarea.small{margin-bottom:19px;padding:8px 10px;font-size:13px;}
textarea.small{min-height:55px;}
@media (min-width:800px){h1,.h1{font-size:36px;}h2{font-size:32px;}.pageTitle{font-size:40px;}.pageDescription{font-size:26px;}}</style></head><body><div id="__next"><div data-reactroot=""><div class="Page content"><div class="jsx-1028385822 Layout bar"><div class="jsx-499055511 SidebarMenu"><div class="jsx-396080995 Logo"><a href="https://www.datacamp.com" class="jsx-396080995 Logo__image"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1367.47 306.77"><path d="M201.49 130.16c2.64-10.87 2.31-21.09-3.62-35.38 0 0 9.55 3.71 8.56-3.65S194.91 76 187 71.11c-3.48-2.17-12.89-6.79-25.52-9.6l2.36-5.32-.66-.32c-19.59-9.54-42.24-.89-42.47-.8l-.7.27 2.24 5.92a78 78 0 0 0-19 7.09C50 96.68 77 152 93.5 165.17s8.89 40 0 64.31H165c1-4.55.13 2.24 3.46-15.91s16.18-11.41 26.3-12 8.52-7.66 8.4-15.56c4.94-2.22 4.94-4.57 1.64-7.41 4.28-4 3.62-4 1.32-7.83s-.66-5.68-.66-5.68 6.92-1.35 7.9-5c.32-7.89-14.5-19.09-11.87-29.93zm-14.78-2.28l-10.59-3.6c-.56 1.45-6 14.9-13 17.27l-6.68-8.84c-3.21 2.51-10.54 4.72-14.07 3.69v-.32h-.19l.2 24.36c-14.05 1.45-30.84-7.06-38.88-18.77l-8.78 6.67c-10-12.07-11.51-26.62-11.62-35h11.77c0-9.27 3.62-21.34 8.72-28l9.23 6.52c.75-.93 7.72-9.27 17.05-12.28h.14l-6.67-17.64c14.09-4.06 24.44-4 35.7.19a3.87 3.87 0 0 1 1 .48l.18.13-1.99 5.26c.53.23 8 3.59 11.09 6.74l2.49-3.44a42.47 42.47 0 0 1 19 25.34L187 98v-.1a55.32 55.32 0 0 1-.28 29.98z"></path><path d="M141.69 95.69a11.77 11.77 0 1 0 11.76 11.77 11.78 11.78 0 0 0-11.76-11.77zM486.07 147.93a85.48 85.48 0 0 1-5.79 31.92 71.67 71.67 0 0 1-41.54 41.32 89 89 0 0 1-32.79 5.83h-60.24V68.9h60.23a88.33 88.33 0 0 1 32.79 5.85A74 74 0 0 1 464 91a72.76 72.76 0 0 1 16.29 25 85.49 85.49 0 0 1 5.78 31.93zm-30.17 0a73.61 73.61 0 0 0-3.44-23.34 48.4 48.4 0 0 0-9.95-17.49 43.45 43.45 0 0 0-15.74-11 54 54 0 0 0-20.82-3.83h-30.72v111.3h30.72a54 54 0 0 0 20.82-3.83 43.39 43.39 0 0 0 15.74-11 48.37 48.37 0 0 0 9.95-17.49 73.6 73.6 0 0 0 3.44-23.32zM505.36 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.21 37.21 0 0 1 13.12 9 38.4 38.4 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.25a12.38 12.38 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.29 97.29 0 0 1-8.31 6.72 48.91 48.91 0 0 1-8.42 4.86 45.32 45.32 0 0 1-9.35 3 53.93 53.93 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.73 25.73 0 0 1-6.78-9.51 33.72 33.72 0 0 1-2.4-13.23 26.32 26.32 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.63 38.63 0 0 1 8.36-7.21 54.43 54.43 0 0 1 12.63-5.9 109.08 109.08 0 0 1 17.44-4.1 174.35 174.35 0 0 1 22.74-1.91v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.91 44.91 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.78 11.78 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zm61.87 48.64a149.08 149.08 0 0 0-19.68 2 52.42 52.42 0 0 0-12.79 3.77 16.8 16.8 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3 42.69 42.69 0 0 0 11.86-9.11zM657.79 228.72q-14.65 0-22.46-8.25t-7.82-22.79V135H616a5.26 5.26 0 0 1-3.72-1.42 5.53 5.53 0 0 1-1.53-4.26v-10.68l18-3 5.68-30.61a6 6 0 0 1 2.08-3.39 6.18 6.18 0 0 1 3.94-1.2h14v35.36h30V135h-30v60.78q0 5.25 2.57 8.2a8.85 8.85 0 0 0 7 3 12.7 12.7 0 0 0 4.21-.6 23 23 0 0 0 3-1.26q1.26-.66 2.24-1.26a3.75 3.75 0 0 1 2-.6 3.1 3.1 0 0 1 2 .6 9.23 9.23 0 0 1 1.64 1.8l8.09 13.12a40.87 40.87 0 0 1-13.55 7.43 50.47 50.47 0 0 1-15.86 2.51zM702.11 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.19 37.19 0 0 1 13.12 9 38.37 38.37 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.25a12.37 12.37 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.21 97.21 0 0 1-8.31 6.72 49 49 0 0 1-8.42 4.86 45.33 45.33 0 0 1-9.35 3 53.92 53.92 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.74 25.74 0 0 1-6.78-9.51 33.72 33.72 0 0 1-2.4-13.23 26.31 26.31 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.66 38.66 0 0 1 8.36-7.21 54.45 54.45 0 0 1 12.63-5.9 109.07 109.07 0 0 1 17.44-4.1 174.32 174.32 0 0 1 22.76-1.93v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.89 44.89 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.79 11.79 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zM764 179.09a149.06 149.06 0 0 0-19.68 2 52.43 52.43 0 0 0-12.79 3.77 16.81 16.81 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3A42.68 42.68 0 0 0 764 198zM929.42 189.69a5.87 5.87 0 0 1 4.26 1.86l11.59 12.57a63.64 63.64 0 0 1-23.67 18.26q-14 6.34-33.72 6.34-17.6 0-31.65-6a69.71 69.71 0 0 1-24-16.73A73.19 73.19 0 0 1 817 180.4a96 96 0 0 1-5.3-32.47 90.36 90.36 0 0 1 5.68-32.63 75 75 0 0 1 16-25.52A72.5 72.5 0 0 1 858 73.11a81.77 81.77 0 0 1 31.7-6q17.27 0 30.66 5.68a73.08 73.08 0 0 1 22.83 14.91l-9.84 13.66a9 9 0 0 1-2.24 2.29 6.35 6.35 0 0 1-3.77 1 7.2 7.2 0 0 1-3.39-.93q-1.75-.93-3.83-2.29t-4.81-3a39.67 39.67 0 0 0-6.34-3 51.92 51.92 0 0 0-8.36-2.29 57.87 57.87 0 0 0-11-.93A48.74 48.74 0 0 0 870.23 96a42.16 42.16 0 0 0-15.14 10.93 50.38 50.38 0 0 0-9.84 17.49 73.27 73.27 0 0 0-3.5 23.56 69.25 69.25 0 0 0 3.77 23.72 52.12 52.12 0 0 0 10.22 17.49 43.61 43.61 0 0 0 15.2 10.81 47 47 0 0 0 18.8 3.77 81.89 81.89 0 0 0 10.88-.66 46.17 46.17 0 0 0 9-2.08 39.7 39.7 0 0 0 7.76-3.66 48.48 48.48 0 0 0 7.27-5.52 10.31 10.31 0 0 1 2.29-1.58 5.56 5.56 0 0 1 2.48-.58zM961.6 130.44q19.35-17.71 46.57-17.71a45.54 45.54 0 0 1 17.6 3.22 37.19 37.19 0 0 1 13.12 9 38.37 38.37 0 0 1 8.14 13.72 52.72 52.72 0 0 1 2.79 17.49V227h-12.24a12.37 12.37 0 0 1-5.9-1.15q-2.08-1.15-3.28-4.65l-2.4-8.09a97.21 97.21 0 0 1-8.31 6.72 49 49 0 0 1-8.42 4.86 45.33 45.33 0 0 1-9.35 3 53.92 53.92 0 0 1-11 1 43.08 43.08 0 0 1-13.12-1.91 28.78 28.78 0 0 1-10.38-5.74 25.74 25.74 0 0 1-6.78-9.51 33.73 33.73 0 0 1-2.4-13.23 26.31 26.31 0 0 1 1.42-8.47 24.76 24.76 0 0 1 4.65-8 38.66 38.66 0 0 1 8.36-7.21 54.45 54.45 0 0 1 12.63-5.9 109.07 109.07 0 0 1 17.44-4.1 174.32 174.32 0 0 1 22.74-1.91v-6.56q0-11.26-4.81-16.67t-13.88-5.41a33 33 0 0 0-10.88 1.53 44.89 44.89 0 0 0-7.6 3.44q-3.28 1.91-6 3.44a11.79 11.79 0 0 1-6 1.53 7.79 7.79 0 0 1-4.81-1.48 12.33 12.33 0 0 1-3.17-3.44zm61.87 48.64a149.06 149.06 0 0 0-19.68 2 52.43 52.43 0 0 0-12.79 3.8 16.81 16.81 0 0 0-6.89 5.36 11.63 11.63 0 0 0-2.08 6.67q0 7.11 4.21 10.17t11 3.06a32 32 0 0 0 14.37-3 42.68 42.68 0 0 0 11.86-9.13zM1078.18 227V114.81h16.51a6.63 6.63 0 0 1 6.89 4.92l1.75 8.31a63.82 63.82 0 0 1 6.18-6 39.66 39.66 0 0 1 6.89-4.7 37.29 37.29 0 0 1 7.87-3.12 35.05 35.05 0 0 1 9.24-1.15q10.6 0 17.43 5.74a34.56 34.56 0 0 1 10.22 15.25 34.23 34.23 0 0 1 6.56-9.57 35.9 35.9 0 0 1 8.63-6.5 39.77 39.77 0 0 1 10-3.72 48.07 48.07 0 0 1 10.66-1.2 44.82 44.82 0 0 1 16.51 2.84 31.69 31.69 0 0 1 12.13 8.31 36.63 36.63 0 0 1 7.49 13.34 58.1 58.1 0 0 1 2.57 18V227h-27v-71.41q0-10.71-4.7-16.12t-13.77-5.41a20.57 20.57 0 0 0-7.71 1.42 18.37 18.37 0 0 0-6.23 4.1 18.73 18.73 0 0 0-4.21 6.72 26.13 26.13 0 0 0-1.53 9.29V227h-27.11v-71.41q0-11.26-4.54-16.4t-13.28-5.14a21.83 21.83 0 0 0-11 2.9 36.66 36.66 0 0 0-9.46 7.92V227zM1289.85 130.12a58.51 58.51 0 0 1 15.63-12.57q8.74-4.81 20.55-4.81a36.79 36.79 0 0 1 16.78 3.83 37.68 37.68 0 0 1 13.12 11.09 53.26 53.26 0 0 1 8.53 17.93 90.21 90.21 0 0 1 3 24.43 76.84 76.84 0 0 1-3.39 23.28 57 57 0 0 1-9.67 18.58 44.72 44.72 0 0 1-15.19 12.3 44.22 44.22 0 0 1-19.95 4.43 40.23 40.23 0 0 1-16.07-2.9 39.23 39.23 0 0 1-11.92-8v45.91h-27V114.81h16.51a6.63 6.63 0 0 1 6.89 4.92zm1.42 67.77a26.57 26.57 0 0 0 10 7.87 29.76 29.76 0 0 0 11.75 2.3 25.79 25.79 0 0 0 11-2.3 21.63 21.63 0 0 0 8.36-7 34.62 34.62 0 0 0 5.3-11.86 67.79 67.79 0 0 0 1.86-16.89 75 75 0 0 0-1.58-16.67 32.22 32.22 0 0 0-4.54-11.09 17.92 17.92 0 0 0-7.16-6.23 22.34 22.34 0 0 0-9.57-2 27.28 27.28 0 0 0-14.32 3.55 43.46 43.46 0 0 0-11.15 10z"></path><path d="M144.06 306.77a9.83 9.83 0 0 1-4.72-1.21L23.79 242a9.82 9.82 0 0 1-5-7.56L.06 57.52a9.77 9.77 0 0 1 6.5-10.29L139.37.55a9.88 9.88 0 0 1 6.43 0L281.5 47.2a9.86 9.86 0 0 1 6.5 10.47L266.47 234.6a9.85 9.85 0 0 1-4.91 7.35l-112.68 63.56a9.84 9.84 0 0 1-4.82 1.26zm-110-77l110 60.49 107.22-60.48L271.89 60.5 142.64 16 16.15 60.5z"></path></svg></a></div><div class="jsx-499055511 icon mobileOnly"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 80 70"><path d="M6 1a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6zm0 28a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6zm0 28a6 6 0 1 0 0 12h68a6 6 0 0 0 0-12H6z"></path></svg></div></div><div class="jsx-2769082546 Menu mobileOnlyHide"><div class="jsx-2769082546 section"><h5 class="jsx-2769082546">community</h5><nav class="jsx-2769082546"><div><a target="_self" class="jsx-2769082546 item" href="/community"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 23 23"><path id="a" d="M2 4.5h20a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3zm0 6h14a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3zm0 6h20a1.5 1.5 0 0 1 0 3H2a1.5 1.5 0 0 1 0-3z"></path></svg></div><div class="jsx-2769082546 text">News</div><div class="jsx-2769082546 statusIcon"><svg height="20" xmlns="http://www.w3.org/2000/svg" width="40" viewBox="0 0 40 20"><g fill="none" fill-rule="evenodd"><rect width="40" height="20" fill="#FFC844" rx="4"></rect><text fill="#3D4251" font-family="Lato-Bold, Lato" font-size="11" font-weight="bold" letter-spacing=".5"><tspan x="5" y="14">BETA</tspan></text></g></svg></div></a></div><div><a target="_self" class="jsx-2769082546 item active" href="/community/tutorials"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 24.22"><path d="M16.23 24.22a2 2 0 0 1-.73-.14L7 20.79a2 2 0 0 1-1.29-1.88v-4a1.5 1.5 0 0 1 3 0v3.36l7.54 2.92 7.54-2.92v-3.45a1.5 1.5 0 0 1 3 0v4.09a2 2 0 0 1-1.29 1.88L17 24.08a2 2 0 0 1-.77.14zm-.35-2.94zm.7 0z"></path><path d="M16.23 13.35a2 2 0 0 1-.62-.1C9.17 11.16 2.36 9 1.61 8.76a2 2 0 0 1-.25-3.87l14-4.78a2 2 0 0 1 1.3 0l14 4.78a2 2 0 0 1 0 3.81l-13.8 4.55a2 2 0 0 1-.63.1zm-.31-3zM5.21 6.74c3.49 1.11 9.07 2.92 11 3.56l10.68-3.53L16 3.05z"></path></svg></div><div class="jsx-2769082546 text">Tutorials</div></a></div><div><a target="_self" class="jsx-2769082546 item" href="/community/data-science-cheatsheets"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 26"><path d="M18.5 26h-13A5.51 5.51 0 0 1 0 20.5v-15A5.51 5.51 0 0 1 5.5 0h13A5.51 5.51 0 0 1 24 5.5v15a5.51 5.51 0 0 1-5.5 5.5zM5.5 3A2.5 2.5 0 0 0 3 5.5v15A2.5 2.5 0 0 0 5.5 23h13a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 18.5 3z"></path><path d="M16 11H8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3zM16 18H8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3z"></path></svg></div><div class="jsx-2769082546 text">Cheat Sheets</div></a></div><div><a target="_self" class="jsx-2769082546 item" href="/community/open-courses"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 34 26"><path d="M28.5 26h-23A5.51 5.51 0 0 1 0 20.5v-15A5.51 5.51 0 0 1 5.5 0h23A5.51 5.51 0 0 1 34 5.5v15a5.51 5.51 0 0 1-5.5 5.5zM5.5 3A2.5 2.5 0 0 0 3 5.5v15A2.5 2.5 0 0 0 5.5 23h23a2.5 2.5 0 0 0 2.5-2.5v-15A2.5 2.5 0 0 0 28.5 3z"></path><path d="M13.5 26a1.5 1.5 0 0 1-1.5-1.5v-22a1.5 1.5 0 0 1 3 0v22a1.5 1.5 0 0 1-1.5 1.5zM27 11h-8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3zM27 18h-8a1.5 1.5 0 0 1 0-3h8a1.5 1.5 0 0 1 0 3z"></path></svg></div><div class="jsx-2769082546 text">Open Courses</div></a></div><div><a target="_self" class="jsx-2769082546 item" href="/community/podcast"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" width="18" viewBox="0 0 18 18"><path d="M9.415 11.077h-.369a2.777 2.777 0 0 1-2.769-2.77V2.77A2.777 2.777 0 0 1 9.047 0h.368a2.777 2.777 0 0 1 2.77 2.77v5.538a2.777 2.777 0 0 1-2.77 2.769zm5.008-7.615c.573 0 1.039.464 1.039 1.038v3.462c0 3.08-2.25 5.64-5.193 6.136v1.825h2.077a1.038 1.038 0 1 1 0 2.077h-6.23a1.038 1.038 0 1 1 0-2.077h2.076v-1.825C5.25 13.602 3 11.042 3 7.962V4.5a1.038 1.038 0 1 1 2.077 0v3.462a4.158 4.158 0 0 0 4.154 4.153 4.158 4.158 0 0 0 4.154-4.153V4.5c0-.574.465-1.038 1.038-1.038z"></path></svg></div><div class="jsx-2769082546 text">Podcast - DataFramed</div></a></div><div><a target="_self" class="jsx-2769082546 item" href="/community/chat"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 16"><g transform="translate(0 -1)"><path id="path-1" d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375h.001zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402h-.001zm-8.423-5.81a1.115 1.115 0 1 0 0-2.229 1.115 1.115 0 0 0 0 2.229zm3.268 0a1.115 1.115 0 1 0 0-2.229 1.115 1.115 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></g></svg></div><div class="jsx-2769082546 text">Chat</div><div class="jsx-2769082546 statusIcon"><svg height="20" xmlns="http://www.w3.org/2000/svg" width="40" viewBox="0 0 40 17"><g fill="none" fill-rule="evenodd"><rect width="40" height="17" fill="#36D57D" rx="4"></rect><text fill="#FFF" font-family="Lato-Bold, Lato" font-size="12" font-weight="bold" letter-spacing=".4"><tspan x="5" y="13">NEW</tspan></text></g></svg></div></a></div></nav></div><div class="jsx-2769082546 section"><h5 class="jsx-2769082546">datacamp</h5><nav class="jsx-2769082546"><div><a target="_self" class="jsx-2769082546 item" href="/community/blog"><div class="jsx-2769082546 image"><svg height="14" id="RÃ©teg_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 17 18"><path id="path-1_1_" d="M12.3 9.8s-.1.1 0 .4c.1.2.2.2-.1.5.2.2.2.3-.1.5 0 .5.1.9-.5 1-.6 0-1.4-.4-1.7.8-.2 1.1-.2.7-.2 1H5.3c.6-1.5 1-3.2 0-4-1.1-1-2.7-4.4.6-6.2.4-.2.8-.3 1.2-.4L6.9 3s1.4-.5 2.7.1v.2c.8.2 1.4.5 1.6.6.5.3 1.2.8 1.2 1.3.1.5-.5.2-.5.2.4.9.4 1.5.2 2.2-.2.7.8 1.4.7 1.9-.1.3-.5.3-.5.3m4.2-7L8.6 0h-.4L.4 2.8c-.3.1-.4.3-.4.6l1.1 10.4c0 .2.1.4.3.4l6.8 3.7c.2.1.4.1.6 0l6.6-3.7c.2-.1.3-.3.3-.4L17 3.4c-.1-.3-.2-.5-.5-.6M8.3 7c-.4 0-.7-.4-.7-.8s.3-.7.7-.7c.4 0 .7.3.7.7 0 .4-.3.8-.7.8zm2.9-1.4l.2-.1c-.3-1-1.2-1.5-1.2-1.5l-.2.2c-.1-.2-.6-.4-.7-.5l.1-.3h-.1c-.6-.3-1.3-.3-2.1 0l.4 1.1c-.6.2-1.1.7-1.1.7l-.6-.4c-.3.5-.5 1.2-.5 1.8h-.8c0 .5.1 1.4.7 2.2l.6-.4c.5.7 1.6 1.3 2.4 1.2V8.1c.3 0 .7-.1.9-.3l.4.6c.4-.1.8-1 .8-1.1l.7.2c.2-.6.2-1.3.1-1.9z"></path></svg></div><div class="jsx-2769082546 text">Official Blog</div></a></div><div><a target="_self" class="jsx-2769082546 item" href="/community/tech"><div class="jsx-2769082546 image"><svg height="14" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 21.75 29.76"><path d="M15.56 22.57a1.5 1.5 0 0 1-1.5-1.5 7.66 7.66 0 0 1 2.47-5.29 7.38 7.38 0 0 0 2.21-5.31A7.48 7.48 0 0 0 11.28 3h-.82a7.47 7.47 0 0 0-5.2 12.83 7.63 7.63 0 0 1 2.42 5.23 1.5 1.5 0 0 1-3 0 4.65 4.65 0 0 0-1.45-3A10.47 10.47 0 0 1 10.47 0h.82a10.47 10.47 0 0 1 7.28 18 4.68 4.68 0 0 0-1.5 3.08 1.5 1.5 0 0 1-1.51 1.49zM16.5 24.26a5.5 5.5 0 0 1-11 0"></path><path d="M10.89 22.56a1.5 1.5 0 0 1-1.5-1.5v-8.84a1.5 1.5 0 0 1 3 0v8.84a1.5 1.5 0 0 1-1.5 1.5z"></path></svg></div><div class="jsx-2769082546 text">Tech Thoughts</div></a></div></nav></div></div><main class="jsx-1028385822 Main"><div class="jsx-2159026896 ActionBar"><div><div class="jsx-3863678361 ActionBarSearch"><button style="font-weight:normal" class="jsx-1844558338 Button extra noPadding"><div class="jsx-1844558338 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.03 23"><path d="M10.39 19.29A9.65 9.65 0 1 1 20 9.65a9.66 9.66 0 0 1-9.61 9.64zm0-17.06a7.42 7.42 0 1 0 7.42 7.42 7.43 7.43 0 0 0-7.42-7.42z"></path><path d="M1.11 23a1.11 1.11 0 0 1-.89-1.78l4.1-5.47a1.11 1.11 0 1 1 1.78 1.34L2 22.56a1.11 1.11 0 0 1-.89.44z"></path></svg></div><div class="jsx-1844558338 desktopOnly">Search</div></button></div></div><div class="jsx-2159026896 authBlock"><div></div><div class="jsx-3196442269 ActionBarAuth"><div class="jsx-3196442269"><a href="https://www.datacamp.com/users/sign_in?redirect=https://www.datacamp.com/community" class="jsx-3196442269"><button class="jsx-1844558338 Button border minWidth"><div class="jsx-1844558338 ">Log in</div></button></a><button class="jsx-1844558338 Button primary"><div class="jsx-1844558338 ">Create Account</div></button></div><div class="jsx-728636942 SubmitAnArticleButton"><button class="jsx-1844558338 Button desktopButton green noPadding"><div class="jsx-1844558338 icon"><svg id="Layer_1" xmlns="http://www.w3.org/2000/svg" viewBox="-90 92 18 18"><path id="a" d="M-80.4 100.4V97c0-.3-.3-.6-.6-.6s-.6.3-.6.6v3.4H-85c-.3 0-.6.3-.6.6s.3.6.6.6h3.4v3.4c0 .3.3.6.6.6s.6-.3.6-.6v-3.4h3.4c.3 0 .6-.3.6-.6s-.3-.6-.6-.6h-3.4zM-81 92c5 0 9 4 9 9s-4 9-9 9-9-4-9-9 4-9 9-9z"></path></svg></div><div class="jsx-1844558338 desktopOnly">Share an Article</div></button><div class="jsx-728636942 mobileButton"><svg xmlns="http://www.w3.org/2000/svg" width="40" height="40" viewBox="0 0 40 40"><path d="M20.86 19.15v-4.822c0-.47-.385-.851-.86-.851s-.86.38-.86.85v4.822h-4.878c-.475 0-.86.381-.86.851s.385.85.86.85h4.877v4.822c0 .47.386.851.861.851s.86-.38.86-.85V20.85h4.878c.475 0 .86-.381.86-.851s-.385-.85-.86-.85h-4.877zM20 0c11.045 0 20 8.953 20 20 0 11.045-8.955 20-20 20C8.953 40 0 31.045 0 20 0 8.953 8.953 0 20 0z"></path></svg></div></div></div></div></div><div class="jsx-1514242801 TitleBar"><div class="jsx-1514242801 filter"><button class="jsx-1844558338 Button iconButton noPadding"><div class="jsx-1844558338 icon"><svg id="RÃ©teg_1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 7 12"><path id="path-1_1_" d="M5.9 0c.4 0 .9.3 1 .7s.1.9-.2 1.2L2.7 6l4 4.1c.3.5.3 1.1-.1 1.6s-1.1.4-1.5.1l-4.8-5c-.4-.4-.4-1.2 0-1.6L5.1.3c.2-.2.5-.3.8-.3z"></path></svg></div><div class="jsx-1844558338 desktopOnly">Back to Tutorials</div></button></div><div class="jsx-1514242801 title"><div class="jsx-3889859319 Title"><div class="jsx-3889859319 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 32 24.22"><path d="M16.23 24.22a2 2 0 0 1-.73-.14L7 20.79a2 2 0 0 1-1.29-1.88v-4a1.5 1.5 0 0 1 3 0v3.36l7.54 2.92 7.54-2.92v-3.45a1.5 1.5 0 0 1 3 0v4.09a2 2 0 0 1-1.29 1.88L17 24.08a2 2 0 0 1-.77.14zm-.35-2.94zm.7 0z"></path><path d="M16.23 13.35a2 2 0 0 1-.62-.1C9.17 11.16 2.36 9 1.61 8.76a2 2 0 0 1-.25-3.87l14-4.78a2 2 0 0 1 1.3 0l14 4.78a2 2 0 0 1 0 3.81l-13.8 4.55a2 2 0 0 1-.63.1zm-.31-3zM5.21 6.74c3.49 1.11 9.07 2.92 11 3.56l10.68-3.53L16 3.05z"></path></svg></div><div class="jsx-3889859319 h1">Tutorials</div></div></div><div class="jsx-1514242801 action"></div></div><div class="jsx-1464850800 Tutorial withRecommend"><div><div><div></div><div class="jsx-undefined social__top desktopOnly"><div class="jsx-undefined voteAndSocial"><div class="jsx-undefined"><a href="#comments" class="jsx-3293774837 CommentCounter"><span class="jsx-3293774837 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></span><span class="jsx-3293774837 count">0</span></a><div class="jsx-1972554161 Upvote"><div class="jsx-1972554161"><div class="jsx-1972554161 normal"><span class="jsx-1972554161 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-1972554161 count">86</span></div><div class="jsx-1972554161 voted"><span class="jsx-1972554161 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-1972554161 count">86</span></div></div></div></div><div class="jsx-494086174 Social vertical"><div class="jsx-494086174 icons"><a href="https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" target="_blank" rel="noopener noreferrer" class="jsx-494086174 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" target="_blank" rel="noopener noreferrer" class="jsx-494086174 icon centerIcon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" target="_blank" rel="noopener noreferrer" class="jsx-494086174 icon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a></div></div></div></div></div><div class="jsx-1464850800 preface"><div class="jsx-1464850800 author"><div class="jsx-566588255 Author"><a href="/profile/karlijn" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Karlijn Willems</div><div class="jsx-566588255 date"><span>March 15th, 2017</span></div></div></a></div></div><div class="jsx-1464850800 tags"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">python</span></div><a class="jsx-1022557955 more">+<!-- -->4</a></div></div><h1 class="jsx-1464850800 pageTitle">Python Exploratory Data Analysis Tutorial</h1><div class="jsx-1464850800 description pageDescription">Learn the basics of Exploratory Data Analysis (EDA) in Python with Pandas, Matplotlib and NumPy, such as sampling, feature engineering, correlation, etc.</div></div><div class="markdown"><div>
<p>As you will know by now, the Python data manipulation library Pandas is used for data manipulation; For those who are just starting out, this might imply that this package can only be handy when preprocessing data, but much less is true: Pandas is also great to explore your data and to store it after youâ€™re done preprocessing the data.</p>

<p>Additionally, for those who have been following DataCampâ€™s Python tutorials or that have already been introduced to the basics of SciPy, NumPy, Matplotlib and Pandas, it might be a good idea to recap some of the knowledge that you have built up.</p>

<p>Todayâ€™s tutorial will actually introduce you to some ways to explore your data efficiently with all the above packages so that you can start modeling your data:</p>

<nav>
<ul>
	<li>Youâ€™ll first learn how to <a href="#import">import data</a>, which is the first step that you need to complete successfully before you can start your analysis.</li>
	<li>If you're not sure what <a href="#eda">Exploratory Data Analysis (EDA)</a> is and what the exact difference between EDA and Data Mining is, this section will explain it for you before you start the tutorial!</li>
	<li>Then, youâ€™ll get a <a href="#description">basic description</a> of your data. Youâ€™ll focus on getting some descriptive statistics, checking out the first and last rows of your DataFrame, retrieving samples from your data, etc. Youâ€™ll see that this is a great way to get an initial feeling with your data and maybe understand it a bit better already!</li>
	<li>After gathering some information on your data, it might also be a good idea to also take a deeper look at it by <a href="#closer">querying</a> or indexing the data. You can use this technique to test some of the basic hypotheses that you might have about the data.</li>
	<li>Now that you have inspected your data, you'll probably already see that there are some <a href="#features">features </a> that can be of interest to your analysis: you'll see which ones can influence your analysis positively with feature engineering and feature selection.</li>
	<li>Next, youâ€™ll see that an initial exploration is good, but you will also need to have an idea of the <a href="#challenges">challenges</a> that your data can pose, such as missing values or outliers, and, of course, how you can handle those challenges, and</li>
	<li>Lastly, youâ€™ll also learn how to discover <a href="#patterns">patterns</a> in your data, by either visualizing your data easily and quickly with the Python data visualization packages Matplotlib and Bokeh, or by using specific functions to compute the correlation between attributes.</li>
</ul>

<div id="scoped-content">
<style type="text/css">:target:before {
content:"";
display:block;
height:150px;
margin:-150px 0 0;
}
h3 {font-weight:normal;
margin-top:.5em}
h4 {
font-weight:lighter
}
</style>
<br />
<p>Are you interested in taking a Pandas course? Consider taking one of our three courses that we have made in collaboration with Continuum Analytics, the creator and driving force behind Anaconda, such as the <a href="https://www.datacamp.com/courses/pandas-foundations/">Pandas Foundations course</a>!</p>

<h2 id="import">Importing The Data</h2>

<p>To start exploring your data, youâ€™ll need to start by actually loading in your data. Youâ€™ll probably know this already, but thanks to the Pandas library, this becomes an easy task: you import the package as <code>pd</code>, following the convention, and you use the <code>read_csv()</code> function, to which you pass the URL in which the data can be found and a <code>header</code> argument. This last argument is one that you can use to make sure that your data is read in correctly: the first row of your data wonâ€™t be interpreted as the column names of your DataFrame.</p>

<p>Alternatively, there are also other arguments that you can specify to ensure that your data is read in correctly: you can specify the delimiter to use with the <code>sep</code> or <code>delimiter</code> arguments, the column names to use with <code>names</code> or the column to use as the row labels for the resulting DataFrame with <code>index_col</code>.</p>

<p>But these are not nearly all the arguments that you can add to the <code>read_csv()</code> function. Read up on this function and its arguments in the <a href="http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html">documentation</a>.</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInNhbXBsZSI6IiMgSW1wb3J0IHRoZSBgcGFuZGFzYCBsaWJyYXJ5IGFzIGBwZGBcbmltcG9ydCBwYW5kYXMgYXMgcGRcblxuIyBMb2FkIGluIHRoZSBkYXRhIHdpdGggYHJlYWRfY3N2KClgXG5kaWdpdHMgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL29wdGRpZ2l0cy9vcHRkaWdpdHMudHJhXCIsXG4gICAgICAgICAgICAgICAgICAgICBoZWFkZXI9Tm9uZSlcblxuIyBQcmludCBvdXQgYGRpZ2l0c2BcbnByaW50KGRpZ2l0cykifQ==</div>
<br /><br />
<p>Note that in this case, you made use of <code>read_csv()</code> because the data happens to be in a comma-separated format. If you have files that have another separator, you can also consider using other functions to load in your data, such as <code>read_table()</code>, <code>read_excel()</code>, <code>read_fwf()</code> and <code>read_clipboard</code>, to read in general delimited files, Excel files, Fixed-Width Formatted data and data that was copied to the Clipboard, respectively.</p>

<p>Also, youâ€™ll find <code>read_sql()</code> as one of the options to read in an SQL query or a database table into a DataFrame. For even more Input functions, consider <a href="http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#input-output">this section</a> of the Pandas documentation.</p>

<p><a href="https://www.datacamp.com/courses/" target="_blank"><img alt="Learn Python for Data Science With DataCamp" src="http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png" /></a></p>

<h2 id="eda">What is Exploratory Data Analysis (EDA)?</h2>

<p>Exploratory Data Analysis (EDA) is used on the one hand to answer questions, test business assumptions, generate hypotheses for further analysis. On the other hand, you can also use it to prepare the data for modeling. The thing that these two probably have in common is a good knowledge of your data to either get the answers that you need or to develop an intuition for interpreting the results of future modeling.</p>

<p>There are a lot of ways to reach these goals: you can get a basic description of the data, visualize it, identify patterns in it, identify challenges of using the data, etc.</p>

<p>One of the things that youâ€™ll often see when youâ€™re reading about EDA is Data profiling. Data profiling is concerned with summarizing your dataset through descriptive statistics. You want to use a variety of measurements to better understand your dataset. The goal of data profiling is to have a solid understanding of your data so you can afterwards start querying and visualizing your data in various ways. However, this doesnâ€™t mean that you donâ€™t have to iterate: exactly because data profiling is concerned with summarizing your dataset, it is frequently used to assess the data quality. Depending on the result of the data profiling, you might decide to correct, discard or handle your data differently.</p>

<p>Youâ€™ll learn more about data profiling in a next post.</p>

<h3>EDA And Data Mining (DM)</h3>

<p>EDA distinguishes itself from data mining, even though the two are closely related, as many EDA techniques have been adopted into data mining. Also the goals of the two are very similar: EDA indeed makes sure that you explore the data in such a way that interesting features and relationships between features will become more clear. In EDA, you typically explore and compare many different variables with a variety of techniques to search and find systematic patterns. Data mining, on the other hand, is concerned with extracting patterns from the data. Those patterns provide insights into relationships between variables that can be used to improve business decisions. Also, in both cases, you have no a priori expectations or expectations that are not complete about the relations between the variables.</p>

<p>However, in general, Data Mining can be said to be more application-oriented, while EDA is concerned with the basic nature of the underlying phenomena. In other words, Data Mining is relatively less concerned with identifying the specific relations between the involved variables. As a result, Data Mining accepts a â€œblack boxâ€ approach to data exploration and doesnâ€™t only use techniques that are also used in EDA but also techniques such as Neural Networks to generate valid predictions but donâ€™t identify the specific nature of the relationships between the variables on which the predictions are based.</p>

<h2 id="description">Basic Description of the Data</h2>

<p>Like you read above, EDA is all about getting to know your data. One of the most elementary steps to do this is by getting a basic description of your data. A basic description of your data is indeed a very broad term: you can interpret it as a quick and dirty way to get some information on your data, as a way of getting some simple, easy-to-understand information on your data, to get a basic feel for your data, etc.</p>

<p>This section wonâ€™t make a distinction between these interpretations: it will indeed introduce you to some of the ways that you can quickly gather information on your DataFrame that is easy to understand.</p>

<div class="section level3" id="describing-the-data">
<h3>Describing The Data</h3>

<p>For example, you can use the <code>describe()</code> function to get various summary statistics that exclude NaN values. Consider this example in which you describe the famous <a href="https://archive.ics.uci.edu/ml/datasets/Iris">Iris dataset</a>. The data has already been loaded in for you in the DataCamp Light chunk:</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiaXJpcy5kZXNjcmliZSgpIn0=</div>
<br /><br />
<p>You see that this function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data. Note that, of course, there are many packages available in Python that can give you those statistics, including Pandas itself. Using this function is just one of the ways to get this information.</p>

<p>Also note that you certainly need to take the time to dive deeper into the descriptive statistics if you havenâ€™t done this yet. You can use these descriptive statistics to begin to assess the quality of your data. Then youâ€™ll be able to decide whether you need to correct, discard or deal with the data in anohter way. This is usually the data profiling step. This step in the EDA is meant to understand the data elements and its anomalies a bit better and to see how the data matches the documentation on the one hand and accommodates to the business needs on the other hand.</p>

<p><strong>Note</strong> that youâ€™ll come back to the data profiling step as you go through your exploratory data analysis, as the quality of your data can be impacted by the steps that youâ€™ll go through.</p>
</div>

<div class="section level3" id="first-and-last-dataframe-rows">
<h3>First and Last DataFrame Rows</h3>

<p>Now that you have got a general idea about your data set, itâ€™s also a good idea to take a closer look at the data itself. With the help of the <code>head()</code> and <code>tail()</code> functions of the Pandas library, you can easily check out the first and last lines of your DataFrame, respectively.</p>

<p>Inspect the first and last five rows of the handwritten digits data with the <code>head()</code> and <code>tail()</code> functions in the DataCamp Light chunk below. The data has already been loaded in for you in the DataCamp Light chunk:</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBJbnNwZWN0IHRoZSBmaXJzdCA1IHJvd3Mgb2YgYGRpZ2l0c2BcbmZpcnN0ID0gZGlnaXRzLl9fX19fKDUpXG5cbiMgSW5zcGVjdCB0aGUgbGFzdCA1IHJvd3Ncbmxhc3QgPSBkaWdpdHMuX19fXyg1KSIsInNvbHV0aW9uIjoiIyBJbnNwZWN0IHRoZSBmaXJzdCA1IHJvd3Mgb2YgYGRpZ2l0c2BcbmZpcnN0ID0gZGlnaXRzLmhlYWQoNSlcblxuIyBJbnNwZWN0IHRoZSBsYXN0IDUgcm93c1xubGFzdCA9IGRpZ2l0cy50YWlsKDUpIiwic2N0IjoidGVzdF9vYmplY3QoXCJmaXJzdFwiKVxudGVzdF9vYmplY3QoXCJsYXN0XCIpXG5zdWNjZXNzX21zZyhcIkFtYXppbmdseSBkb25lIVwiKSJ9</div>
<br /><br />
<p>Youâ€™ll see that the result of the <code>head()</code> and <code>tail()</code> functions doesnâ€™t quite say much when youâ€™re not familiar with this kind of data.</p>

<p>You might just see a bunch of rows and columns with numerical values in them. Consider reading up on the <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.names">data set description</a> if you havenâ€™t done so already, which will give you relevant information on how the data was collected and also states the number of attributes and rows, which can be handy to check whether you have imported the data correctly.</p>

<p>Additionally, go back to your initial finding: the numerical values in the rows. At first sight, you might not think that there is a problem, as the integer values appear to be correct and donâ€™t raise any flags when youâ€™re looking at it at first.</p>

<p>But if you would have done all of this on another data set that you had in front of you and that might have had, for example, date time information, a quick glance on the result of these lines of code might have raised the following questions: â€œHas my data been read in as a DateTime?â€, â€œHow can I check this?â€ and â€œHow can I change the data type?â€.</p>

<p>These are deeper questions that youâ€™ll typically address in the data profiling step, which will be addressed in a next post.</p>
</div>

<div class="section level3" id="sampling-the-data">
<h3>Sampling The Data</h3>

<p>If you have a large dataset, you might consider taking a sample of your data as an easy way to get a feel for your data quickly. As a first and easy way to do this, you can make use of the <code>sample()</code> function that is included in Pandas, just like this:</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBUYWtlIGEgc2FtcGxlIG9mIDVcbmRpZ2l0cy5zYW1wbGUoNSkiLCJzb2x1dGlvbiI6IiMgVGFrZSBhIHNhbXBsZSBvZiA1XG5kaWdpdHMuc2FtcGxlKDUpIiwic2N0IjoiY2hlY2tfb3V0cHV0X2NvbnRhaW5zKFwiZGlnaXRzLnNhbXBsZSg1KVwiLCAxKSJ9</div>
<br /><br />
<p>Another -perhaps more complicated- way to do this is by creating a random index and then get random rows from your DataFrame. Youâ€™ll see that the code below makes use the <code>random</code> package that has a module <code>sample</code> that will allow you to sample your data, in combination with <code>range()</code> and <code>len()</code>. Note that you also make use of <code>ix</code> to select the exact rows of your DataFrame that you want to include in your sample.</p>

<p>If you donâ€™ have an idea of why you use <code>ix</code> in this context, DataCampâ€™s more specific tutorial can be of help! It covers these more general topics in detail. Go and check it out by clicking on the link that has been included above!</p>

<p>For now, letâ€™s practice our Python skills! Get started on the exercise below:</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IG51bXB5IGFzIG5wXG5pbXBvcnQgcGFuZGFzIGFzIHBkXG5kaWdpdHMgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL29wdGRpZ2l0cy9vcHRkaWdpdHMudHJhXCIsXG4gICAgICAgICAgICAgICAgICAgICBoZWFkZXI9Tm9uZSkiLCJzYW1wbGUiOiIjIGltcG9ydCBgc2FtcGxlYCBmcm9tIGByYW5kb21gXG5mcm9tIHJhbmRvbSBpbXBvcnQgX19fX19fXG5cbiMgQ3JlYXRlIGEgcmFuZG9tIGluZGV4XG5yYW5kb21JbmRleCA9IG5wLmFycmF5KHNhbXBsZShyYW5nZShsZW4oX19fX19fKSksIDUpKVxuXG4jIEdldCA1IHJhbmRvbSByb3dzXG5kaWdpdHNTYW1wbGUgPSBkaWdpdHMuaXhbX19fX19fX19fX19dXG5cbiMgUHJpbnQgdGhlIHNhbXBsZVxucHJpbnQoX19fX19fX19fX19fKSIsInNvbHV0aW9uIjoiIyBpbXBvcnQgYHNhbXBsZWAgZnJvbSBgcmFuZG9tYFxuZnJvbSByYW5kb20gaW1wb3J0IHNhbXBsZVxuXG4jIENyZWF0ZSBhIHJhbmRvbSBpbmRleFxucmFuZG9tSW5kZXggPSBucC5hcnJheShzYW1wbGUocmFuZ2UobGVuKGRpZ2l0cykpLCA1KSlcblxuIyBHZXQgNSByYW5kb20gcm93c1xuZGlnaXRzU2FtcGxlID0gZGlnaXRzLml4W3JhbmRvbUluZGV4XVxuXG4jIFByaW50IHRoZSBzYW1wbGVcbnByaW50KGRpZ2l0c1NhbXBsZSkiLCJzY3QiOiJ0ZXN0X2ltcG9ydChcInJhbmRvbS5zYW1wbGVcIilcbnRlc3Rfb2JqZWN0KFwicmFuZG9tSW5kZXhcIilcbnRlc3Rfb2JqZWN0KFwiZGlnaXRzU2FtcGxlXCIpXG50ZXN0X2Z1bmN0aW9uKFwicHJpbnRcIikifQ==</div>
</div>
</div>
<br /><br />
<div class="section level2" id="a-closer-look-at-your-data-queries">
<h2 id="closer">A Closer Look At Your Data: Queries</h2>

<p>Now that you have taken a quick look at your data and have seen what itâ€™s about, youâ€™re ready to dive a little bit deeper: itâ€™s time to inspect the data further by querying the data.</p>

<p>This goes easily with the <code>query()</code> function, which allows you to test some very simple hypotheses that you have about your data, such as â€œIs the petal length usually greater than the sepal length?â€ or â€œIs the petal length sometimes equal to the sepal length?â€.</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiIyBQZXRhbCBsZW5ndGggZ3JlYXRlciB0aGFuIHNlcGFsIGxlbmd0aD9cbmlyaXMucXVlcnkoJ1BldGFsX2xlbmd0aCA+IFNlcGFsX2xlbmd0aCcpXG5cbiMgUGV0YWwgbGVuZ3RoIGVxdWFscyBzZXBhbCBsZW5ndGg/XG5pcmlzLnF1ZXJ5KCdQZXRhbF9sZW5ndGggPT0gU2VwYWxfbGVuZ3RoJykifQ==</div>

<p>Youâ€™ll see that this hypothesis doesnâ€™t hold. You get an empty DataFrame back as a result.</p>

<p><strong>Note</strong> that this function can also be expressed as <code>iris[iris.Petal_length &gt; iris.Sepal_length]</code>.</p>
</div>

<div class="section level2" id="the-challenges-of-your-data">
<h2 id="challenges">The Challenges of Your Data</h2>

<p>Now that youâ€™ve gathered some basic information on your data, itâ€™s a good idea to just go a little bit deeper into the challenges that your data might pose. If you have already gone through the data profiling step, youâ€™ll be aware of missing values, youâ€™ll have an idea of which values might be outliers, etc.</p>

<p>This section will describe some of the basic ways to already get an idea of these things and will describe how you can handle the data in case you do find irregularities in your data. Note once again that you will go or have gone deeper into identifying these irregularities in the data profiling step, and that itâ€™s normal to return to this step once you have handled some of the challenges that your data poses.</p>

<div class="section level3" id="missing-values">
<h3>Missing Values</h3>

<p>Something that you also might want to check when youâ€™re exploring your data is whether or not the data set has any missing values.</p>

<p>Examining this is important because when some of your data is missing, the data set can lose expressiveness, which can lead to weak or biased analyses. Practically, this means that when youâ€™re missing values for certain features, the chances of your classification or predictions for the data being off only increase.</p>

<p>Of course, the cause of you missing data in your data set can be the result of a faulty extraction or import of the data, or it might be the result of the collection process. The systems that give you the data might malfunction or the survey that you sent out might have some blanks left my the respondents. It's very important to consider also whether there is a pattern in the missing data, and this is something where the data profiling step can be useful. Remember that you can use data profiling to get a better idea of your data quality. You can read more about how you can discover patterns of missing data in a follow-up post.
 </p>

<p>In short, the causes of missing data can be various and largely depend on the data context, but can also depend on yourself. Thatâ€™s why you have first inspected your data when you imported it in one of the previous steps!</p>

<p>To identify the rows that contain missing values, you can use <code>isnull()</code>. In the result that youâ€™ll get back, youâ€™ll see <code>True</code> or <code>False</code> appearing in each cell: <code>True</code> will indicate that the value contained within the cell is a missing value, <code>False</code> means that the cell contains a â€˜normalâ€™ value.</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBJZGVudGlmaXkgbWlzc2luZyB2YWx1ZXNcbnBkLmlzbnVsbChfX19fX18pIiwic29sdXRpb24iOiIjIElkZW50aWZpeSBtaXNzaW5nIHZhbHVlc1xucGQuaXNudWxsKGRpZ2l0cykiLCJzY3QiOiJ0ZXN0X2Z1bmN0aW9uKFwicGFuZGFzLmlzbnVsbFwiLCBpbmNvcnJlY3RfbXNnPVwiRGlkIHlvdSBwYXNzIGBkaWdpdHNgIHRvIGBwZC5pc251bGwoKWA/XCIsIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwYXNzIGBkaWdpdHNgIHRvIGBwZC5pc251bGwoKWA/XCIpXG5zdWNjZXNzX21zZyhcIldlbGwgZG9uZSFcIikifQ==</div>
<br /><br />
<p>In this case, you see that the data is quite complete: there are no missing values.</p>

<p><strong>Note</strong> that you could have also read this in the data set description of the UCI Machine Learning Repository which was linked above, where youâ€™ll have seen that there are no missing values listed for the data.</p>

<p>However, this will not be the case in every data set that youâ€™ll come across. Thatâ€™s why itâ€™s good to know what you can do when you do run across a situation where you need to think about what you want to be doing with the missing data.</p>

<ul>
	<li>You can delete the missing data: you either delete the whole record or you can just keep the records in which the features of interest are still present. Of course, you have to be careful with this procedure, as deleting data might also bias your analysis. Thatâ€™s why you should ask yourself the question of whether the probability of certain data that is missing for a record is the same as for all other records. If the probability doesnâ€™t vary record-per-record, deleting the missing data is a valid option.</li>
	<li>Besides deletion, there are also methods that you can use to fill up cells if they contain missing values with so-called â€œimputation methodsâ€. If you already have a lot of experience with statistics, youâ€™ll know that imputation is the process of replacing missing data with substituted values. You can either fill in the mean, the mode or the median. Of course, here you need to think about whether you want to take, for example, the mean or median for all missing values of a variable, or whether you want to replace the missing values based on another variable. For example, for data in which you have records that have features with categorical variables such as â€œmaleâ€ or â€œfemaleâ€, you might also want to consider those before replacing the missing values, as the observations might differ from males and females. If this is the case, you might just calculate the average of the female observations and then fill out the missing values for other â€œfemaleâ€ records with this average.</li>
	<li>Estimate the value with the help of regression, ANOVA, logistic regression or another modelling technique. This is by far the most complex way to fill in the values.</li>
	<li>You fill in the cells with values of records that are most similar to the one that has missing values. You can use KNN or K-Nearest Neighbors in cases such as these.</li>
</ul>
<br />
<p>Note that there are advantages and drawbacks to every one of the above ways to fill in missing data! Youâ€™ll want to consider things such as time, expense, the nature of your data, etc. before making a final decision on this.</p>

<p>When you have made a final decision on what youâ€™re going to do with the missing data, read on to see how you can implement the changes that you want to see in your data.</p>

<div class="section level4" id="filling-missing-values">
<h4>Filling Missing Values</h4>

<p>If you do decide to fill in the values with imputation, you can still choose how you want to make this happen!</p>

<p>Make use of Pandas <code>fillna()</code> in combination with the functions that NumPy has to offer. Consider the following code chunk, in which you supposedly have a DataFrame with the results of a survey that asks for peopleâ€™s salary. Assuming a context where your audience are all from the same class in society and the likelihood of the respondents answering to the question is the same for every person, you can opt to calculate the mean of the people that did answer the question and use that mean to fill in the values of people that didnâ€™t answer.</p>

<pre>
<code># Import NumPy
import numpy as np

# Calculate the mean
mean = np.mean(df.Salary)

# Replace missing values with the mean
df. = df.Salary.fillna(mean)</code></pre>

<p>Of course, you donâ€™t necessarily need to pass in a value to <code>fillna()</code>. You can also propagate non-null values forward or backward by adding the argument <code>method</code> to the <code>fillna()</code> function. Pass in <code>ffill</code> or <code>bfill</code> to specify you want to fill the values backward or forward.</p>
</div>

<div class="section level4" id="drop-labels-with-missing-values">
<h4>Drop Labels With Missing Values</h4>

<p>To exclude columns or rows that contain missing values, you can make use of Pandasâ€™ <code>dropna()</code> function:</p>

<pre>
<code># Drop rows with missing values
df.dropna(axis=0)

# Drop columns with missing values 
df.dropna(axis=1)</code></pre>
</div>

<div class="section level4" id="interpolation">
<h4>Interpolation</h4>

<p>Alternatively, you can also choose to interpolate missing values: the <code>interpolate()</code> function will perform a linear interpolation at the missing data points to â€œguessâ€ the value that is most likely to be filled in.</p>

<pre>
<code>df.interpolate()</code></pre>

<p>You can also add the <code>method</code> argument to gain access to fancier interpolation methods, such as polynomial interpolation or cubic interpolation, but when you want to use these types of interpolation, youâ€™ll need to have SciPy installed.</p>

<p>Of course, there are limits to the interpolation, especially if the NaN values for interpolation are too far from the last valid observation. In such cases, you want to add a <code>limit</code> argument to the original code. You pass a positive integer to it and this number will determine how many values after a non-NaN value will be filled out. The default limit direction is forward, but also this you can change by adding <code>limit_direction</code></p>
</div>
</div>

<div class="section level3" id="outliers">
<h3>Outliers</h3>

<p>Just like missing values, your data might also contain values that diverge heavily from the big majority of your other data. These data points are called â€œoutliersâ€. To find them, you can check the distribution of your single variables by means of a box plot or you can make a scatter plot of your data to identify data points that donâ€™t lie in the â€œexpectedâ€ area of the plot.</p>

<p>The causes for outliers in your data might vary, going from system errors to people interfering with the data through data entry or data processing, but itâ€™s important to consider the effect that they can have on your analysis: they will change the result of statistical tests such as standard deviation, mean or median, they can potentially decrease the normality and impact the results of statistical models, such as regression or ANOVA.</p>

<p>To deal with outliers, you can either delete, transform, or impute them: the decision will again depend on the data context. Thatâ€™s why itâ€™s again important to understand your data and identify the cause for the outliers:</p>

<ul>
	<li>If the outlier value is due to data entry or data processing errors, you might consider deleting the value.</li>
	<li>You can transform the outliers by assigning weights to your observations or use the natural log to reduce the variation that the outlier values in your data set cause.</li>
	<li>Just like the missing values, you can also use imputation methods to replace the extreme values of your data with median, mean or mode values.</li>
</ul>
<br />
<p>You can use the functions that were described in the above section to deal with outliers in your data.</p>
</div>

<div class="section level3" id="your-datas-features">
<h2 id="features">Your Dataâ€™s Features</h2>

<p><strong>Note</strong> that this step is one that you do iteratively with other data science tasks: youâ€™ll build your models and validate, but after, you might decide to adjust the features and iterate on building the model again, etc.</p>
</div>
</div>

<div class="section level2" id="feature-engineering">
<h3>Feature Engineering</h3>

<p>You can use feature engineering as a way to increase the predictive power of learning algorithms by creating features from raw data that will help the learning process. Youâ€™ll do this by creating additional relevant features from the existing raw features in the data.</p>

<p>Feature engineering is something that will cost some time to get the hang of; Itâ€™s not always clear what you can do with the raw data so that you can help the predictive power of the data. But maybe the following list can provide some help when youâ€™re looking for ways to engineer features for your dataset:</p>

<ul>
	<li>Factorize a feature: encode categorical variables into numerical ones with <code>factorize()</code>, like in this example:</li>
</ul>
<br />
<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiIyBGYWN0b3JpemUgdGhlIHZhbHVlcyBcbmxhYmVscyxsZXZlbHMgPSBwZC5mYWN0b3JpemUoaXJpcy5DbGFzcylcblxuIyBTYXZlIHRoZSBlbmNvZGVkIHZhcmlhYmxlcyBpbiBgaXJpcy5DbGFzc2BcbmlyaXMuQ2xhc3MgPSBsYWJlbHNcblxuIyBQcmludCBvdXQgdGhlIGZpcnN0IHJvd3NcbmlyaXMuQ2xhc3MuaGVhZCgpIn0=</div>
<br /><br />
<ul>
	<li>Bin continuous variables in groups: use <code>cut()</code> to cut the values for a column in bins</li>
</ul>
<br />
<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5XG51cmwgPSBcImh0dHBzOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9waW1hLWluZGlhbnMtZGlhYmV0ZXMvcGltYS1pbmRpYW5zLWRpYWJldGVzLmRhdGFcIlxubmFtZXMgPSBbJ3ByZWcnLCAncGxhcycsICdwcmVzJywgJ3NraW4nLCAndGVzdCcsICdtYXNzJywgJ3BlZGknLCAnYWdlJywgJ2NsYXNzJ11cbmRmID0gcGQucmVhZF9jc3YodXJsLCBuYW1lcz1uYW1lcylcbmFycmF5ID0gZGYudmFsdWVzXG5YID0gYXJyYXlbOiwwOjhdXG5ZID0gYXJyYXlbOiw4XSIsInNhbXBsZSI6IiMgRGVmaW5lIHlvdXIgb3duIGJpbnNcbm15YmlucyA9IHJhbmdlKDAsIGRmLmFnZS5tYXgoKSwgMTApXG5cbiMgQ3V0IHRoZSBkYXRhIHdpdGggdGhlIGhlbHAgb2YgdGhlIGJpbnNcbmRmWydhZ2VfYnVja2V0J10gPSBwZC5jdXQoZGYuYWdlLCBiaW5zPW15YmlucylcblxuIyBDb3VudCB0aGUgbnVtYmVyIG9mIHZhbHVlcyBwZXIgYnVja2V0XG5kZlsnYWdlX2J1Y2tldCddLnZhbHVlX2NvdW50cygpIn0=</div>
<br /><br />
<ul>
	<li>Scale features: center your data around 0. You can make use of Scikit-Learnâ€™s preprocessing module:</li>
</ul>
<br />
<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5XG51cmwgPSBcImh0dHBzOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9waW1hLWluZGlhbnMtZGlhYmV0ZXMvcGltYS1pbmRpYW5zLWRpYWJldGVzLmRhdGFcIlxubmFtZXMgPSBbJ3ByZWcnLCAncGxhcycsICdwcmVzJywgJ3NraW4nLCAndGVzdCcsICdtYXNzJywgJ3BlZGknLCAnYWdlJywgJ2NsYXNzJ11cbmRhdGFmcmFtZSA9IHBkLnJlYWRfY3N2KHVybCwgbmFtZXM9bmFtZXMpXG5hcnJheSA9IGRhdGFmcmFtZS52YWx1ZXNcblggPSBhcnJheVs6LDA6OF1cblkgPSBhcnJheVs6LDhdIiwic2FtcGxlIjoiZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyXG5cbnNjYWxlciA9IFN0YW5kYXJkU2NhbGVyKCkuZml0KFgpXG5cbnJlc2NhbGVkWCA9IHNjYWxlci50cmFuc2Zvcm0oWCkifQ==</div>
<br /><br />
<p><strong>Tip</strong>: look into the preprocessing module of Scikit-Learn more closely, youâ€™ll see that it contains some handy functions that will help you to come up with new features for your data!</p>

<p>Note that these are just some of the ways in which you can engineer new features to make your data more predictive! The key is to brainstorm new features or combine old features together and try to test their effectiveness with Scikit-Learn.</p>
</div>

<div class="section level2" id="feature-selection">
<h3>Feature Selection</h3>

<p>When you select features, you select the key subset of original data features in an attempt to reduce the dimensionality of the training problem. This seems very similar to other dimensionality reduction techniques that you might already know, such as PCA. Yet, there is a difference: PCA combines similar (correlated) attributes and creates new ones that are considered superior to the original attributes of the dataset. Feature selection doesnâ€™t combine attributes: it evaluates the quality and predictive power and selects the best set.</p>

<p>To find important features, you can make use of the RandomForest algorithm: it randomly generates thousands of decision trees and takes turns leaving out each variable in fitting the model. This way, you can calculate how much better or worse a model does when you leave one variable out of the equation. You can use the Scikit-Learn Python library to implement this algorithm:</p>

<div data-datacamp-exercise data-encoded="true" data-height="500">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiIyBJbXBvcnQgYFJhbmRvbUZvcmVzdENsYXNzaWZpZXJgXG5mcm9tIHNrbGVhcm4uZW5zZW1ibGUgaW1wb3J0IFJhbmRvbUZvcmVzdENsYXNzaWZpZXJcblxuIyBJc29sYXRlIERhdGEsIGNsYXNzIGxhYmVscyBhbmQgY29sdW1uIHZhbHVlc1xuWCA9IGlyaXMuaWxvY1s6LDA6NF1cblkgPSBpcmlzLmlsb2NbOiwtMV1cbm5hbWVzID0gaXJpcy5jb2x1bW5zLnZhbHVlc1xuXG4jIEJ1aWxkIHRoZSBtb2RlbFxucmZjID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpXG5cbiMgRml0IHRoZSBtb2RlbFxucmZjLmZpdChYLCBZKVxuXG4jIFByaW50IHRoZSByZXN1bHRzXG5wcmludChcIkZlYXR1cmVzIHNvcnRlZCBieSB0aGVpciBzY29yZTpcIilcbnByaW50KHNvcnRlZCh6aXAobWFwKGxhbWJkYSB4OiByb3VuZCh4LCA0KSwgcmZjLmZlYXR1cmVfaW1wb3J0YW5jZXNfKSwgbmFtZXMpLCByZXZlcnNlPVRydWUpKSJ9</div>
<br /><br />
<p>Youâ€™ll see that the best feature set is one that includes the petal length and petal width data.</p>

<p><a href="https://www.datacamp.com/courses/" target="_blank"><img alt="Exploratory Data Analysis with Python" src="http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png" /></a></p>

<p><strong>Note</strong> that you can also visualize the results of the feature selection with Matplotlib:</p>

<pre>
<code># Import `pyplot` and `numpy`
import matplotlib.pyplot as plt
import numpy as np

# Isolate feature importances 
importance = rfc.feature_importances_

# Sort the feature importances 
sorted_importances = np.argsort(importance)

# Insert padding
padding = np.arange(len(names)-1) + 0.5

# Plot the data
plt.barh(padding, importance[sorted_importances], align='center')

# Customize the plot
plt.yticks(padding, names[sorted_importances])
plt.xlabel(&quot;Relative Importance&quot;)
plt.title(&quot;Variable Importance&quot;)

# Show the plot
plt.show()</code></pre>
<br />
<p><img alt="Feature selection Pandas" src="http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/427/content_image1_pandas.png" /></p>
</div>
<br />
<div class="section level2" id="patterns-in-your-data">
<h2 id="patterns">Patterns In Your Data</h2>

<p>One of the next steps that you can take in the exploration of your data is the identification of patterns in your data, which includes correlation between data attributes or between missing data. One of the things that can help in doing this is the visualization of your data; And this doesnâ€™t need to be static: dare to go for interactive visualizations of your data with the Python libraries Bokeh or Plotly.</p>

<div class="section level3" id="correlation-identification-with-matplotlib">
<h3>Correlation Identification With Matplotlib</h3>

<p>Now that you have looked at the numbers and analyzed your data in a quantitative way, youâ€™ll also find it useful to consider you data in a visual way. Itâ€™s time to also explore the data visually.</p>

<p>To easily and quickly do this, you can make use of the Python data visualization library Matplotlib. The only thing that stands in your way is, ironically, your data: as you are well aware, your data has 64 columns or features. When you have so many features, itâ€™s said that youâ€™re working with high dimensional data.</p>

<p>What dimensional data exactly is, youâ€™ll learn in our machine learning tutorial, but for now itâ€™s good to understand that, if you want to visualize your data in a 2D or 3D plot, youâ€™ll need your data to only have two or three dimensions. This means that youâ€™ll need to reduce your dataâ€™s dimensions.</p>

<p>This means that youâ€™ll have to make use of Dimensionality Reduction techniques, such as Principal Component Analysis (PCA):</p>

<div data-datacamp-exercise data-encoded="true" data-height="350">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBJbXBvcnQgYFBDQWAgZnJvbSBgc2tsZWFybi5kZWNvbXBvc2l0aW9uYFxuZnJvbSBza2xlYXJuLmRlY29tcG9zaXRpb24gaW1wb3J0IF9fX1xuXG4jIEJ1aWxkIHRoZSBtb2RlbFxucGNhID0gUENBKG5fY29tcG9uZW50cz0yKVxuXG4jIFJlZHVjZSB0aGUgZGF0YSwgb3V0cHV0IGlzIG5kYXJyYXlcbnJlZHVjZWRfZGF0YSA9IHBjYS5maXRfdHJhbnNmb3JtKF9fX19fX18pXG5cbiMgSW5zcGVjdCB0aGUgc2hhcGUgb2YgYHJlZHVjZWRfZGF0YWBcbnJlZHVjZWRfZGF0YS5fX19fX19cblxuIyBwcmludCBvdXQgdGhlIHJlZHVjZWQgZGF0YVxucHJpbnQoX19fX19fX19fX19fX19fKSIsInNvbHV0aW9uIjoiIyBJbXBvcnQgYFBDQWAgZnJvbSBgc2tsZWFybi5kZWNvbXBvc2l0aW9uYFxuZnJvbSBza2xlYXJuLmRlY29tcG9zaXRpb24gaW1wb3J0IFBDQVxuXG4jIEJ1aWxkIHRoZSBtb2RlbFxucGNhID0gUENBKG5fY29tcG9uZW50cz0yKVxuXG4jIFJlZHVjZSB0aGUgZGF0YSwgb3V0cHV0IGlzIG5kYXJyYXlcbnJlZHVjZWRfZGF0YSA9IHBjYS5maXRfdHJhbnNmb3JtKGRpZ2l0cylcblxuIyBJbnNwZWN0IHNoYXBlIG9mIHRoZSBgcmVkdWNlZF9kYXRhYFxucmVkdWNlZF9kYXRhLnNoYXBlXG5cbiMgcHJpbnQgb3V0IHRoZSByZWR1Y2VkIGRhdGFcbnByaW50KHJlZHVjZWRfZGF0YSkiLCJzY3QiOiJ0ZXN0X2ltcG9ydChcInNrbGVhcm4uZGVjb21wb3NpdGlvbi5QQ0FcIilcbnRlc3Rfb2JqZWN0KFwicGNhXCIsIGRvX2V2YWw9RmFsc2UpXG50ZXN0X29iamVjdChcInJlZHVjZWRfZGF0YVwiLCBkb19ldmFsPUZhbHNlKVxucHJlZGVmX21zZz1cIkRpZCB5b3UgaW5zcGVjdCB0aGUgc2hhcGUgb2YgYHJlZHVjZWRfZGF0YWA/XCJcbnRlc3Rfb2JqZWN0X2FjY2Vzc2VkKFwicmVkdWNlZF9kYXRhLnNoYXBlXCIsIG5vdF9hY2Nlc3NlZF9tc2c9cHJlZGVmX21zZylcbiMgVGVzdCBgcHJpbnRgIFxudGVzdF9mdW5jdGlvbihcbiAgICBcInByaW50XCIsXG4gICAgbm90X2NhbGxlZF9tc2c9XCJEaWQgeW91IHByaW50IG91dCB0aGUgYHJlZHVjZWRfZGF0YV9ycGNhYCBkYXRhP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBgcmVkdWNlZF9kYXRhX3JwY2FgIGRhdGEhXCIsXG4gICAgZG9fZXZhbD1GYWxzZVxuKVxuc3VjY2Vzc19tc2coXCJBbWF6aW5nIVwiKSJ9</div>
<br /><br />
<p>When you inspect the reduced data, that the columns or features have now been reduced to only two. The number of rows or observations is still the same, namely, 3823. And now that your data is in the right format, itâ€™s time to get to the plotting!</p>

<p>The choice of the right plot is already a great start, but what will you choose?</p>

<p>In this case, youâ€™re exploring the data, so you probably want to discover possible correlations between the attributes of your data. A scatter plot is probably a good way to visualize this: it allows you to identify a relationship between the two features that you have gained from the dimensionality reduction.</p>

<pre>
<code>import matplotlib.pyplot as plt

plt.scatter(reduced_data[:,0], reduced_data[:,1], c=labels, cmap = 'viridis')

plt.show()</code></pre>
<br />
<p><img alt="Correlation Python" src="https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python+EDA+Tutorial/content_content_unknown.png" /></p>
</div>
<br />
<div class="section level3" id="correlation-identification-with-bokeh">
<h3>Correlation Identification With Bokeh</h3>

<p>Secondly, you can also consider using Bokeh to construct an interactive plot to discover correlations between the attributes in your data. The Bokeh library is a Python interactive visualization library that targets modern web browsers for presentation. Itâ€™s ideal if youâ€™re working with large or streaming datasets, but as you can see in the following example, you can also use it for â€œregularâ€ data.</p>

<p>The code is very simple: you import the necessary modules, construct the scatter plot, configure the default output state to generate output saved to a file when show() is called. Finally, you call <code>show()</code> to see the scatter plot that you have constructed!</p>

<pre>
<code># Import the necessary modules
from bokeh.charts import Scatter, output_file, show

# Construct the scatter plot
p = Scatter(iris, x='Petal_length', y='Petal_width', color=&quot;Class&quot;, title=&quot;Petal Length vs Petal Width&quot;,
            xlabel=&quot;Sepal Length&quot;, ylabel=&quot;Sepal Width&quot;)

# Output the file 
output_file('scatter.html')

# Show the scatter plot
show(p)</code></pre>

<p>The result is elegant:</p>
<br />
<p><img alt="Python data exploration" src="http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/430/content_bokeh_plot_1.png" /></p>
<br />
<p>Note that this is a static, saved image of the plot but that the resulting plot in your notebook or terminal will be interactive! Of course, this is just one simple example of how you can use Bokeh to make interactive graphs. Make sure to check out the Bokeh Gallery for more inspiration or take DataCampâ€™s <a href="https://www.datacamp.com/courses/interactive-data-visualization-with-bokeh/">Interactive Data Visualization with Bokeh</a> course.</p>
</div>

<div class="section level3" id="correlation-identification-with-pandas">
<h3>Correlation Identification With Pandas</h3>

<p>The plots that you have seen in the previous sections are a visual way of exploring correlation between the attributes of your data. But that doesnâ€™t mean that you can not explore this measure in a quantitative way! And when you do decide to do this, make use of Pandasâ€™ <code>corr()</code> function. But do note that the NaN or null values are excluded in this computation!</p>

<div data-datacamp-exercise data-encoded="true" data-height="300">eyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pXG5pcmlzID0gaXJpcy5yYW5rKCkiLCJzYW1wbGUiOiIjIFBlYXJzb24gY29ycmVsYXRpb25cbmlyaXMuY29ycigpXG5cbiMgS2VuZGFsbCBUYXUgY29ycmVsYXRpb25cbmlyaXMuY29ycigna2VuZGFsbCcpXG5cbiMgU3BlYXJtYW4gUmFuayBjb3JyZWxhdGlvblxuaXJpcy5jb3JyKCdzcGVhcm1hbicpIn0=</div>
<br /><br />
<p><strong>Note</strong> that the two last correlation measures require you to rank the data before calculating the coefficients. You can easily do this with <code>rank()</code>: for the exercise above, the <code>iris</code> data was ranked by executing <code>iris.rank()</code> for you.</p>

<p>Furthermore, there are some assumptions that these correlations work with: the Pearson correlation assumes that your variables are normally distributed, that there is a straight line relationship between each of the variables and that the data is normally distributed about the regression line. The Spearman correlation, on the other hand, assumes that you have two ordinal variables or two variables that are related in some way, but not linearly.</p>

<p>The Kendall Tau correlation is a coefficient that represents the degree of concordance between two columns of ranked data. You can use the Spearman correlation to measure the degree of association between two variables. These seem very similar to each other, donâ€™t they?</p>

<p>Even though the Kendal and the Spearman correlation measures seem similar, but they do differ: the exact difference lies in the fact that the calculations are different. The Kendal Tau coefficient is calculated by the number of concordant pairs minus the number of discordant pairs divided by the total number of pairs. The Spearman coefficient is the sum of deviation squared by <code>n</code> times <code>n</code> minus 1.</p>

<p>Spearmanâ€™s coefficient will usually be larger than the Kendallâ€™s Tau coefficient, but this is not always the case: youâ€™ll get a smaller Spearmanâ€™s coefficient when the deviations are huge among the observations of your data. The Spearman correlation is very sensitive to this and this might come in handy in some cases!</p>

<p>So, when do you want to use which coefficient, because the two of these correlation actually test something different; Kendallâ€™s Tau is representing the proportion of concordant pairs relative to discordant pairs and the Spearmanâ€™s coefficient doesnâ€™t do that. You can also argue that the Kendall Tau correlation has a more intuitive interpretation and easier to calculate, that it gives a better estimate of the corresponding population parameter and that the p values are more accurate in small sample sizes.</p>

<p><strong>Tip</strong> add the <code>print()</code> function to see the results of the specific pairwise correlation compututations of columns.</p>
</div>
</div>

<div class="section level2" id="onwards">
<h2>Onwards!</h2>

<p>Congrats, you have made it to the end of our Pandas tutorial! You now have some mastered some of the basic techniques that you can use to explore your data with Python.</p>

<p>If you want to deep dive into the topic even further, our Pandas course series is perfect: check out our <a href="https://www.datacamp.com/courses/pandas-foundations/">Pandas Foundations</a>, <a href="https://www.datacamp.com/courses/merging-dataframes-with-pandas/">Merging DataFrames with Pandas</a> or <a href="https://www.datacamp.com/courses/manipulating-dataframes-with-pandas/">Manipulating DataFrames with Pandas</a> courses.</p>

<p>If, however, youâ€™re ready to move on from Pandas and explore the Matplotlib package some more, consider taking DataCampâ€™s <a href="https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python/">Python data visualization tutorial</a> or start modelling your data! Continue to our <a href="https://www.datacamp.com/community/tutorials/machine-learning-python/">machine learning tutorial</a> to find out how you can build a machine learning model to recognize the handwritten digits automatically!</p>
</div>
</nav>
</div><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/solarized-dark.min.css" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Lora" rel="stylesheet"/><link href="https://fonts.googleapis.com/css?family=Roboto+Mono:400,400i,700,700i" rel="stylesheet"/></div><div class="jsx-1464850800 social__bottom mobileOnly"><div class="jsx-1464850800 voteAndSocial"><div class="jsx-1464850800"><div class="jsx-1972554161 Upvote"><div class="jsx-1972554161"><div class="jsx-1972554161 normal"><span class="jsx-1972554161 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-1972554161 count">86</span></div><div class="jsx-1972554161 voted"><span class="jsx-1972554161 icon"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 12 12"><path d="M1 10L6 0l5 10z"></path></svg></span><span class="jsx-1972554161 count">86</span></div></div></div><a href="#comments" class="jsx-3293774837 CommentCounter"><span class="jsx-3293774837 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></span><span class="jsx-3293774837 count">0</span></a></div><div class="jsx-494086174 Social"><div class="jsx-494086174 icons"><a href="https://www.facebook.com/sharer.php?u=https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" target="_blank" rel="noopener noreferrer" class="jsx-494086174 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/intent/tweet?url=https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" target="_blank" rel="noopener noreferrer" class="jsx-494086174 icon centerIcon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/cws/share?url=https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python" target="_blank" rel="noopener noreferrer" class="jsx-494086174 icon"><svg height="10" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a></div></div></div></div></div></div><div class="jsx-2205214625 RecommendedArticles"><div class="jsx-2205214625 title">Related posts</div><div class="jsx-2205214625 articleLayout"><div class="jsx-2205214625 articleWrapper"><div class="jsx-1426450779 RecommendedCard"><div class="jsx-1426450779 info noImage"><div class="jsx-1426450779 infoHead"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">data manipulation</span></div><a class="jsx-1022557955 more">+<!-- -->3</a></div><h2 class="jsx-1426450779"><a href="/community/tutorials/python-data-profiling">Exploratory Data Analysis of Craft Beers: Data Profiling</a></h2></div><div class="jsx-1426450779 space"></div><div class="jsx-1426450779 authorWrapper"><div class="jsx-566588255 Author"><a href="/profile/nickhould" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/923/685/square/2d8068c50718ed35659b1de3ce219dc735d27c0b.png?1505990828);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Jean-Nicholas Hould</div><div class="jsx-566588255 date"><span>April 13th, 2017</span></div></div></a></div></div></div></div></div><div class="jsx-2205214625 articleWrapper"><div class="jsx-1426450779 RecommendedCard"><div class="jsx-1426450779 info noImage"><div class="jsx-1426450779 infoHead"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">python</span></div><a class="jsx-1022557955 more">+<!-- -->2</a></div><h2 class="jsx-1426450779"><a href="/community/tutorials/pandas-multi-index">Hierarchical indices, groupby and pandas</a></h2></div><div class="jsx-1426450779 space"></div><div class="jsx-1426450779 authorWrapper"><div class="jsx-566588255 Author"><a href="/profile/hugobowneanderson" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/469/499/square/hugo_bowne-anderson.png?1470132470);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Hugo Bowne-Anderson</div><div class="jsx-566588255 date"><span>October 2nd, 2017</span></div></div></a></div></div></div></div></div><div class="jsx-2205214625 articleWrapper"><div class="jsx-1426450779 RecommendedCard"><div class="jsx-1426450779 info noImage"><div class="jsx-1426450779 infoHead"><div class="jsx-2792531181 TagLine"><div class="jsx-1764811326 Tag"><span class="jsx-1764811326 title">python</span></div><a class="jsx-1022557955 more">+<!-- -->8</a></div><h2 class="jsx-1426450779"><a href="/community/tutorials/kaggle-machine-learning-eda">Kaggle Tutorial: EDA &amp; Machine Learning</a></h2></div><div class="jsx-1426450779 space"></div><div class="jsx-1426450779 authorWrapper"><div class="jsx-566588255 Author"><a href="/profile/hugobowneanderson" target="_blank" class="jsx-566588255"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://assets.datacamp.com/users/avatars/000/469/499/square/hugo_bowne-anderson.png?1470132470);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-566588255 info"><div class="jsx-566588255 name">Hugo Bowne-Anderson</div><div class="jsx-566588255 date"><span>December 21st, 2017</span></div></div></a></div></div></div></div></div></div></div><div id="comments" class="jsx-3956319705 PostAComment"><button class="jsx-1844558338 Button big seeAll same greyIcon"><div class="jsx-1844558338 icon"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><path d="M12.595 13.364c.01-.111.02-.197.028-.251.058-.405.372-.702.74-.702h1.257c1.035-.002 1.875-.934 1.88-2.082V4.764c-.001-1.155-.842-2.092-1.878-2.094H3.38c-1.034.002-1.873.931-1.88 2.076v5.565c.001 1.156.842 2.092 1.878 2.094h6.626c.292 0 .557.189.68.484.408.977 1.07 1.576 1.94 1.85a6.004 6.004 0 0 1-.03-1.375zm1.51 1.119c.048.314.136.521.235.606.566.487.258 1.497-.458 1.497-1.87 0-3.423-.785-4.33-2.51H3.376C1.513 14.07.004 12.39 0 10.311V4.74C.014 2.673 1.52 1.004 3.378 1h11.245c1.864.004 3.373 1.686 3.377 3.763v5.57c-.01 2.07-1.518 3.744-3.378 3.748h-.551c.004.138.016.273.035.402zm-8.423-5.81a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.268 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229zm3.318 0a1.114 1.114 0 1 0 0-2.229 1.114 1.114 0 0 0 0 2.229z"></path></svg></div><div class="jsx-1844558338 ">Post a Comment</div></button></div></main><div class="jsx-2506565400 SidebarSocial"><div class="jsx-2506565400 rss"><a href="/community/rss.xml" class="jsx-2506565400"><svg height="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 18 18"><circle cx="3.08" cy="14.92" r="3.08"></circle><path d="M16.46 18a1.54 1.54 0 0 1-1.54-1.54c0-8.25-5.13-13.38-13.38-13.38A1.59 1.59 0 0 1 .46 1.15 1.72 1.72 0 0 1 1.54 0a16.45 16.45 0 0 1 12 4.51c3 2.95 4.51 7.08 4.51 12A1.54 1.54 0 0 1 16.46 18z"></path><path d="M10.63 18a1.54 1.54 0 0 1-1.54-1.54c0-5-2.54-7.54-7.54-7.54a1.54 1.54 0 0 1 0-3.08c6.75 0 10.63 3.87 10.63 10.62A1.54 1.54 0 0 1 10.63 18z"></path></svg>Subscribe to RSS</a></div><div class="jsx-2506565400 icons"><a href="https://www.facebook.com/pages/DataCamp/726282547396228" target="_blank" rel="noopener noreferrer" class="jsx-2506565400 icon"><svg height="16" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 11.73 22.58"><path d="M7.61 22.58v-10.3h3.46l.52-4h-4V5.7c0-1.16.32-2 2-2h2.13V.16A28.47 28.47 0 0 0 8.63 0C5.56 0 3.47 1.87 3.47 5.31v3H0v4h3.47v10.3h4.14z"></path></svg></a><a href="https://twitter.com/datacamp" target="_blank" rel="noopener noreferrer" class="jsx-2506565400 icon"><svg height="13" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20.42 16.67"><path d="M10 5.18c0-.28-.06-.53-.07-.78a4 4 0 0 1 .73-2.57A4.08 4.08 0 0 1 13.93 0 4 4 0 0 1 17 1.15a.43.43 0 0 0 .46.12 8.68 8.68 0 0 0 2.2-.84l.2-.1a4.36 4.36 0 0 1-1.75 2.28A9 9 0 0 0 20.42 2l-.21.3a3.83 3.83 0 0 1-.23.3A8.45 8.45 0 0 1 18.5 4a.28.28 0 0 0-.13.27A12 12 0 0 1 17 10.18a11.8 11.8 0 0 1-3.37 4.11 11.17 11.17 0 0 1-4.39 2.06 12.53 12.53 0 0 1-4.44.22 11.87 11.87 0 0 1-4.74-1.73L0 14.79a8.6 8.6 0 0 0 6.16-1.74 4.28 4.28 0 0 1-3.91-2.91h.95a6.18 6.18 0 0 0 .89-.12A4.2 4.2 0 0 1 .8 5.88a4 4 0 0 0 1.81.49 4.23 4.23 0 0 1-1.78-3A4.07 4.07 0 0 1 1.38.79 12.06 12.06 0 0 0 10 5.18z" id="iOjKBC.tif"></path></svg></a><a href="https://www.linkedin.com/company/datamind-org" target="_blank" rel="noopener noreferrer" class="jsx-2506565400 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 16.99 17"><path d="M3.85 17H.34V5.67h3.51zM2.07 4.18a2.09 2.09 0 1 1 2.08-2.09 2.08 2.08 0 0 1-2.08 2.09zM17 17h-3.5v-5.95c0-1.63-.62-2.54-1.91-2.54s-2.14.95-2.14 2.54V17H6.09V5.67h3.36v1.52a4 4 0 0 1 3.42-1.87c2.4 0 4.12 1.47 4.12 4.5V17z"></path></svg></a><a href="https://www.youtube.com/channel/UC79Gv3mYp6zKiSwYemEik9A" target="_blank" rel="noopener noreferrer" class="jsx-2506565400 icon"><svg height="12" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 25.19 17.73"><path d="M24.21 1.52C23.3.44 21.62 0 18.42 0H6.78C3.5 0 1.79.47.88 1.62S0 4.4 0 6.68V11c0 4.43 1 6.68 6.78 6.68h11.64c2.78 0 4.32-.39 5.32-1.34S25.2 13.76 25.2 11V6.68c-.01-2.41-.08-4.07-.99-5.16zm-8 7.94l-5.29 2.76a.81.81 0 0 1-1.19-.72V6a.81.81 0 0 1 1.19-.72L16.17 8a.81.81 0 0 1 0 1.44z"></path></svg></a></div><div class="jsx-2506565400 menu"><a href="/about" class="jsx-2506565400 menuItem">About</a><a href="/terms-of-use" class="jsx-2506565400 menuItem">Terms</a><a href="/privacy-policy" class="jsx-2506565400 menuItem">Privacy</a></div></div><div class="jsx-879378290 BottomBar bar"><div class="jsx-879378290 barView"><div style="background-image:url(https://res.cloudinary.com/dyd911kmh/image/fetch/t_avatar_thumbnail/https://cdn.datacamp.com/community/assets/placeholder_avatar-7f673b5d40e159404a56b5931250cc73.png);border-radius:20px;min-width:40px;min-height:40px" class="jsx-3208234818 Avatar"></div><div class="jsx-879378290 blueBar">Want to leave a comment?</div></div></div></div><link href="https://fonts.googleapis.com/css?family=Lato:300,400i,400,700" rel="stylesheet"/><div class="Analytics"><script>
      ;(function(p,l,o,w,i,n,g){if(!p[i]){p.GlobalSnowplowNamespace=p.GlobalSnowplowNamespace||[];
        p.GlobalSnowplowNamespace.push(i);p[i]=function(){(p[i].q=p[i].q||[]).push(arguments)
        };p[i].q=p[i].q||[];n=l.createElement(o);g=l.getElementsByTagName(o)[0];n.async=1;
        n.src=w;g.parentNode.insertBefore(n,g)}}(window,document,"script","//d36fqcuygdrd4y.cloudfront.net/BuKMCyKUvvyXZkMi44LjI.js","snowplow"));

      window.snowplow('newTracker', 'co', 'track.datacamp.com', {
        platform: 'web',
        post: true,
        discoverRootDomain: true,
        contexts: {
          webPage: true,
          performanceTiming: true
        }
      });
      window.snowplow('enableActivityTracking', 10, 10);
      window.snowplow('enableLinkClickTracking');
    </script><script data-cfasync="false">(function(W,i,s,e,P,o,p){W['WisePopsObject']=P;W[P]=W[P]||function(){
      (W[P].q=W[P].q||[]).push(arguments)},W[P].l=1*new Date();o=i.createElement(s),
      p=i.getElementsByTagName(s)[0];o.async=1;o.src=e;p.parentNode.insertBefore(o,p)
    })(window,document,'script','//loader.wisepops.com/get-loader.js?v=1&site=VswVJn7o4J','wisepops');</script></div></div></div></div><div id="__next-error"></div><script>
          __NEXT_DATA__ = {"props":{"isServer":true,"store":{},"initialState":{"adminContent":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{},"form":{"isSaving":false,"isSucceeded":false,"statusMessage":"","isAdminFormModalOpen":false,"previewSlug":""},"delete":{"isDeleting":false,"isSucceeded":false,"statusMessage":"","isDeleteAdminContentModalOpen":false},"update":{"isApprovingArticle":false,"isSucceeded":false,"statusMessage":"","isApproveArticleModalOpen":false}},"adminList":{"isFetched":false,"isFetching":false,"statusMessage":""},"auth":{"isAuthModalOpen":false,"isLogin":false,"isAuthorized":false,"isSubscriber":false,"user":{},"loginTitle":"","signUpTitle":""},"clientConfig":{"isDevelopment":false,"absoluteUrl":"https://www.datacamp.com","isNewsActive":true,"ALGOLIA_APP_ID":"7H5IORUQLD","ALGOLIA_API_KEY":"ae4f7a78b4914ef37d11dc177ad2eb13","ALGOLIA_API_INDEX":"community_prod","DC_COMMUNITY_AUTHOR_APP_URL":"https://community-author-app.new.datacamp.com/","DC_LIGHT_URL":"https://cdn.datacamp.com/datacamp-light-latest.min.js","ANALYTICS_GOOGLE_TAG_MANAGER":"GTM-TGGWB2P","ANALYTICS_SNOWPLOW_ENDPOINT":"track.datacamp.com","WISEPOPS":"VswVJn7o4J","CHAT_SUBSCRIBER_REDIRECT":"https://www.datacamp.com/slack/join","CHAT_NONSUBSCRIBER_LINK":"https://www.datacamp.com/subscribe?from_communitychat=true","CHAT_SUBSCRIBE_TEAM":"https://www.datacamp.com/groups/business"},"comment":{"isFetching":false,"isFetched":false,"statusMessage":"","comments":[],"commentsTotal":0,"form":{"isSaving":false,"isSucceeded":false,"statusMessage":"","id":"new","parentId":null,"commentText":""},"delete":{"isDeleting":false,"isSucceeded":false,"statusMessage":"","isDeleteCommentModalOpen":false},"isBottomBarOpen":true,"bottomBarView":"bar"},"content":{"content":{"id":292,"externalId":null,"type":"Tutorial","status":"published","authorId":"karlijn","title":"Python Exploratory Data Analysis Tutorial","slug":"exploratory-data-analysis-python","previewSlug":null,"description":"Learn the basics of Exploratory Data Analysis (EDA) in Python with Pandas, Matplotlib and NumPy, such as sampling, feature engineering, correlation, etc.","articles":[318,7750,8243],"courses":[],"redirectSlug":null,"contentHtml":"\u003cscript src=\"https://cdn.datacamp.com/datacamp-light-latest.min.js\"\u003e\u003c/script\u003e\r\n\u003cp\u003eAs you will know by now, the Python data manipulation library Pandas is used for data manipulation; For those who are just starting out, this might imply that this package can only be handy when preprocessing data, but much less is true: Pandas is also great to explore your data and to store it after you\u0026rsquo;re done preprocessing the data.\u003c/p\u003e\r\n\r\n\u003cp\u003eAdditionally, for those who have been following DataCamp\u0026rsquo;s Python tutorials or that have already been introduced to the basics of SciPy, NumPy, Matplotlib and Pandas, it might be a good idea to recap some of the knowledge that you have built up.\u003c/p\u003e\r\n\r\n\u003cp\u003eToday\u0026rsquo;s tutorial will actually introduce you to some ways to explore your data efficiently with all the above packages so that you can start modeling your data:\u003c/p\u003e\r\n\r\n\u003cnav\u003e\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou\u0026rsquo;ll first learn how to \u003ca href=\"#import\"\u003eimport data\u003c/a\u003e, which is the first step that you need to complete successfully before you can start your analysis.\u003c/li\u003e\r\n\t\u003cli\u003eIf you\u0026#39;re not sure what \u003ca href=\"#eda\"\u003eExploratory Data Analysis (EDA)\u003c/a\u003e is and what the exact difference between EDA and Data Mining is, this section will explain it for you before you start the tutorial!\u003c/li\u003e\r\n\t\u003cli\u003eThen, you\u0026rsquo;ll get a \u003ca href=\"#description\"\u003ebasic description\u003c/a\u003e of your data. You\u0026rsquo;ll focus on getting some descriptive statistics, checking out the first and last rows of your DataFrame, retrieving samples from your data, etc. You\u0026rsquo;ll see that this is a great way to get an initial feeling with your data and maybe understand it a bit better already!\u003c/li\u003e\r\n\t\u003cli\u003eAfter gathering some information on your data, it might also be a good idea to also take a deeper look at it by \u003ca href=\"#closer\"\u003equerying\u003c/a\u003e or indexing the data. You can use this technique to test some of the basic hypotheses that you might have about the data.\u003c/li\u003e\r\n\t\u003cli\u003eNow that you have inspected your data, you'll probably already see that there are some \u003ca href=\"#features\"\u003efeatures \u003c/a\u003e that can be of interest to your analysis: you\u0026#39;ll see which ones can influence your analysis positively with feature engineering and feature selection.\u003c/li\u003e\r\n\t\u003cli\u003eNext, you\u0026rsquo;ll see that an initial exploration is good, but you will also need to have an idea of the \u003ca href=\"#challenges\"\u003echallenges\u003c/a\u003e that your data can pose, such as missing values or outliers, and, of course, how you can handle those challenges, and\u003c/li\u003e\r\n\t\u003cli\u003eLastly, you\u0026rsquo;ll also learn how to discover \u003ca href=\"#patterns\"\u003epatterns\u003c/a\u003e in your data, by either visualizing your data easily and quickly with the Python data visualization packages Matplotlib and Bokeh, or by using specific functions to compute the correlation between attributes.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\r\n\u003cdiv id=\"scoped-content\"\u003e\r\n\u003cstyle type=\"text/css\"\u003e:target:before {\r\ncontent:\"\";\r\ndisplay:block;\r\nheight:150px;\r\nmargin:-150px 0 0;\r\n}\r\nh3 {font-weight:normal;\r\nmargin-top:.5em}\r\nh4 {\r\nfont-weight:lighter\r\n}\r\n\u003c/style\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eAre you interested in taking a Pandas course? Consider taking one of our three courses that we have made in collaboration with Continuum Analytics, the creator and driving force behind Anaconda, such as the \u003ca href=\"https://www.datacamp.com/courses/pandas-foundations/\"\u003ePandas Foundations course\u003c/a\u003e!\u003c/p\u003e\r\n\r\n\u003ch2 id=\"import\"\u003eImporting The Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eTo start exploring your data, you\u0026rsquo;ll need to start by actually loading in your data. You\u0026rsquo;ll probably know this already, but thanks to the Pandas library, this becomes an easy task: you import the package as \u003ccode\u003epd\u003c/code\u003e, following the convention, and you use the \u003ccode\u003eread_csv()\u003c/code\u003e function, to which you pass the URL in which the data can be found and a \u003ccode\u003eheader\u003c/code\u003e argument. This last argument is one that you can use to make sure that your data is read in correctly: the first row of your data won\u0026rsquo;t be interpreted as the column names of your DataFrame.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlternatively, there are also other arguments that you can specify to ensure that your data is read in correctly: you can specify the delimiter to use with the \u003ccode\u003esep\u003c/code\u003e or \u003ccode\u003edelimiter\u003c/code\u003e arguments, the column names to use with \u003ccode\u003enames\u003c/code\u003e or the column to use as the row labels for the resulting DataFrame with \u003ccode\u003eindex_col\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut these are not nearly all the arguments that you can add to the \u003ccode\u003eread_csv()\u003c/code\u003e function. Read up on this function and its arguments in the \u003ca href=\"http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html\"\u003edocumentation\u003c/a\u003e.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInNhbXBsZSI6IiMgSW1wb3J0IHRoZSBgcGFuZGFzYCBsaWJyYXJ5IGFzIGBwZGBcbmltcG9ydCBwYW5kYXMgYXMgcGRcblxuIyBMb2FkIGluIHRoZSBkYXRhIHdpdGggYHJlYWRfY3N2KClgXG5kaWdpdHMgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL29wdGRpZ2l0cy9vcHRkaWdpdHMudHJhXCIsXG4gICAgICAgICAgICAgICAgICAgICBoZWFkZXI9Tm9uZSlcblxuIyBQcmludCBvdXQgYGRpZ2l0c2BcbnByaW50KGRpZ2l0cykifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eNote that in this case, you made use of \u003ccode\u003eread_csv()\u003c/code\u003e because the data happens to be in a comma-separated format. If you have files that have another separator, you can also consider using other functions to load in your data, such as \u003ccode\u003eread_table()\u003c/code\u003e, \u003ccode\u003eread_excel()\u003c/code\u003e, \u003ccode\u003eread_fwf()\u003c/code\u003e and \u003ccode\u003eread_clipboard\u003c/code\u003e, to read in general delimited files, Excel files, Fixed-Width Formatted data and data that was copied to the Clipboard, respectively.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso, you\u0026rsquo;ll find \u003ccode\u003eread_sql()\u003c/code\u003e as one of the options to read in an SQL query or a database table into a DataFrame. For even more Input functions, consider \u003ca href=\"http://pandas.pydata.org/pandas-docs/version/0.18.1/api.html#input-output\"\u003ethis section\u003c/a\u003e of the Pandas documentation.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Learn Python for Data Science With DataCamp\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\r\n\u003ch2 id=\"eda\"\u003eWhat is Exploratory Data Analysis (EDA)?\u003c/h2\u003e\r\n\r\n\u003cp\u003eExploratory Data Analysis (EDA) is used on the one hand to answer questions, test business assumptions, generate hypotheses for further analysis. On the other hand, you can also use it to prepare the data for modeling. The thing that these two probably have in common is a good knowledge of your data to either get the answers that you need or to develop an intuition for interpreting the results of future modeling.\u003c/p\u003e\r\n\r\n\u003cp\u003eThere are a lot of ways to reach these goals: you can get a basic description of the data, visualize it, identify patterns in it, identify challenges of using the data, etc.\u003c/p\u003e\r\n\r\n\u003cp\u003eOne of the things that you\u0026rsquo;ll often see when you\u0026rsquo;re reading about EDA is Data profiling. Data profiling is concerned with summarizing your dataset through descriptive statistics. You want to use a variety of measurements to better understand your dataset. The goal of data profiling is to have a solid understanding of your data so you can afterwards start querying and visualizing your data in various ways. However, this doesn\u0026rsquo;t mean that you don\u0026rsquo;t have to iterate: exactly because data profiling is concerned with summarizing your dataset, it is frequently used to assess the data quality. Depending on the result of the data profiling, you might decide to correct, discard or handle your data differently.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou\u0026rsquo;ll learn more about data profiling in a next post.\u003c/p\u003e\r\n\r\n\u003ch3\u003eEDA And Data Mining (DM)\u003c/h3\u003e\r\n\r\n\u003cp\u003eEDA distinguishes itself from data mining, even though the two are closely related, as many EDA techniques have been adopted into data mining. Also the goals of the two are very similar: EDA indeed makes sure that you explore the data in such a way that interesting features and relationships between features will become more clear. In EDA, you typically explore and compare many different variables with a variety of techniques to search and find systematic patterns. Data mining, on the other hand, is concerned with extracting patterns from the data. Those patterns provide insights into relationships between variables that can be used to improve business decisions. Also, in both cases, you have no a priori expectations or expectations that are not complete about the relations between the variables.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, in general, Data Mining can be said to be more application-oriented, while EDA is concerned with the basic nature of the underlying phenomena. In other words, Data Mining is relatively less concerned with identifying the specific relations between the involved variables. As a result, Data Mining accepts a \u0026ldquo;black box\u0026rdquo; approach to data exploration and doesn\u0026rsquo;t only use techniques that are also used in EDA but also techniques such as Neural Networks to generate valid predictions but don\u0026rsquo;t identify the specific nature of the relationships between the variables on which the predictions are based.\u003c/p\u003e\r\n\r\n\u003ch2 id=\"description\"\u003eBasic Description of the Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eLike you read above, EDA is all about getting to know your data. One of the most elementary steps to do this is by getting a basic description of your data. A basic description of your data is indeed a very broad term: you can interpret it as a quick and dirty way to get some information on your data, as a way of getting some simple, easy-to-understand information on your data, to get a basic feel for your data, etc.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis section won\u0026rsquo;t make a distinction between these interpretations: it will indeed introduce you to some of the ways that you can quickly gather information on your DataFrame that is easy to understand.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"describing-the-data\"\u003e\r\n\u003ch3\u003eDescribing The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eFor example, you can use the \u003ccode\u003edescribe()\u003c/code\u003e function to get various summary statistics that exclude NaN values. Consider this example in which you describe the famous \u003ca href=\"https://archive.ics.uci.edu/ml/datasets/Iris\"\u003eIris dataset\u003c/a\u003e. The data has already been loaded in for you in the DataCamp Light chunk:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiaXJpcy5kZXNjcmliZSgpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou see that this function returns the count, mean, standard deviation, minimum and maximum values and the quantiles of the data. Note that, of course, there are many packages available in Python that can give you those statistics, including Pandas itself. Using this function is just one of the ways to get this information.\u003c/p\u003e\r\n\r\n\u003cp\u003eAlso note that you certainly need to take the time to dive deeper into the descriptive statistics if you haven\u0026rsquo;t done this yet. You can use these descriptive statistics to begin to assess the quality of your data. Then you\u0026rsquo;ll be able to decide whether you need to correct, discard or deal with the data in anohter way. This is usually the data profiling step. This step in the EDA is meant to understand the data elements and its anomalies a bit better and to see how the data matches the documentation on the one hand and accommodates to the business needs on the other hand.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that you\u0026rsquo;ll come back to the data profiling step as you go through your exploratory data analysis, as the quality of your data can be impacted by the steps that you\u0026rsquo;ll go through.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"first-and-last-dataframe-rows\"\u003e\r\n\u003ch3\u003eFirst and Last DataFrame Rows\u003c/h3\u003e\r\n\r\n\u003cp\u003eNow that you have got a general idea about your data set, it\u0026rsquo;s also a good idea to take a closer look at the data itself. With the help of the \u003ccode\u003ehead()\u003c/code\u003e and \u003ccode\u003etail()\u003c/code\u003e functions of the Pandas library, you can easily check out the first and last lines of your DataFrame, respectively.\u003c/p\u003e\r\n\r\n\u003cp\u003eInspect the first and last five rows of the handwritten digits data with the \u003ccode\u003ehead()\u003c/code\u003e and \u003ccode\u003etail()\u003c/code\u003e functions in the DataCamp Light chunk below. The data has already been loaded in for you in the DataCamp Light chunk:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBJbnNwZWN0IHRoZSBmaXJzdCA1IHJvd3Mgb2YgYGRpZ2l0c2BcbmZpcnN0ID0gZGlnaXRzLl9fX19fKDUpXG5cbiMgSW5zcGVjdCB0aGUgbGFzdCA1IHJvd3Ncbmxhc3QgPSBkaWdpdHMuX19fXyg1KSIsInNvbHV0aW9uIjoiIyBJbnNwZWN0IHRoZSBmaXJzdCA1IHJvd3Mgb2YgYGRpZ2l0c2BcbmZpcnN0ID0gZGlnaXRzLmhlYWQoNSlcblxuIyBJbnNwZWN0IHRoZSBsYXN0IDUgcm93c1xubGFzdCA9IGRpZ2l0cy50YWlsKDUpIiwic2N0IjoidGVzdF9vYmplY3QoXCJmaXJzdFwiKVxudGVzdF9vYmplY3QoXCJsYXN0XCIpXG5zdWNjZXNzX21zZyhcIkFtYXppbmdseSBkb25lIVwiKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;ll see that the result of the \u003ccode\u003ehead()\u003c/code\u003e and \u003ccode\u003etail()\u003c/code\u003e functions doesn\u0026rsquo;t quite say much when you\u0026rsquo;re not familiar with this kind of data.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou might just see a bunch of rows and columns with numerical values in them. Consider reading up on the \u003ca href=\"https://archive.ics.uci.edu/ml/machine-learning-databases/optdigits/optdigits.names\"\u003edata set description\u003c/a\u003e if you haven\u0026rsquo;t done so already, which will give you relevant information on how the data was collected and also states the number of attributes and rows, which can be handy to check whether you have imported the data correctly.\u003c/p\u003e\r\n\r\n\u003cp\u003eAdditionally, go back to your initial finding: the numerical values in the rows. At first sight, you might not think that there is a problem, as the integer values appear to be correct and don\u0026rsquo;t raise any flags when you\u0026rsquo;re looking at it at first.\u003c/p\u003e\r\n\r\n\u003cp\u003eBut if you would have done all of this on another data set that you had in front of you and that might have had, for example, date time information, a quick glance on the result of these lines of code might have raised the following questions: \u0026ldquo;Has my data been read in as a DateTime?\u0026rdquo;, \u0026ldquo;How can I check this?\u0026rdquo; and \u0026ldquo;How can I change the data type?\u0026rdquo;.\u003c/p\u003e\r\n\r\n\u003cp\u003eThese are deeper questions that you\u0026rsquo;ll typically address in the data profiling step, which will be addressed in a next post.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"sampling-the-data\"\u003e\r\n\u003ch3\u003eSampling The Data\u003c/h3\u003e\r\n\r\n\u003cp\u003eIf you have a large dataset, you might consider taking a sample of your data as an easy way to get a feel for your data quickly. As a first and easy way to do this, you can make use of the \u003ccode\u003esample()\u003c/code\u003e function that is included in Pandas, just like this:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBUYWtlIGEgc2FtcGxlIG9mIDVcbmRpZ2l0cy5zYW1wbGUoNSkiLCJzb2x1dGlvbiI6IiMgVGFrZSBhIHNhbXBsZSBvZiA1XG5kaWdpdHMuc2FtcGxlKDUpIiwic2N0IjoiY2hlY2tfb3V0cHV0X2NvbnRhaW5zKFwiZGlnaXRzLnNhbXBsZSg1KVwiLCAxKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eAnother -perhaps more complicated- way to do this is by creating a random index and then get random rows from your DataFrame. You\u0026rsquo;ll see that the code below makes use the \u003ccode\u003erandom\u003c/code\u003e package that has a module \u003ccode\u003esample\u003c/code\u003e that will allow you to sample your data, in combination with \u003ccode\u003erange()\u003c/code\u003e and \u003ccode\u003elen()\u003c/code\u003e. Note that you also make use of \u003ccode\u003eix\u003c/code\u003e to select the exact rows of your DataFrame that you want to include in your sample.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you don\u0026rsquo; have an idea of why you use \u003ccode\u003eix\u003c/code\u003e in this context, DataCamp\u0026rsquo;s more specific tutorial can be of help! It covers these more general topics in detail. Go and check it out by clicking on the link that has been included above!\u003c/p\u003e\r\n\r\n\u003cp\u003eFor now, let\u0026rsquo;s practice our Python skills! Get started on the exercise below:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IG51bXB5IGFzIG5wXG5pbXBvcnQgcGFuZGFzIGFzIHBkXG5kaWdpdHMgPSBwZC5yZWFkX2NzdihcImh0dHA6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL29wdGRpZ2l0cy9vcHRkaWdpdHMudHJhXCIsXG4gICAgICAgICAgICAgICAgICAgICBoZWFkZXI9Tm9uZSkiLCJzYW1wbGUiOiIjIGltcG9ydCBgc2FtcGxlYCBmcm9tIGByYW5kb21gXG5mcm9tIHJhbmRvbSBpbXBvcnQgX19fX19fXG5cbiMgQ3JlYXRlIGEgcmFuZG9tIGluZGV4XG5yYW5kb21JbmRleCA9IG5wLmFycmF5KHNhbXBsZShyYW5nZShsZW4oX19fX19fKSksIDUpKVxuXG4jIEdldCA1IHJhbmRvbSByb3dzXG5kaWdpdHNTYW1wbGUgPSBkaWdpdHMuaXhbX19fX19fX19fX19dXG5cbiMgUHJpbnQgdGhlIHNhbXBsZVxucHJpbnQoX19fX19fX19fX19fKSIsInNvbHV0aW9uIjoiIyBpbXBvcnQgYHNhbXBsZWAgZnJvbSBgcmFuZG9tYFxuZnJvbSByYW5kb20gaW1wb3J0IHNhbXBsZVxuXG4jIENyZWF0ZSBhIHJhbmRvbSBpbmRleFxucmFuZG9tSW5kZXggPSBucC5hcnJheShzYW1wbGUocmFuZ2UobGVuKGRpZ2l0cykpLCA1KSlcblxuIyBHZXQgNSByYW5kb20gcm93c1xuZGlnaXRzU2FtcGxlID0gZGlnaXRzLml4W3JhbmRvbUluZGV4XVxuXG4jIFByaW50IHRoZSBzYW1wbGVcbnByaW50KGRpZ2l0c1NhbXBsZSkiLCJzY3QiOiJ0ZXN0X2ltcG9ydChcInJhbmRvbS5zYW1wbGVcIilcbnRlc3Rfb2JqZWN0KFwicmFuZG9tSW5kZXhcIilcbnRlc3Rfb2JqZWN0KFwiZGlnaXRzU2FtcGxlXCIpXG50ZXN0X2Z1bmN0aW9uKFwicHJpbnRcIikifQ==\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cdiv class=\"section level2\" id=\"a-closer-look-at-your-data-queries\"\u003e\r\n\u003ch2 id=\"closer\"\u003eA Closer Look At Your Data: Queries\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that you have taken a quick look at your data and have seen what it\u0026rsquo;s about, you\u0026rsquo;re ready to dive a little bit deeper: it\u0026rsquo;s time to inspect the data further by querying the data.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis goes easily with the \u003ccode\u003equery()\u003c/code\u003e function, which allows you to test some very simple hypotheses that you have about your data, such as \u0026ldquo;Is the petal length usually greater than the sepal length?\u0026rdquo; or \u0026ldquo;Is the petal length sometimes equal to the sepal length?\u0026rdquo;.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiIyBQZXRhbCBsZW5ndGggZ3JlYXRlciB0aGFuIHNlcGFsIGxlbmd0aD9cbmlyaXMucXVlcnkoJ1BldGFsX2xlbmd0aCA+IFNlcGFsX2xlbmd0aCcpXG5cbiMgUGV0YWwgbGVuZ3RoIGVxdWFscyBzZXBhbCBsZW5ndGg/XG5pcmlzLnF1ZXJ5KCdQZXRhbF9sZW5ndGggPT0gU2VwYWxfbGVuZ3RoJykifQ==\u003c/div\u003e\r\n\r\n\u003cp\u003eYou\u0026rsquo;ll see that this hypothesis doesn\u0026rsquo;t hold. You get an empty DataFrame back as a result.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this function can also be expressed as \u003ccode\u003eiris[iris.Petal_length \u0026gt; iris.Sepal_length]\u003c/code\u003e.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"the-challenges-of-your-data\"\u003e\r\n\u003ch2 id=\"challenges\"\u003eThe Challenges of Your Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eNow that you\u0026rsquo;ve gathered some basic information on your data, it\u0026rsquo;s a good idea to just go a little bit deeper into the challenges that your data might pose. If you have already gone through the data profiling step, you\u0026rsquo;ll be aware of missing values, you\u0026rsquo;ll have an idea of which values might be outliers, etc.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis section will describe some of the basic ways to already get an idea of these things and will describe how you can handle the data in case you do find irregularities in your data. Note once again that you will go or have gone deeper into identifying these irregularities in the data profiling step, and that it\u0026rsquo;s normal to return to this step once you have handled some of the challenges that your data poses.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"missing-values\"\u003e\r\n\u003ch3\u003eMissing Values\u003c/h3\u003e\r\n\r\n\u003cp\u003eSomething that you also might want to check when you\u0026rsquo;re exploring your data is whether or not the data set has any missing values.\u003c/p\u003e\r\n\r\n\u003cp\u003eExamining this is important because when some of your data is missing, the data set can lose expressiveness, which can lead to weak or biased analyses. Practically, this means that when you\u0026rsquo;re missing values for certain features, the chances of your classification or predictions for the data being off only increase.\u003c/p\u003e\r\n\r\n\u003cp\u003eOf course, the cause of you missing data in your data set can be the result of a faulty extraction or import of the data, or it might be the result of the collection process. The systems that give you the data might malfunction or the survey that you sent out might have some blanks left my the respondents. It's very important to consider also whether there is a pattern in the missing data, and this is something where the data profiling step can be useful. Remember that you can use data profiling to get a better idea of your data quality. You can read more about how you can discover patterns of missing data in a follow-up post.\r\n \u003c/p\u003e\r\n\r\n\u003cp\u003eIn short, the causes of missing data can be various and largely depend on the data context, but can also depend on yourself. That\u0026rsquo;s why you have first inspected your data when you imported it in one of the previous steps!\u003c/p\u003e\r\n\r\n\u003cp\u003eTo identify the rows that contain missing values, you can use \u003ccode\u003eisnull()\u003c/code\u003e. In the result that you\u0026rsquo;ll get back, you\u0026rsquo;ll see \u003ccode\u003eTrue\u003c/code\u003e or \u003ccode\u003eFalse\u003c/code\u003e appearing in each cell: \u003ccode\u003eTrue\u003c/code\u003e will indicate that the value contained within the cell is a missing value, \u003ccode\u003eFalse\u003c/code\u003e means that the cell contains a \u0026lsquo;normal\u0026rsquo; value.\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBJZGVudGlmaXkgbWlzc2luZyB2YWx1ZXNcbnBkLmlzbnVsbChfX19fX18pIiwic29sdXRpb24iOiIjIElkZW50aWZpeSBtaXNzaW5nIHZhbHVlc1xucGQuaXNudWxsKGRpZ2l0cykiLCJzY3QiOiJ0ZXN0X2Z1bmN0aW9uKFwicGFuZGFzLmlzbnVsbFwiLCBpbmNvcnJlY3RfbXNnPVwiRGlkIHlvdSBwYXNzIGBkaWdpdHNgIHRvIGBwZC5pc251bGwoKWA/XCIsIG5vdF9jYWxsZWRfbXNnPVwiRGlkIHlvdSBwYXNzIGBkaWdpdHNgIHRvIGBwZC5pc251bGwoKWA/XCIpXG5zdWNjZXNzX21zZyhcIldlbGwgZG9uZSFcIikifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eIn this case, you see that the data is quite complete: there are no missing values.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that you could have also read this in the data set description of the UCI Machine Learning Repository which was linked above, where you\u0026rsquo;ll have seen that there are no missing values listed for the data.\u003c/p\u003e\r\n\r\n\u003cp\u003eHowever, this will not be the case in every data set that you\u0026rsquo;ll come across. That\u0026rsquo;s why it\u0026rsquo;s good to know what you can do when you do run across a situation where you need to think about what you want to be doing with the missing data.\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eYou can delete the missing data: you either delete the whole record or you can just keep the records in which the features of interest are still present. Of course, you have to be careful with this procedure, as deleting data might also bias your analysis. That\u0026rsquo;s why you should ask yourself the question of whether the probability of certain data that is missing for a record is the same as for all other records. If the probability doesn\u0026rsquo;t vary record-per-record, deleting the missing data is a valid option.\u003c/li\u003e\r\n\t\u003cli\u003eBesides deletion, there are also methods that you can use to fill up cells if they contain missing values with so-called \u0026ldquo;imputation methods\u0026rdquo;. If you already have a lot of experience with statistics, you\u0026rsquo;ll know that imputation is the process of replacing missing data with substituted values. You can either fill in the mean, the mode or the median. Of course, here you need to think about whether you want to take, for example, the mean or median for all missing values of a variable, or whether you want to replace the missing values based on another variable. For example, for data in which you have records that have features with categorical variables such as \u0026ldquo;male\u0026rdquo; or \u0026ldquo;female\u0026rdquo;, you might also want to consider those before replacing the missing values, as the observations might differ from males and females. If this is the case, you might just calculate the average of the female observations and then fill out the missing values for other \u0026ldquo;female\u0026rdquo; records with this average.\u003c/li\u003e\r\n\t\u003cli\u003eEstimate the value with the help of regression, ANOVA, logistic regression or another modelling technique. This is by far the most complex way to fill in the values.\u003c/li\u003e\r\n\t\u003cli\u003eYou fill in the cells with values of records that are most similar to the one that has missing values. You can use KNN or K-Nearest Neighbors in cases such as these.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eNote that there are advantages and drawbacks to every one of the above ways to fill in missing data! You\u0026rsquo;ll want to consider things such as time, expense, the nature of your data, etc. before making a final decision on this.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhen you have made a final decision on what you\u0026rsquo;re going to do with the missing data, read on to see how you can implement the changes that you want to see in your data.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"filling-missing-values\"\u003e\r\n\u003ch4\u003eFilling Missing Values\u003c/h4\u003e\r\n\r\n\u003cp\u003eIf you do decide to fill in the values with imputation, you can still choose how you want to make this happen!\u003c/p\u003e\r\n\r\n\u003cp\u003eMake use of Pandas \u003ccode\u003efillna()\u003c/code\u003e in combination with the functions that NumPy has to offer. Consider the following code chunk, in which you supposedly have a DataFrame with the results of a survey that asks for people\u0026rsquo;s salary. Assuming a context where your audience are all from the same class in society and the likelihood of the respondents answering to the question is the same for every person, you can opt to calculate the mean of the people that did answer the question and use that mean to fill in the values of people that didn\u0026rsquo;t answer.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import NumPy\r\nimport numpy as np\r\n\r\n# Calculate the mean\r\nmean = np.mean(df.Salary)\r\n\r\n# Replace missing values with the mean\r\ndf. = df.Salary.fillna(mean)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eOf course, you don\u0026rsquo;t necessarily need to pass in a value to \u003ccode\u003efillna()\u003c/code\u003e. You can also propagate non-null values forward or backward by adding the argument \u003ccode\u003emethod\u003c/code\u003e to the \u003ccode\u003efillna()\u003c/code\u003e function. Pass in \u003ccode\u003effill\u003c/code\u003e or \u003ccode\u003ebfill\u003c/code\u003e to specify you want to fill the values backward or forward.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"drop-labels-with-missing-values\"\u003e\r\n\u003ch4\u003eDrop Labels With Missing Values\u003c/h4\u003e\r\n\r\n\u003cp\u003eTo exclude columns or rows that contain missing values, you can make use of Pandas\u0026rsquo; \u003ccode\u003edropna()\u003c/code\u003e function:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Drop rows with missing values\r\ndf.dropna(axis=0)\r\n\r\n# Drop columns with missing values \r\ndf.dropna(axis=1)\u003c/code\u003e\u003c/pre\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"interpolation\"\u003e\r\n\u003ch4\u003eInterpolation\u003c/h4\u003e\r\n\r\n\u003cp\u003eAlternatively, you can also choose to interpolate missing values: the \u003ccode\u003einterpolate()\u003c/code\u003e function will perform a linear interpolation at the missing data points to \u0026ldquo;guess\u0026rdquo; the value that is most likely to be filled in.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003edf.interpolate()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eYou can also add the \u003ccode\u003emethod\u003c/code\u003e argument to gain access to fancier interpolation methods, such as polynomial interpolation or cubic interpolation, but when you want to use these types of interpolation, you\u0026rsquo;ll need to have SciPy installed.\u003c/p\u003e\r\n\r\n\u003cp\u003eOf course, there are limits to the interpolation, especially if the NaN values for interpolation are too far from the last valid observation. In such cases, you want to add a \u003ccode\u003elimit\u003c/code\u003e argument to the original code. You pass a positive integer to it and this number will determine how many values after a non-NaN value will be filled out. The default limit direction is forward, but also this you can change by adding \u003ccode\u003elimit_direction\u003c/code\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"outliers\"\u003e\r\n\u003ch3\u003eOutliers\u003c/h3\u003e\r\n\r\n\u003cp\u003eJust like missing values, your data might also contain values that diverge heavily from the big majority of your other data. These data points are called \u0026ldquo;outliers\u0026rdquo;. To find them, you can check the distribution of your single variables by means of a box plot or you can make a scatter plot of your data to identify data points that don\u0026rsquo;t lie in the \u0026ldquo;expected\u0026rdquo; area of the plot.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe causes for outliers in your data might vary, going from system errors to people interfering with the data through data entry or data processing, but it\u0026rsquo;s important to consider the effect that they can have on your analysis: they will change the result of statistical tests such as standard deviation, mean or median, they can potentially decrease the normality and impact the results of statistical models, such as regression or ANOVA.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo deal with outliers, you can either delete, transform, or impute them: the decision will again depend on the data context. That\u0026rsquo;s why it\u0026rsquo;s again important to understand your data and identify the cause for the outliers:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eIf the outlier value is due to data entry or data processing errors, you might consider deleting the value.\u003c/li\u003e\r\n\t\u003cli\u003eYou can transform the outliers by assigning weights to your observations or use the natural log to reduce the variation that the outlier values in your data set cause.\u003c/li\u003e\r\n\t\u003cli\u003eJust like the missing values, you can also use imputation methods to replace the extreme values of your data with median, mean or mode values.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eYou can use the functions that were described in the above section to deal with outliers in your data.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"your-datas-features\"\u003e\r\n\u003ch2 id=\"features\"\u003eYour Data\u0026rsquo;s Features\u003c/h2\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that this step is one that you do iteratively with other data science tasks: you\u0026rsquo;ll build your models and validate, but after, you might decide to adjust the features and iterate on building the model again, etc.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"feature-engineering\"\u003e\r\n\u003ch3\u003eFeature Engineering\u003c/h3\u003e\r\n\r\n\u003cp\u003eYou can use feature engineering as a way to increase the predictive power of learning algorithms by creating features from raw data that will help the learning process. You\u0026rsquo;ll do this by creating additional relevant features from the existing raw features in the data.\u003c/p\u003e\r\n\r\n\u003cp\u003eFeature engineering is something that will cost some time to get the hang of; It\u0026rsquo;s not always clear what you can do with the raw data so that you can help the predictive power of the data. But maybe the following list can provide some help when you\u0026rsquo;re looking for ways to engineer features for your dataset:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eFactorize a feature: encode categorical variables into numerical ones with \u003ccode\u003efactorize()\u003c/code\u003e, like in this example:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiIyBGYWN0b3JpemUgdGhlIHZhbHVlcyBcbmxhYmVscyxsZXZlbHMgPSBwZC5mYWN0b3JpemUoaXJpcy5DbGFzcylcblxuIyBTYXZlIHRoZSBlbmNvZGVkIHZhcmlhYmxlcyBpbiBgaXJpcy5DbGFzc2BcbmlyaXMuQ2xhc3MgPSBsYWJlbHNcblxuIyBQcmludCBvdXQgdGhlIGZpcnN0IHJvd3NcbmlyaXMuQ2xhc3MuaGVhZCgpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cul\u003e\r\n\t\u003cli\u003eBin continuous variables in groups: use \u003ccode\u003ecut()\u003c/code\u003e to cut the values for a column in bins\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5XG51cmwgPSBcImh0dHBzOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9waW1hLWluZGlhbnMtZGlhYmV0ZXMvcGltYS1pbmRpYW5zLWRpYWJldGVzLmRhdGFcIlxubmFtZXMgPSBbJ3ByZWcnLCAncGxhcycsICdwcmVzJywgJ3NraW4nLCAndGVzdCcsICdtYXNzJywgJ3BlZGknLCAnYWdlJywgJ2NsYXNzJ11cbmRmID0gcGQucmVhZF9jc3YodXJsLCBuYW1lcz1uYW1lcylcbmFycmF5ID0gZGYudmFsdWVzXG5YID0gYXJyYXlbOiwwOjhdXG5ZID0gYXJyYXlbOiw4XSIsInNhbXBsZSI6IiMgRGVmaW5lIHlvdXIgb3duIGJpbnNcbm15YmlucyA9IHJhbmdlKDAsIGRmLmFnZS5tYXgoKSwgMTApXG5cbiMgQ3V0IHRoZSBkYXRhIHdpdGggdGhlIGhlbHAgb2YgdGhlIGJpbnNcbmRmWydhZ2VfYnVja2V0J10gPSBwZC5jdXQoZGYuYWdlLCBiaW5zPW15YmlucylcblxuIyBDb3VudCB0aGUgbnVtYmVyIG9mIHZhbHVlcyBwZXIgYnVja2V0XG5kZlsnYWdlX2J1Y2tldCddLnZhbHVlX2NvdW50cygpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cul\u003e\r\n\t\u003cli\u003eScale features: center your data around 0. You can make use of Scikit-Learn\u0026rsquo;s preprocessing module:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaW1wb3J0IG51bXB5XG51cmwgPSBcImh0dHBzOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9waW1hLWluZGlhbnMtZGlhYmV0ZXMvcGltYS1pbmRpYW5zLWRpYWJldGVzLmRhdGFcIlxubmFtZXMgPSBbJ3ByZWcnLCAncGxhcycsICdwcmVzJywgJ3NraW4nLCAndGVzdCcsICdtYXNzJywgJ3BlZGknLCAnYWdlJywgJ2NsYXNzJ11cbmRhdGFmcmFtZSA9IHBkLnJlYWRfY3N2KHVybCwgbmFtZXM9bmFtZXMpXG5hcnJheSA9IGRhdGFmcmFtZS52YWx1ZXNcblggPSBhcnJheVs6LDA6OF1cblkgPSBhcnJheVs6LDhdIiwic2FtcGxlIjoiZnJvbSBza2xlYXJuLnByZXByb2Nlc3NpbmcgaW1wb3J0IFN0YW5kYXJkU2NhbGVyXG5cbnNjYWxlciA9IFN0YW5kYXJkU2NhbGVyKCkuZml0KFgpXG5cbnJlc2NhbGVkWCA9IHNjYWxlci50cmFuc2Zvcm0oWCkifQ==\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e: look into the preprocessing module of Scikit-Learn more closely, you\u0026rsquo;ll see that it contains some handy functions that will help you to come up with new features for your data!\u003c/p\u003e\r\n\r\n\u003cp\u003eNote that these are just some of the ways in which you can engineer new features to make your data more predictive! The key is to brainstorm new features or combine old features together and try to test their effectiveness with Scikit-Learn.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"feature-selection\"\u003e\r\n\u003ch3\u003eFeature Selection\u003c/h3\u003e\r\n\r\n\u003cp\u003eWhen you select features, you select the key subset of original data features in an attempt to reduce the dimensionality of the training problem. This seems very similar to other dimensionality reduction techniques that you might already know, such as PCA. Yet, there is a difference: PCA combines similar (correlated) attributes and creates new ones that are considered superior to the original attributes of the dataset. Feature selection doesn\u0026rsquo;t combine attributes: it evaluates the quality and predictive power and selects the best set.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo find important features, you can make use of the RandomForest algorithm: it randomly generates thousands of decision trees and takes turns leaving out each variable in fitting the model. This way, you can calculate how much better or worse a model does when you leave one variable out of the equation. You can use the Scikit-Learn Python library to implement this algorithm:\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"500\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pIiwic2FtcGxlIjoiIyBJbXBvcnQgYFJhbmRvbUZvcmVzdENsYXNzaWZpZXJgXG5mcm9tIHNrbGVhcm4uZW5zZW1ibGUgaW1wb3J0IFJhbmRvbUZvcmVzdENsYXNzaWZpZXJcblxuIyBJc29sYXRlIERhdGEsIGNsYXNzIGxhYmVscyBhbmQgY29sdW1uIHZhbHVlc1xuWCA9IGlyaXMuaWxvY1s6LDA6NF1cblkgPSBpcmlzLmlsb2NbOiwtMV1cbm5hbWVzID0gaXJpcy5jb2x1bW5zLnZhbHVlc1xuXG4jIEJ1aWxkIHRoZSBtb2RlbFxucmZjID0gUmFuZG9tRm9yZXN0Q2xhc3NpZmllcigpXG5cbiMgRml0IHRoZSBtb2RlbFxucmZjLmZpdChYLCBZKVxuXG4jIFByaW50IHRoZSByZXN1bHRzXG5wcmludChcIkZlYXR1cmVzIHNvcnRlZCBieSB0aGVpciBzY29yZTpcIilcbnByaW50KHNvcnRlZCh6aXAobWFwKGxhbWJkYSB4OiByb3VuZCh4LCA0KSwgcmZjLmZlYXR1cmVfaW1wb3J0YW5jZXNfKSwgbmFtZXMpLCByZXZlcnNlPVRydWUpKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;ll see that the best feature set is one that includes the petal length and petal width data.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003ca href=\"https://www.datacamp.com/courses/\" target=\"_blank\"\u003e\u003cimg alt=\"Exploratory Data Analysis with Python\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/293/content_blog_banner.png\" /\u003e\u003c/a\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that you can also visualize the results of the feature selection with Matplotlib:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import `pyplot` and `numpy`\r\nimport matplotlib.pyplot as plt\r\nimport numpy as np\r\n\r\n# Isolate feature importances \r\nimportance = rfc.feature_importances_\r\n\r\n# Sort the feature importances \r\nsorted_importances = np.argsort(importance)\r\n\r\n# Insert padding\r\npadding = np.arange(len(names)-1) + 0.5\r\n\r\n# Plot the data\r\nplt.barh(padding, importance[sorted_importances], align='center')\r\n\r\n# Customize the plot\r\nplt.yticks(padding, names[sorted_importances])\r\nplt.xlabel(\"Relative Importance\")\r\nplt.title(\"Variable Importance\")\r\n\r\n# Show the plot\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Feature selection Pandas\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/427/content_image1_pandas.png\" /\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\r\n\u003cdiv class=\"section level2\" id=\"patterns-in-your-data\"\u003e\r\n\u003ch2 id=\"patterns\"\u003ePatterns In Your Data\u003c/h2\u003e\r\n\r\n\u003cp\u003eOne of the next steps that you can take in the exploration of your data is the identification of patterns in your data, which includes correlation between data attributes or between missing data. One of the things that can help in doing this is the visualization of your data; And this doesn\u0026rsquo;t need to be static: dare to go for interactive visualizations of your data with the Python libraries Bokeh or Plotly.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"correlation-identification-with-matplotlib\"\u003e\r\n\u003ch3\u003eCorrelation Identification With Matplotlib\u003c/h3\u003e\r\n\r\n\u003cp\u003eNow that you have looked at the numbers and analyzed your data in a quantitative way, you\u0026rsquo;ll also find it useful to consider you data in a visual way. It\u0026rsquo;s time to also explore the data visually.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo easily and quickly do this, you can make use of the Python data visualization library Matplotlib. The only thing that stands in your way is, ironically, your data: as you are well aware, your data has 64 columns or features. When you have so many features, it\u0026rsquo;s said that you\u0026rsquo;re working with high dimensional data.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhat dimensional data exactly is, you\u0026rsquo;ll learn in our machine learning tutorial, but for now it\u0026rsquo;s good to understand that, if you want to visualize your data in a 2D or 3D plot, you\u0026rsquo;ll need your data to only have two or three dimensions. This means that you\u0026rsquo;ll need to reduce your data\u0026rsquo;s dimensions.\u003c/p\u003e\r\n\r\n\u003cp\u003eThis means that you\u0026rsquo;ll have to make use of Dimensionality Reduction techniques, such as Principal Component Analysis (PCA):\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"350\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuZGlnaXRzID0gcGQucmVhZF9jc3YoXCJodHRwOi8vYXJjaGl2ZS5pY3MudWNpLmVkdS9tbC9tYWNoaW5lLWxlYXJuaW5nLWRhdGFiYXNlcy9vcHRkaWdpdHMvb3B0ZGlnaXRzLnRyYVwiLFxuICAgICAgICAgICAgICAgICAgICAgaGVhZGVyPU5vbmUpIiwic2FtcGxlIjoiIyBJbXBvcnQgYFBDQWAgZnJvbSBgc2tsZWFybi5kZWNvbXBvc2l0aW9uYFxuZnJvbSBza2xlYXJuLmRlY29tcG9zaXRpb24gaW1wb3J0IF9fX1xuXG4jIEJ1aWxkIHRoZSBtb2RlbFxucGNhID0gUENBKG5fY29tcG9uZW50cz0yKVxuXG4jIFJlZHVjZSB0aGUgZGF0YSwgb3V0cHV0IGlzIG5kYXJyYXlcbnJlZHVjZWRfZGF0YSA9IHBjYS5maXRfdHJhbnNmb3JtKF9fX19fX18pXG5cbiMgSW5zcGVjdCB0aGUgc2hhcGUgb2YgYHJlZHVjZWRfZGF0YWBcbnJlZHVjZWRfZGF0YS5fX19fX19cblxuIyBwcmludCBvdXQgdGhlIHJlZHVjZWQgZGF0YVxucHJpbnQoX19fX19fX19fX19fX19fKSIsInNvbHV0aW9uIjoiIyBJbXBvcnQgYFBDQWAgZnJvbSBgc2tsZWFybi5kZWNvbXBvc2l0aW9uYFxuZnJvbSBza2xlYXJuLmRlY29tcG9zaXRpb24gaW1wb3J0IFBDQVxuXG4jIEJ1aWxkIHRoZSBtb2RlbFxucGNhID0gUENBKG5fY29tcG9uZW50cz0yKVxuXG4jIFJlZHVjZSB0aGUgZGF0YSwgb3V0cHV0IGlzIG5kYXJyYXlcbnJlZHVjZWRfZGF0YSA9IHBjYS5maXRfdHJhbnNmb3JtKGRpZ2l0cylcblxuIyBJbnNwZWN0IHNoYXBlIG9mIHRoZSBgcmVkdWNlZF9kYXRhYFxucmVkdWNlZF9kYXRhLnNoYXBlXG5cbiMgcHJpbnQgb3V0IHRoZSByZWR1Y2VkIGRhdGFcbnByaW50KHJlZHVjZWRfZGF0YSkiLCJzY3QiOiJ0ZXN0X2ltcG9ydChcInNrbGVhcm4uZGVjb21wb3NpdGlvbi5QQ0FcIilcbnRlc3Rfb2JqZWN0KFwicGNhXCIsIGRvX2V2YWw9RmFsc2UpXG50ZXN0X29iamVjdChcInJlZHVjZWRfZGF0YVwiLCBkb19ldmFsPUZhbHNlKVxucHJlZGVmX21zZz1cIkRpZCB5b3UgaW5zcGVjdCB0aGUgc2hhcGUgb2YgYHJlZHVjZWRfZGF0YWA/XCJcbnRlc3Rfb2JqZWN0X2FjY2Vzc2VkKFwicmVkdWNlZF9kYXRhLnNoYXBlXCIsIG5vdF9hY2Nlc3NlZF9tc2c9cHJlZGVmX21zZylcbiMgVGVzdCBgcHJpbnRgIFxudGVzdF9mdW5jdGlvbihcbiAgICBcInByaW50XCIsXG4gICAgbm90X2NhbGxlZF9tc2c9XCJEaWQgeW91IHByaW50IG91dCB0aGUgYHJlZHVjZWRfZGF0YV9ycGNhYCBkYXRhP1wiLFxuICAgIGluY29ycmVjdF9tc2c9XCJEb24ndCBmb3JnZXQgdG8gcHJpbnQgb3V0IHRoZSBgcmVkdWNlZF9kYXRhX3JwY2FgIGRhdGEhXCIsXG4gICAgZG9fZXZhbD1GYWxzZVxuKVxuc3VjY2Vzc19tc2coXCJBbWF6aW5nIVwiKSJ9\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003eWhen you inspect the reduced data, that the columns or features have now been reduced to only two. The number of rows or observations is still the same, namely, 3823. And now that your data is in the right format, it\u0026rsquo;s time to get to the plotting!\u003c/p\u003e\r\n\r\n\u003cp\u003eThe choice of the right plot is already a great start, but what will you choose?\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, you\u0026rsquo;re exploring the data, so you probably want to discover possible correlations between the attributes of your data. A scatter plot is probably a good way to visualize this: it allows you to identify a relationship between the two features that you have gained from the dimensionality reduction.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003eimport matplotlib.pyplot as plt\r\n\r\nplt.scatter(reduced_data[:,0], reduced_data[:,1], c=labels, cmap = 'viridis')\r\n\r\nplt.show()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Correlation Python\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Python+EDA+Tutorial/content_content_unknown.png\" /\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003cbr\u003e\r\n\u003cdiv class=\"section level3\" id=\"correlation-identification-with-bokeh\"\u003e\r\n\u003ch3\u003eCorrelation Identification With Bokeh\u003c/h3\u003e\r\n\r\n\u003cp\u003eSecondly, you can also consider using Bokeh to construct an interactive plot to discover correlations between the attributes in your data. The Bokeh library is a Python interactive visualization library that targets modern web browsers for presentation. It\u0026rsquo;s ideal if you\u0026rsquo;re working with large or streaming datasets, but as you can see in the following example, you can also use it for \u0026ldquo;regular\u0026rdquo; data.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe code is very simple: you import the necessary modules, construct the scatter plot, configure the default output state to generate output saved to a file when show() is called. Finally, you call \u003ccode\u003eshow()\u003c/code\u003e to see the scatter plot that you have constructed!\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode\u003e# Import the necessary modules\r\nfrom bokeh.charts import Scatter, output_file, show\r\n\r\n# Construct the scatter plot\r\np = Scatter(iris, x='Petal_length', y='Petal_width', color=\"Class\", title=\"Petal Length vs Petal Width\",\r\n            xlabel=\"Sepal Length\", ylabel=\"Sepal Width\")\r\n\r\n# Output the file \r\noutput_file('scatter.html')\r\n\r\n# Show the scatter plot\r\nshow(p)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThe result is elegant:\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cimg alt=\"Python data exploration\" src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/430/content_bokeh_plot_1.png\" /\u003e\u003c/p\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eNote that this is a static, saved image of the plot but that the resulting plot in your notebook or terminal will be interactive! Of course, this is just one simple example of how you can use Bokeh to make interactive graphs. Make sure to check out the Bokeh Gallery for more inspiration or take DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/courses/interactive-data-visualization-with-bokeh/\"\u003eInteractive Data Visualization with Bokeh\u003c/a\u003e course.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"correlation-identification-with-pandas\"\u003e\r\n\u003ch3\u003eCorrelation Identification With Pandas\u003c/h3\u003e\r\n\r\n\u003cp\u003eThe plots that you have seen in the previous sections are a visual way of exploring correlation between the attributes of your data. But that doesn\u0026rsquo;t mean that you can not explore this measure in a quantitative way! And when you do decide to do this, make use of Pandas\u0026rsquo; \u003ccode\u003ecorr()\u003c/code\u003e function. But do note that the NaN or null values are excluded in this computation!\u003c/p\u003e\r\n\r\n\u003cdiv data-datacamp-exercise=\"\" data-encoded=\"true\" data-height=\"300\"\u003eeyJsYW5ndWFnZSI6InB5dGhvbiIsInByZV9leGVyY2lzZV9jb2RlIjoiaW1wb3J0IHBhbmRhcyBhcyBwZFxuaXJpcyA9IHBkLnJlYWRfY3N2KFwiaHR0cHM6Ly9hcmNoaXZlLmljcy51Y2kuZWR1L21sL21hY2hpbmUtbGVhcm5pbmctZGF0YWJhc2VzL2lyaXMvaXJpcy5kYXRhXCIsIFxuICAgICAgICAgICAgICAgICAgc2VwPVwiLFwiLCBcbiAgICAgICAgICAgICAgICAgIGhlYWRlcj1Ob25lLFxuICAgICAgICAgICAgICAgICAgbmFtZXM9WydTZXBhbF9sZW5ndGgnLCAnU2VwYWxfd2lkdGgnLCAnUGV0YWxfbGVuZ3RoJywgJ1BldGFsX3dpZHRoJywgJ0NsYXNzJ10pXG5pcmlzID0gaXJpcy5yYW5rKCkiLCJzYW1wbGUiOiIjIFBlYXJzb24gY29ycmVsYXRpb25cbmlyaXMuY29ycigpXG5cbiMgS2VuZGFsbCBUYXUgY29ycmVsYXRpb25cbmlyaXMuY29ycigna2VuZGFsbCcpXG5cbiMgU3BlYXJtYW4gUmFuayBjb3JyZWxhdGlvblxuaXJpcy5jb3JyKCdzcGVhcm1hbicpIn0=\u003c/div\u003e\r\n\u003cbr\u003e\u003cbr\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that the two last correlation measures require you to rank the data before calculating the coefficients. You can easily do this with \u003ccode\u003erank()\u003c/code\u003e: for the exercise above, the \u003ccode\u003eiris\u003c/code\u003e data was ranked by executing \u003ccode\u003eiris.rank()\u003c/code\u003e for you.\u003c/p\u003e\r\n\r\n\u003cp\u003eFurthermore, there are some assumptions that these correlations work with: the Pearson correlation assumes that your variables are normally distributed, that there is a straight line relationship between each of the variables and that the data is normally distributed about the regression line. The Spearman correlation, on the other hand, assumes that you have two ordinal variables or two variables that are related in some way, but not linearly.\u003c/p\u003e\r\n\r\n\u003cp\u003eThe Kendall Tau correlation is a coefficient that represents the degree of concordance between two columns of ranked data. You can use the Spearman correlation to measure the degree of association between two variables. These seem very similar to each other, don\u0026rsquo;t they?\u003c/p\u003e\r\n\r\n\u003cp\u003eEven though the Kendal and the Spearman correlation measures seem similar, but they do differ: the exact difference lies in the fact that the calculations are different. The Kendal Tau coefficient is calculated by the number of concordant pairs minus the number of discordant pairs divided by the total number of pairs. The Spearman coefficient is the sum of deviation squared by \u003ccode\u003en\u003c/code\u003e times \u003ccode\u003en\u003c/code\u003e minus 1.\u003c/p\u003e\r\n\r\n\u003cp\u003eSpearman\u0026rsquo;s coefficient will usually be larger than the Kendall\u0026rsquo;s Tau coefficient, but this is not always the case: you\u0026rsquo;ll get a smaller Spearman\u0026rsquo;s coefficient when the deviations are huge among the observations of your data. The Spearman correlation is very sensitive to this and this might come in handy in some cases!\u003c/p\u003e\r\n\r\n\u003cp\u003eSo, when do you want to use which coefficient, because the two of these correlation actually test something different; Kendall\u0026rsquo;s Tau is representing the proportion of concordant pairs relative to discordant pairs and the Spearman\u0026rsquo;s coefficient doesn\u0026rsquo;t do that. You can also argue that the Kendall Tau correlation has a more intuitive interpretation and easier to calculate, that it gives a better estimate of the corresponding population parameter and that the p values are more accurate in small sample sizes.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eTip\u003c/strong\u003e add the \u003ccode\u003eprint()\u003c/code\u003e function to see the results of the specific pairwise correlation compututations of columns.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"onwards\"\u003e\r\n\u003ch2\u003eOnwards!\u003c/h2\u003e\r\n\r\n\u003cp\u003eCongrats, you have made it to the end of our Pandas tutorial! You now have some mastered some of the basic techniques that you can use to explore your data with Python.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf you want to deep dive into the topic even further, our Pandas course series is perfect: check out our \u003ca href=\"https://www.datacamp.com/courses/pandas-foundations/\"\u003ePandas Foundations\u003c/a\u003e, \u003ca href=\"https://www.datacamp.com/courses/merging-dataframes-with-pandas/\"\u003eMerging DataFrames with Pandas\u003c/a\u003e or \u003ca href=\"https://www.datacamp.com/courses/manipulating-dataframes-with-pandas/\"\u003eManipulating DataFrames with Pandas\u003c/a\u003e courses.\u003c/p\u003e\r\n\r\n\u003cp\u003eIf, however, you\u0026rsquo;re ready to move on from Pandas and explore the Matplotlib package some more, consider taking DataCamp\u0026rsquo;s \u003ca href=\"https://www.datacamp.com/community/tutorials/matplotlib-tutorial-python/\"\u003ePython data visualization tutorial\u003c/a\u003e or start modelling your data! Continue to our \u003ca href=\"https://www.datacamp.com/community/tutorials/machine-learning-python/\"\u003emachine learning tutorial\u003c/a\u003e to find out how you can build a machine learning model to recognize the handwritten digits automatically!\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/nav\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/exploratory-data-analysis-python","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Python Exploratory Data Analysis Tutorial","seoMetaDescription":"Learn the basics of Exploratory Data Analysis (EDA) in Python with Pandas, Matplotlib and NumPy, such as sampling, feature engineering, correlation, etc.","seoKeyword":"Python EDA tutorial","mustRead":false,"programmingLanguage":null,"submissionDate":"2017-03-15T17:32:16.000Z","publishDate":"2017-03-15T18:59:41.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":19506,"createdAt":"2017-09-08T15:37:25.446Z","updatedAt":"2019-07-01T03:34:18.162Z","upvoting":{"voteCount":86,"voted":false},"tags":["python","data manipulation","data analysis","pandas","numpy"],"author":{"id":494311,"slug":"karlijn","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/494/311/square/Screenshot_2017-04-26_16.02.58.png?1493215479","fullName":"Karlijn Willems","nameFromEmail":"karlijn","isAdmin":false},"recommendedArticles":[{"id":318,"externalId":null,"type":"Tutorial","status":"published","authorId":"nickhould","title":"Exploratory Data Analysis of Craft Beers: Data Profiling","slug":"python-data-profiling","previewSlug":null,"description":"In this tutorial, you'll learn about exploratory data analysis (EDA) in Python, and more specifically, data profiling with pandas.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003e\u003cem\u003eEditor's note: \u003ca href=\"http://www.jeannicholashould.com/\"\u003eJean-Nicholas Hould\u003c/a\u003e is a data scientist at Intel Security in Montreal and he \u003ca href=\"http://www.jeannicholashould.com/\"\u003eteaches how to get started in data science on his blog\u003c/a\u003e.\u003c/em\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eExploratory data analysis (\u003cem\u003eEDA\u003c/em\u003e) is a statistical approach that aims at discovering and summarizing a dataset. At this step of the data science process, you want to explore the structure of your dataset, the variables and their relationships.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this post, you\u0026rsquo;ll focus on one aspect of exploratory data analysis: data profiling.\u003c/p\u003e\r\n\r\n\u003cp\u003eData profiling is all about summarizing your dataset through descriptive statistics. You want to use a plethora of measurements to better understand your dataset. Data types, missing values, mean, median and standard deviation are just a few of the many elements you\u0026rsquo;ll need to gather when profiling a dataset. The goal of data profiling is to have a solid understanding of your data so you can afterwards start querying and visualizing your data in various ways.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"know-where-your-data-comes-from\"\u003e\r\n\u003ch2\u003eKnow Where Your Data Comes From\u003c/h2\u003e\r\n\r\n\u003cp\u003eBefore jumping in any EDA, you should know as much as possible on the provenance of the data you are analyzing. You need to understand how the data was collected and how it was processed. Are there any past transformations on the data that could affect your analysis?\u003c/p\u003e\r\n\r\n\u003cp\u003eYou should be able to answer those questions on your dataset:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eHow was it collected?\u003c/li\u003e\r\n\t\u003cli\u003eIs it a \u003ca href=\"https://en.wikipedia.org/wiki/Sample_(statistics)\"\u003esample\u003c/a\u003e?\u003c/li\u003e\r\n\t\u003cli\u003eWas it properly sampled?\u003c/li\u003e\r\n\t\u003cli\u003eWas the dataset transformed in any way?\u003c/li\u003e\r\n\t\u003cli\u003eAre there some know problems on the dataset?\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eIf you don\u0026rsquo;t understand where the data is coming from, you will have a hard time drawing any meaningful conclusions from the dataset. You are also at risk of making very important analysis mistakes.\u003c/p\u003e\r\n\r\n\u003cp\u003eAdditionally, you should make sure the dataset is structured in a standardized manner. The recommended format is the third normal form, also named \u003ca href=\"http://vita.had.co.nz/papers/tidy-data.pdf\"\u003etidy data\u003c/a\u003e. A \u0026ldquo;tidy\u0026rdquo; dataset has the following attributes:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eEach variable forms a column and contains values\u003c/li\u003e\r\n\t\u003cli\u003eEach observation forms a row\u003c/li\u003e\r\n\t\u003cli\u003eEach type of observational unit forms a table\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eRespecting this standardized format will speed up your analysis since this it\u0026rsquo;s compatible with many tools and libraries.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"data-profiling\"\u003e\r\n\u003ch2\u003eData Profiling\u003c/h2\u003e\r\n\r\n\u003cp\u003eIn this post, you will use a dataset of Craft Beers from the CraftCans website. This dataset only contains data from \u003cstrong\u003ecanned\u003c/strong\u003e beers from breweries in the \u003cstrong\u003eUnited States\u003c/strong\u003e. It\u0026rsquo;s not clear from the website if this dataset reports every single canned beer brewed in the US or not. To be safe, you will consider this dataset to be a sample that may contain biases.\u003c/p\u003e\r\n\r\n\u003cp\u003eHere is the structure of the datasets you\u0026rsquo;ll be using:\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003cstrong\u003eBeers:\u003c/strong\u003e\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eID\u003c/code\u003e: Unique identifier of the beer.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eName\u003c/code\u003e: Name of the beer.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eABV\u003c/code\u003e: Alcohol by volume of the beer.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e: International Bittering Units of the beer.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eStyle\u003c/code\u003e: Style of the beer.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eOunces\u003c/code\u003e: Ounces of beer.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003e\u003cstrong\u003eBreweries:\u003c/strong\u003e\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eID\u003c/code\u003e: Unique identifier of the brewery.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eName\u003c/code\u003e: Name of the brewery.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eCity\u003c/code\u003e: City where the brewery is located.\u003c/li\u003e\r\n\t\u003cli\u003e\u003ccode class=\"lang-python\"\u003eState\u003c/code\u003e: State where the brewery is located.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cdiv class=\"section level3\" id=\"data-types\"\u003e\r\n\u003ch3\u003eData Types\u003c/h3\u003e\r\n\r\n\u003cp\u003eThe first step is to understand the composition of your dataset.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhat variables are you dealing with?\u003c/p\u003e\r\n\r\n\u003cp\u003eYou can generally fit the data in one of those categories:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003eNumerical\u003c/li\u003e\r\n\t\u003cli\u003eCategorical\u003c/li\u003e\r\n\t\u003cli\u003eText\u003c/li\u003e\r\n\t\u003cli\u003eDate\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eYou\u0026rsquo;ll first import the datasets that you can find in \u003ca href=\"https://github.com/nickhould/craft-beers-dataset\"\u003ethis repository\u003c/a\u003e with pandas\u0026rsquo; \u003ccode class=\"lang-python\"\u003efrom_csv\u003c/code\u003e function. You\u0026rsquo;ll also join the \u003ccode class=\"lang-python\"\u003ebeers\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003ebreweries\u003c/code\u003e datasets together to facilitate analysis down the road.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eimport pandas as pd\r\n\r\nbeers = pd.DataFrame.from_csv(\"https://raw.githubusercontent.com/nickhould/craft-beers-dataset/master/data/craftcans_beers.csv\")\r\nbreweries = pd.DataFrame.from_csv(\"https://raw.githubusercontent.com/nickhould/craft-beers-dataset/master/data/craftcans_breweries.csv\")\r\n\r\nbeers_and_breweries = pd.merge(beers, \r\n                               breweries, \r\n                               how='inner', \r\n                               left_on=\"brewery_id\", \r\n                               right_on=\"id\", \r\n                               sort=True,\r\n                               suffixes=('_beer', '_brewery'))\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWith the pandas library, you can run the function \u003ccode class=\"lang-python\"\u003edtypes\u003c/code\u003e to list each column and their data types.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ebeers.dtypes\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWhich gives you the following result:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eabv           float64\r\nibu           float64\r\nid              int64\r\nname           object\r\nstyle          object\r\nbrewery_id      int64\r\nounces        float64\r\ndtype: object\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eAs you can see above, that function doesn\u0026rsquo;t do a clean grouping of the different data types. The various numerical data types (\u003ccode class=\"lang-python\"\u003efloat64\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003eint64\u003c/code\u003e) are not grouped into a single category as we would like to. Also, some columns are listed as objects which is not very helpful.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo go around this, you can build your own function that will determine the category of each column in a \u003ccode class=\"lang-python\"\u003eDataFrame\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003edef get_var_category(series):\r\n    unique_count = series.nunique(dropna=False)\r\n    total_count = len(series)\r\n    if pd.api.types.is_numeric_dtype(series):\r\n        return 'Numerical'\r\n    elif pd.api.types.is_datetime64_dtype(series):\r\n        return 'Date'\r\n    elif unique_count==total_count:\r\n        return 'Text (Unique)'\r\n    else:\r\n        return 'Categorical'\r\n\r\ndef print_categories(df):\r\n    for column_name in df.columns:\r\n        print(column_name, \": \", get_var_category(df[column_name]))\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"beers-variables\"\u003e\r\n\u003ch4\u003e\u003ccode class=\"lang-python\"\u003eBeers\u003c/code\u003e Variables\u003c/h4\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eprint_categories(beers)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThe command above gives you back the following result:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eabv :  Numerical\r\nibu :  Numerical\r\nid :  Numerical\r\nname :  Categorical\r\nstyle :  Categorical\r\nbrewery_id :  Numerical\r\nounces :  Numerical\u003c/code\u003e\u003c/pre\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"breweries-variables\"\u003e\r\n\u003ch4\u003e\u003ccode class=\"lang-python\"\u003eBreweries\u003c/code\u003e Variables\u003c/h4\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eprint_categories(breweries)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWhich gives you the following result:\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ename :  Categorical\r\ncity :  Categorical\r\nstate :  Categorical\r\nid :  Numerical\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eWith this information, you can already better understand our dataset. You know that you are dealing only with categorical and numerical data. Numerical variables can be used to extract many different measurements such as the mean, standard deviation, etc. Categorical variables are generally an interesting way of segmenting and grouping the data. For example, you might want to understand how the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e differs between the various styles of beers.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"descriptive-statistics\"\u003e\r\n\u003ch3\u003eDescriptive Statistics\u003c/h3\u003e\r\n\r\n\u003cp\u003eIn this section, you\u0026rsquo;ll walk through various descriptive statistics that can be used to better understand our data. You\u0026rsquo;ll notice that each of those measurements in isolation is not very helpful. The combination of those different measurement is where you can extract the most value.\u003c/p\u003e\r\n\r\n\u003cp\u003eYou will focus on the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e variable because it is a numerical variable. This type of variable offers a broader range of measurements than the categorical variables. You can still run measurements on your categorical variables but you will be much more limited.\u003c/p\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"length\"\u003e\r\n\u003ch4\u003eLength\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe \u003ccode class=\"lang-python\"\u003elen\u003c/code\u003e function counts the number of observations in a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e. The function will count all observations, regardless if there are missing or null values.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003elength = len(beers[\"ibu\"])\r\nprint(length)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eIn this \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e we have a total of 2410 observations.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"count\"\u003e\r\n\u003ch4\u003eCount\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe \u003ccode class=\"lang-python\"\u003ecount\u003c/code\u003e function will return the number of non-NA/non-null observations in a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ecount = beers[\"ibu\"].count()\r\nprint(count)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eAs you can see, you have 1405 non-null observations in the \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"missing-values\"\u003e\r\n\u003ch4\u003eMissing Values\u003c/h4\u003e\r\n\r\n\u003cp\u003eWith the \u003ccode class=\"lang-python\"\u003eLength\u003c/code\u003e and the \u003ccode class=\"lang-python\"\u003eCount\u003c/code\u003e, we are now able to calculate the number of missing values. The number of missing values is the difference between the \u003ccode class=\"lang-python\"\u003eLength\u003c/code\u003e and the \u003ccode class=\"lang-python\"\u003eCount\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003enumber_of_missing_values = length - count\r\npct_of_missing_values = float(number_of_missing_values / length)\r\npct_of_missing_values = \"{0:.1f}%\".format(pct_of_missing_values*100)\r\nprint(pct_of_missing_values)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eTo output the missing values as a percentage, you simply divide the number of missing values by the total number of observations, the length. The \u003ccode class=\"lang-python\"\u003efloat\u003c/code\u003e function is used to make sure the decimals are captured in the division. The \u003ccode class=\"lang-python\"\u003eformat\u003c/code\u003e function is used to nicely format the number as a percentage.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, you are missing almost 42% of the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e variable. This is important for you to know because it will affect your analysis. Most of the descriptive statistics will ignore those missing values and this will certainly cause a bias.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"minimummaximum-value\"\u003e\r\n\u003ch4\u003eMinimum/Maximum Value\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe minimum and maximum value of a dataset can easily be obtained with the \u003ccode class=\"lang-python\"\u003emin\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003emax\u003c/code\u003e function on a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eprint(\"Minimum value: \", beers[\"ibu\"].min())\r\nprint(\"Maximum value: \", beers[\"ibu\"].max())\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThe min/max values are helpful to understand the range of values in a variable. In this case, the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e ranges from 4 to 138.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"mode\"\u003e\r\n\u003ch4\u003eMode\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe mode is the most frequent value in a dataset. It can be obtained using the \u003ccode class=\"lang-python\"\u003emode\u003c/code\u003e function on a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eprint(beers[\"ibu\"].mode())\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eIn a normal distribution, the mode is equal to the \u003ccode class=\"lang-python\"\u003emean\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003emedian\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this case, the mode of the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e variable is \u003ccode class=\"lang-python\"\u003e20\u003c/code\u003e. It is the most frequent \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e in our dataset.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"mean\"\u003e\r\n\u003ch4\u003eMean\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe mean is a measure of central tendency. It represents the sum of the values divided by the count of non-missing observations.\u003c/p\u003e\r\n\r\n\u003cp\u003eIt can be obtained with the \u003ccode class=\"lang-python\"\u003emean\u003c/code\u003e function on a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003emean = beers[\"ibu\"].mean()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eThe mean is prone to be influenced by outliers. A few extreme values can greatly change the mean, dragging it up or down.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"median\"\u003e\r\n\u003ch4\u003eMedian\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe median is also a measure of central tendency. It is the number exactly in the middle of an ordered list of numerical values.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003emedian = beers[\"ibu\"].median()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eIn the case of skewed distributions, the median is a much better measure of central tendency than the mean.\u003c/p\u003e\r\n\r\n\u003cp\u003eIn the case of the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e distribution, the mean and the median are in the same orders of magnitude.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"standard-deviation\"\u003e\r\n\u003ch4\u003eStandard Deviation\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe standard deviation is a measure of dispersion. A high standard deviation indicates the data points are spread over a wide range of values. The standard deviation is expressed in the same unit as the values.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003estandarddev = beers[\"ibu\"].std()\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003eIn this case, the standard deviation is ~26. 25.954065911259324 to be exact. If the distribution of \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e was a normal distribution, you would know that ~68% of the observations are within one standard deviation of the mean.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"quantile-statistics\"\u003e\r\n\u003ch4\u003eQuantile Statistics\u003c/h4\u003e\r\n\r\n\u003cp\u003eQuantiles are cut points that split a distribution in equal sizes. Many quantiles have their own name. If you split a distribution into four equal groups, the quantile you created is named \u003ccode class=\"lang-python\"\u003equartile\u003c/code\u003e. You can easily create quantile using the \u003ccode class=\"lang-python\"\u003equantile\u003c/code\u003e function on a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e. You can pass to that function an array with the different quantiles to compute. In the case below, we want to split our distribution in four equal groups.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003equantile = beers[\"ibu\"].quantile([.25, .5, .75])\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003e\u0026nbsp;\u003c/p\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable\u003e\r\n  \u003ctr\u003e\r\n    \u003ctd\u003e0.25\u003c/td\u003e\r\n    \u003ctd\u003e21.0\u003c/td\u003e\r\n  \u003c/tr\u003e\r\n  \u003ctr\u003e\r\n    \u003ctd\u003e0.50\u003c/td\u003e\r\n    \u003ctd\u003e35.0\u003c/td\u003e\r\n  \u003c/tr\u003e\r\n  \u003ctr\u003e\r\n    \u003ctd\u003e0.75\u003c/td\u003e\r\n    \u003ctd\u003e64.0\u003c/td\u003e\r\n  \u003c/tr\u003e\r\n  \u003ctr\u003e\r\n    \u003ctd\u003eName: ibu,\u003c/td\u003e\r\n    \u003ctd\u003edtype: float64\u003c/td\u003e\r\n  \u003c/tr\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003cp\u003eAs you can see above, the 50% quantile is equal to the median. It is the value that splits the dataset in half. You can also note that 75% of the observations are equal or below to 64 \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e. Furthermore, 50% of the distribution is located between 21 and 64 \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e. It\u0026rsquo;s important to note that the missing values are not taken into account in those metrics.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"distribution-plots\"\u003e\r\n\u003ch4\u003eDistribution Plots\u003c/h4\u003e\r\n\r\n\u003cp\u003eVisualizations are very useful in exploratory data analysis. In this post, we will not go over the topic visualizations. However, we can\u0026rsquo;t talk about data profiling without mentioning the importance of a frenquency-distribution plot. It is one of the simplest yet most powerful visualization. It demonstrates the frequency of each value in our dataset.\u003c/p\u003e\r\n\r\n\u003cp\u003eTo create this visualization, we are using the \u003ccode class=\"lang-python\"\u003eseaborn`` library with the\u003c/code\u003edisplot\u003ccode class=\"lang-python\"\u003efunction. This function expects a\u003c/code\u003eSeries` with no missing values.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eimport seaborn as sns\r\nsns.set(color_codes=True)\r\nsns.set_palette(sns.color_palette(\"muted\"))\r\n\r\nsns.distplot(beers[\"ibu\"].dropna());\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003e\u003cimg src=\"http://community.datacamp.com.s3.amazonaws.com/community/production/ckeditor_assets/pictures/471/content_dataprofiling-image1.png\" /\u003e\u003c/p\u003e\r\n\r\n\u003cp\u003eIn this distribution plot, you can clearly see a few of the values we previously calculated. The minimal value is close to 0 \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e and the maximum value is close to 140 \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e. You clearly see that the most frequent value is close to 20 \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e. Additionally to this information, we now see a peak close to 60 \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e.\u003c/p\u003e\r\n\r\n\u003cp\u003eWhy are there two peaks in this distribution?\u003c/p\u003e\r\n\r\n\u003cp\u003eWhat can explain this? This is an aspect that we can explore in the second phase of exploratory data analysis.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"correlations\"\u003e\r\n\u003ch4\u003eCorrelations\u003c/h4\u003e\r\n\r\n\u003cp\u003eCorrelations are a great way to discover relationships between numerical variables. There are various ways to calculate the correlation. The Pearson correlation coefficient is a widely used approach that measures the linear dependence between two variables. The correlation coefficient ranges from -1 to 1. A correlation of 1 is a total positive correlation, a correlation of -1 is a total negative correlation and a correlation of 0 is non-linear correlation. We can perform that calculation using the \u003ccode class=\"lang-python\"\u003ecorr\u003c/code\u003e function on a \u003ccode class=\"lang-python\"\u003eSeries\u003c/code\u003e. By default, this function will use the Pearson correlation coefficient calculation. It is possible to use different methods of calculation with this function.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ebeers[[\"abv\", \"ibu\", \"ounces\"]].corr()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable\u003e\r\n\t\u003ctbody\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eabv\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eibu\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eounces\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003eabv\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e1\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e0.670621\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e0.172529\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003eibu\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e0.670621\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e1\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e0.054691\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003eounces\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e0.172529\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e0.054691\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e1\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003cp\u003eAs you can see above, the correlation between \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e and itself is 1. Obviously, numerical variables are perfectly correlated with themselves. More interestingly, you can see that the correlation of the \u003ccode class=\"lang-python\"\u003eABV\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e is equal to \u003ccode class=\"lang-python\"\u003e0.670621\u003c/code\u003e. While this is not a total positive correlation, it is still highly correlated. This is an interesting aspect that we can explore further down the road.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level4\" id=\"a-few-notes-on-non-numerical-variables\"\u003e\r\n\u003ch4\u003eA few notes on non-numerical variables\u003c/h4\u003e\r\n\r\n\u003cp\u003eThe metrics that have been previously extracted are mostly applicable for numerical values only. If you are dealing with other types of data such as categorical data, you can still gather some interesting measurements. You could calculate the frequency of each value in the dataset.\u003c/p\u003e\r\n\r\n\u003cp\u003e\u003ccode class=\"lang-python\"\u003eDataFrame\u003c/code\u003e have a function named \u003ccode class=\"lang-python\"\u003edescribe\u003c/code\u003e that summarizes the dataset. If your \u003ccode class=\"lang-python\"\u003eDataFrame\u003c/code\u003e only has categorical or text values, the summary will be adapted specifically for this type of data.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003ebeers[[\"name\", \"style\"]].describe()\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable\u003e\r\n\t\u003ctbody\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t    \u003ctd\u003e\u003c/td\u003e\r\n\t\t\t\u003ctd\u003ename\u003c/td\u003e\r\n\t\t\t\u003ctd\u003estyle\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003ecount\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e2410\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e2405\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003eunique\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e2305\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e99\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"odd\"\u003e\r\n\t\t\t\u003ctd\u003etop\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eNonstop Hef Hop\u003c/td\u003e\r\n\t\t\t\u003ctd\u003eAmerican IPA\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\t\u003ctr class=\"even\"\u003e\r\n\t\t\t\u003ctd\u003efreq\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e12\u003c/td\u003e\r\n\t\t\t\u003ctd\u003e424\u003c/td\u003e\r\n\t\t\u003c/tr\u003e\r\n\t\u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\u003cdiv class=\"section level3\" id=\"profiling-libraries\"\u003e\r\n\u003ch3\u003eProfiling Libraries\u003c/h3\u003e\r\n\r\n\u003cp\u003eAs you\u0026rsquo;ve seen above, gathering descriptive statistics can be a tedious process. Gladly, there are libraries that exist that perform all of the data crunching for you. They output a very clear profile of your data. \u003ccode class=\"lang-python\"\u003epandas-profiling\u003c/code\u003e is one of them. That library offers out-of-the-box statistical profiling of your dataset. Since the dataset we are using is tidy and standardized, we can use the library right away on our dataset.\u003c/p\u003e\r\n\r\n\u003cpre\u003e\r\n\u003ccode class=\"lang-python\"\u003eimport pandas_profiling \r\n\r\npandas_profiling.ProfileReport(beers_and_breweries)\u003c/code\u003e\u003c/pre\u003e\r\n\r\n\u003cp\u003e\u003ciframe height=\"200\" src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/report.html\" width=\"1000\"\u003e\u003c/iframe\u003e\u003c/p\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level3\" id=\"more-questions\"\u003e\r\n\u003ch3\u003eMore Questions\u003c/h3\u003e\r\n\r\n\u003cp\u003eGenerally, once you have profiled your dataset, you have a lot more question on it than you initially had. This is great because those new questions will fuel your exploratory data analysis.\u003c/p\u003e\r\n\r\n\u003cp\u003eHere are a few questions that we have gathered while doing this profiling:\u003c/p\u003e\r\n\r\n\u003cul\u003e\r\n\t\u003cli\u003e41.7% of the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e values are missing. Why is that? How can that affect our analysis?\u003c/li\u003e\r\n\t\u003cli\u003eThere are two peaks in the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e distribution. What explains this?\u003c/li\u003e\r\n\t\u003cli\u003eWhat explains the correlation between \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e and \u003ccode class=\"lang-python\"\u003eABV\u003c/code\u003e? What is the influence of the beer style in this correlation?\u003c/li\u003e\r\n\t\u003cli\u003eAre there differences in the \u003ccode class=\"lang-python\"\u003eIBU\u003c/code\u003e, \u003ccode class=\"lang-python\"\u003eABV\u003c/code\u003e or \u003ccode class=\"lang-python\"\u003eStyle\u003c/code\u003e between geographical regions? What about the East Coast vs the West Coast?\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cbr\u003e\r\n\u003cp\u003eData profiling is not a linear process. As you filter and segment your dataset, you will come back to it and gather descriptive statistics on subgroups of your data.\u003c/p\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cdiv class=\"section level2\" id=\"next-steps\"\u003e\r\n\u003ch2\u003eNext Steps\u003c/h2\u003e\r\n\r\n\u003cp\u003eIn this post, you have seen how to profile a dataset. You now know how to attribute variables to specific data types groups. You have also calculated different descriptive statistics on the dataset and you understand how to interpret those measurements. Finally, you have seen that there are some libraries that can help you do the crunching to profile your dataset. More importantly, you have generated more questions than ever to fuel your exploratory data analysis.\u003c/p\u003e\r\n\u003c/div\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/python-data-profiling","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Exploratory Data Analysis Tutorial: Data Profiling","seoMetaDescription":"In this tutorial, you'll learn about exploratory data analysis (EDA) in Python, and more specifically, data profiling with pandas.","seoKeyword":"exploratory data analysis python","mustRead":false,"programmingLanguage":null,"submissionDate":"2017-04-13T14:11:56.000Z","publishDate":"2017-04-13T16:33:08.000Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-09-08T15:37:31.266Z","updatedAt":"2018-02-22T13:36:44.533Z","upvoting":{"voteCount":25,"voted":false},"tags":["data manipulation","python","data analysis","pandas"],"author":{"id":923685,"slug":"nickhould","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/923/685/square/2d8068c50718ed35659b1de3ce219dc735d27c0b.png?1505990828","fullName":"Jean-Nicholas Hould","nameFromEmail":"nickhould","isAdmin":false}},{"id":7750,"externalId":null,"type":"Tutorial","status":"published","authorId":"hugobowneanderson","title":"Hierarchical indices, groupby and pandas","slug":"pandas-multi-index","previewSlug":null,"description":"In this tutorial, youâ€™ll learn about multi-indices for pandas DataFrames and how they arise naturally from groupby operations on real-world data sets.","articles":[],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eIn a \u003ca href=\"https://www.datacamp.com/community/tutorials/pandas-split-apply-combine-groupby\"\u003eprevious post\u003c/a\u003e, you saw how the groupby operation arises naturally through the lens of the principle of split-apply-combine. You checked out a dataset of Netflix user ratings and grouped the rows by the release year of the movie to generate the following figure:\u003c/p\u003e\r\n\u003cp align=\"center\"\u003e\r\n\u003cimg alt=\"pandas groupby\" src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1506959105/netflix_median_dmnhid.png\"\u003e\r\n\u003c/p\u003e\r\n\r\n\u003cp\u003eThis was achieved via grouping by a single column. I mentioned, in passing, that you may want to group by several columns, in which case the resulting pandas DataFrame ends up with a multi-index \u003cem\u003eor\u003c/em\u003e hierarchical index. In this post, you\u0026#39;ll learn what \u003cem\u003ehierarchical indices\u003c/em\u003e and see how they arise when grouping by several features of your data. You can find out more about all of these concept and practices in our \u003ca href=\"https://www.datacamp.com/courses/manipulating-dataframes-with-pandas\"\u003eManipulating DataFrames with pandas course\u003c/a\u003e.\u003c/p\u003e\r\n\u003cp\u003eSo first up: what are hierarchical indices?\u003c/p\u003e\r\n\u003cp\u003e\u003cimg alt=\"hierarchical index pandas\" src=\"http://res.cloudinary.com/dyd911kmh/image/upload/c_scale,w_472/v1507560120/Hierarchical_Indices_and_Pandas_Banner_vlrypg.png\" /\u003e\u003c/p\u003e\r\n\u003ch2 id=\"hierarchical-indices-and-pandas-dataframes\"\u003eHierarchical Indices and pandas DataFrames\u003c/h2\u003e\r\n\u003ch3 id=\"what-is-the-index-of-a-dataframe-\"\u003eWhat Is The Index of a DataFrame?\u003c/h3\u003e\r\n\u003cp\u003eBefore introducing hierarchical indices, I want you to recall what the index of pandas DataFrame is. The index of a DataFrame is a set that consists of a label for each row. Let\u0026#39;s look at an example. I\u0026#39;ll first import a synthetic dataset of a hypothetical DataCamp student Ellie\u0026#39;s activity on DataCamp. The columns are a date, a programming language and the number of exercises that Ellie completed that day in that language. Load in the data:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import pandas\r\nimport pandas as pd\r\n\r\n# Load in data\r\ndf = pd.read_csv(\u0026#39;data/user_ex_python.csv\u0026#39;)\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003elanguage\u003c/th\u003e\r\n      \u003cth\u003eex_complete\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-01\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e6\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-02\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e5\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-03\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e10\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\u003cp\u003eYou can see the Index on the left hand side of the DataFrame and that it consists of integers. This is a \u003ccode\u003eRangeIndex\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out index\r\ndf.index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eRangeIndex(start=0, stop=3, step=1)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eWe can use this index to slice out a row or rows of \u003ccode\u003edf\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Slice and dice data\r\ndf.loc[:1]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003elanguage\u003c/th\u003e\r\n      \u003cth\u003eex_complete\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-01\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e6\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-02\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e5\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eThis index, however, is not so informative. If you\u0026#39;re going to label the rows of your DataFrame, it would be good to label them in a meaningful manner, if at all possible. Can you do this with the dataset in question? A good way to think about this challenge is that you want a \u003cstrong\u003eunique \u003cem\u003eand\u003c/em\u003e meaningful identifier for each row\u003c/strong\u003e. Check out the columns and see if any matches these criteria. Notice that the \u003ccode\u003edate\u003c/code\u003e column contains unique dates so it makes sense to label each row by the date column. That is,you can make the \u003ccode\u003edate\u003c/code\u003e column the index of the DataFrame using the \u003ccode\u003e.set_index()\u003c/code\u003e method (n.b. \u003ccode\u003einplace=True\u003c/code\u003e means you\u0026#39;re actually altering the DataFrame \u003ccode\u003edf\u003c/code\u003e inplace):\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Set new index\r\ndf.set_index(pd.DatetimeIndex(df[\u0026#39;date\u0026#39;]), inplace=True)\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003elanguage\u003c/th\u003e\r\n      \u003cth\u003eex_complete\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-01\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-01\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e6\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-02\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-02\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e5\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-03\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-03\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e10\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eThis then gives \u003ccode\u003edf\u003c/code\u003e a \u003ccode\u003eDateTimeIndex\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out new index\r\ndf.index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eDatetimeIndex([\u0026#39;2017-01-01\u0026#39;, \u0026#39;2017-01-02\u0026#39;, \u0026#39;2017-01-03\u0026#39;], dtype=\u0026#39;datetime64[ns]\u0026#39;, name=\u0026#39;date\u0026#39;, freq=None)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eNow you can slice out rows using the \u003ccode\u003eDateTimeIndex\u003c/code\u003e that you\u0026#39;ve created:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Slice and dice data w/ new index\r\ndf.loc[\u0026#39;2017-01-02\u0026#39;]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003edate           2017-01-02\r\nlanguage           python\r\nex_complete             5\r\nName: 2017-01-02 00:00:00, dtype: object\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAlso note that the \u003ccode\u003e.columns\u003c/code\u003e attribute returns an index containg the column names of \u003ccode\u003edf\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out columns\r\ndf.columns\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eIndex([\u0026#39;date\u0026#39;, \u0026#39;language\u0026#39;, \u0026#39;ex_complete\u0026#39;], dtype=\u0026#39;object\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThis can be slightly confusing because this says is that \u003ccode\u003edf.columns\u003c/code\u003e is of type \u003ccode\u003eIndex\u003c/code\u003e. This \u003cstrong\u003edoes not mean\u003c/strong\u003e that the columns are the index of the DataFrame. The index of \u003ccode\u003edf\u003c/code\u003e is always given by \u003ccode\u003edf.index\u003c/code\u003e. Check out our \u003ca href=\"https://www.datacamp.com/community/tutorials/pandas-tutorial-dataframe-python\"\u003epandas DataFrames tutorial\u003c/a\u003e for more on indices. Now it\u0026#39;s time to meet hierarchical indices.\u003c/p\u003e\r\n\u003ch3 id=\"the-multi-index-of-a-pandas-dataframe\"\u003eThe Multi-index of a pandas DataFrame\u003c/h3\u003e\r\n\u003cp\u003eWhat if we had multiple languages for our dataset, as we do on DataCamp? Have a look:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import and check out data\r\ndf = pd.read_csv(\u0026#39;data/user_ex.csv\u0026#39;)\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003elanguage\u003c/th\u003e\r\n      \u003cth\u003eex_complete\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-01\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e6\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-02\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e5\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-03\u003c/td\u003e\r\n      \u003ctd\u003epython\u003c/td\u003e\r\n      \u003ctd\u003e10\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-01\u003c/td\u003e\r\n      \u003ctd\u003er\u003c/td\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e4\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-02\u003c/td\u003e\r\n      \u003ctd\u003er\u003c/td\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e5\u003c/th\u003e\r\n      \u003ctd\u003e2017-01-03\u003c/td\u003e\r\n      \u003ctd\u003er\u003c/td\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eEach date now corresponds to several rows, one for each language. See, for example, that the date \u0026#39;2017-01-02\u0026#39; occurs in rows 1 and 4, for languages Python and R, respectively. Thus the date no longer \u003cem\u003euniquely\u003c/em\u003e specifies the row. However, \u0026#39;date\u0026#39; and \u0026#39;language\u0026#39; together do uniquely specify the rows. For this reason, we use both as the index:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Set index\r\ndf.set_index([\u0026#39;date\u0026#39;, \u0026#39;language\u0026#39;], inplace=True)\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003eex_complete\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003elanguage\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-01\u003c/th\u003e\r\n      \u003cth\u003epython\u003c/th\u003e\r\n      \u003ctd\u003e6\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-02\u003c/th\u003e\r\n      \u003cth\u003epython\u003c/th\u003e\r\n      \u003ctd\u003e5\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-03\u003c/th\u003e\r\n      \u003cth\u003epython\u003c/th\u003e\r\n      \u003ctd\u003e10\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-01\u003c/th\u003e\r\n      \u003cth\u003er\u003c/th\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-02\u003c/th\u003e\r\n      \u003cth\u003er\u003c/th\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2017-01-03\u003c/th\u003e\r\n      \u003cth\u003er\u003c/th\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eYou have now created a multi-index, or hierarchical index (become comfortable with both these terms as you\u0026#39;ll find them used interchangeably), and you can see this by checking out the index as follows:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out multi-index\r\ndf.index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eMultiIndex(levels=[[\u0026#39;2017-01-01\u0026#39;, \u0026#39;2017-01-02\u0026#39;, \u0026#39;2017-01-03\u0026#39;], [\u0026#39;python\u0026#39;, \u0026#39;r\u0026#39;]],\r\n           labels=[[0, 1, 2, 0, 1, 2], [0, 0, 0, 1, 1, 1]],\r\n           names=[\u0026#39;date\u0026#39;, \u0026#39;language\u0026#39;])\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe above tells you that your DataFrame \u003ccode\u003edf\u003c/code\u003e now has a \u003ccode\u003eMultiIndex\u003c/code\u003e with two \u003cem\u003elevels\u003c/em\u003e, the first given by the date, the second by the the language. Recall that above you were able to slice the DataFrame using the index and the \u003ccode\u003e.loc\u003c/code\u003e accessor: \u003ccode\u003edf.loc[\u0026#39;2017-01-02\u0026#39;]\u003c/code\u003e. To be able to slice with a multi-index, you need to sort the index first:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Sort index\r\ndf.sort_index(inplace=True)\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003eex_complete\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003edate\u003c/th\u003e\r\n      \u003cth\u003elanguage\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth rowspan=\"2\" valign=\"top\"\u003e2017-01-01\u003c/th\u003e\r\n      \u003cth\u003epython\u003c/th\u003e\r\n      \u003ctd\u003e6\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003er\u003c/th\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth rowspan=\"2\" valign=\"top\"\u003e2017-01-02\u003c/th\u003e\r\n      \u003cth\u003epython\u003c/th\u003e\r\n      \u003ctd\u003e5\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003er\u003c/th\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth rowspan=\"2\" valign=\"top\"\u003e2017-01-03\u003c/th\u003e\r\n      \u003cth\u003epython\u003c/th\u003e\r\n      \u003ctd\u003e10\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003er\u003c/th\u003e\r\n      \u003ctd\u003e8\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eNow you can slice out the number of R exercises completed on 2017-01-02 by passing a tuple to the \u003ccode\u003e.loc\u003c/code\u003e accessor:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Slice \u0026amp; dice your DataFrame\r\ndf.loc[(\u0026#39;2017-01-02\u0026#39;, \u0026#39;r\u0026#39;)]\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eex_complete    8\r\nName: (2017-01-02, r), dtype: int64\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou now know a bit about hierarchical indices (or multi-indices). It\u0026#39;s time to see how they arise when working with groupby objects.\u003c/p\u003e\r\n\u003chr\u003e\r\n\u003ch2 id=\"hierarchical-indices-groupby-objects-and-split-apply-combine\"\u003eHierarchical Indices, groupby Objects and Split-Apply-Combine\u003c/h2\u003e\r\n\u003cp\u003eIn \u003ca href=\"https://www.datacamp.com/community/tutorials/pandas-split-apply-combine-groupby\"\u003ea previous post\u003c/a\u003e, we explored groupby objects and the data analytic principles of split-apply-combine using netflix data. Lets have a quick refresher with a different dataset, the tips dataset that is built into the \u003ccode\u003eseaborn\u003c/code\u003e package. \u0026#39;Tips\u0026#39; contains features such as tip, total_bill, the day of the week and the time of day. First load and explore the data:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import and check out data\r\nimport seaborn as sns\r\ntips = sns.load_dataset(\u0026quot;tips\u0026quot;)\r\ntips.head()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003etotal_bill\u003c/th\u003e\r\n      \u003cth\u003etip\u003c/th\u003e\r\n      \u003cth\u003esex\u003c/th\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003eday\u003c/th\u003e\r\n      \u003cth\u003etime\u003c/th\u003e\r\n      \u003cth\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e16.99\u003c/td\u003e\r\n      \u003ctd\u003e1.01\u003c/td\u003e\r\n      \u003ctd\u003eFemale\u003c/td\u003e\r\n      \u003ctd\u003eNo\u003c/td\u003e\r\n      \u003ctd\u003eSun\u003c/td\u003e\r\n      \u003ctd\u003eDinner\u003c/td\u003e\r\n      \u003ctd\u003e2\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e10.34\u003c/td\u003e\r\n      \u003ctd\u003e1.66\u003c/td\u003e\r\n      \u003ctd\u003eMale\u003c/td\u003e\r\n      \u003ctd\u003eNo\u003c/td\u003e\r\n      \u003ctd\u003eSun\u003c/td\u003e\r\n      \u003ctd\u003eDinner\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e21.01\u003c/td\u003e\r\n      \u003ctd\u003e3.50\u003c/td\u003e\r\n      \u003ctd\u003eMale\u003c/td\u003e\r\n      \u003ctd\u003eNo\u003c/td\u003e\r\n      \u003ctd\u003eSun\u003c/td\u003e\r\n      \u003ctd\u003eDinner\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e23.68\u003c/td\u003e\r\n      \u003ctd\u003e3.31\u003c/td\u003e\r\n      \u003ctd\u003eMale\u003c/td\u003e\r\n      \u003ctd\u003eNo\u003c/td\u003e\r\n      \u003ctd\u003eSun\u003c/td\u003e\r\n      \u003ctd\u003eDinner\u003c/td\u003e\r\n      \u003ctd\u003e2\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e4\u003c/th\u003e\r\n      \u003ctd\u003e24.59\u003c/td\u003e\r\n      \u003ctd\u003e3.61\u003c/td\u003e\r\n      \u003ctd\u003eFemale\u003c/td\u003e\r\n      \u003ctd\u003eNo\u003c/td\u003e\r\n      \u003ctd\u003eSun\u003c/td\u003e\r\n      \u003ctd\u003eDinner\u003c/td\u003e\r\n      \u003ctd\u003e4\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eNote that the index of \u003ccode\u003etips\u003c/code\u003e is a \u003ccode\u003eRangeIndex\u003c/code\u003e:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out index\r\ntips.index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eRangeIndex(start=0, stop=244, step=1)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIt always helps to do some visual EDA before diving into computation and seaborn\u0026#39;s pairplot function allows you to get an overview of all numerical variables:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import pyplot, figures inline, set style, plot pairplot\r\nimport matplotlib.pyplot as plt\r\n%matplotlib inline\r\nsns.set()\r\nsns.pairplot(tips, hue=\u0026#39;day\u0026#39;);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1506974292/output_39_0_lpsfvm.png\" alt=\"\"\u003e\u003c/p\u003e\r\n\u003cp\u003eIf you want to check out how the average tip differs between \u0026#39;smokers\u0026#39; and \u0026#39;non-smokers\u0026#39;, you can \u003cstrong\u003esplit\u003c/strong\u003e the original DataFrame by the \u0026#39;smoker\u0026#39; (using \u003ccode\u003egroupby\u003c/code\u003e), \u003cstrong\u003eapply\u003c/strong\u003e the function \u0026#39;mean\u0026#39; and \u003cstrong\u003ecombine\u003c/strong\u003e into a new DataFrame:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Get mean of smoker/non-smoker groups\r\ndf = tips.groupby(\u0026#39;smoker\u0026#39;).mean()\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003etotal_bill\u003c/th\u003e\r\n      \u003cth\u003etip\u003c/th\u003e\r\n      \u003cth\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003ctd\u003e20.756344\u003c/td\u003e\r\n      \u003ctd\u003e3.008710\u003c/td\u003e\r\n      \u003ctd\u003e2.408602\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n      \u003ctd\u003e19.188278\u003c/td\u003e\r\n      \u003ctd\u003e2.991854\u003c/td\u003e\r\n      \u003ctd\u003e2.668874\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eThe resulting index of the DataFrame \u003ccode\u003edf\u003c/code\u003e is the \u0026#39;smoker\u0026#39; column/feature of the original \u0026#39;tips\u0026#39; DataFrame: \u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out new index\r\ndf.index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eCategoricalIndex([\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;], categories=[\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;], ordered=False, name=\u0026#39;smoker\u0026#39;, dtype=\u0026#39;category\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf desired, you can reset the index so that \u0026#39;smoker\u0026#39; becomes a column of the DataFrame:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Reset the index\r\ndf.reset_index()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003etotal_bill\u003c/th\u003e\r\n      \u003cth\u003etip\u003c/th\u003e\r\n      \u003cth\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003eYes\u003c/td\u003e\r\n      \u003ctd\u003e20.756344\u003c/td\u003e\r\n      \u003ctd\u003e3.008710\u003c/td\u003e\r\n      \u003ctd\u003e2.408602\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003eNo\u003c/td\u003e\r\n      \u003ctd\u003e19.188278\u003c/td\u003e\r\n      \u003ctd\u003e2.991854\u003c/td\u003e\r\n      \u003ctd\u003e2.668874\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eNow it\u0026#39;s time to find out how hierarchical indices arise from split-apply-combine and groupby operations.\u003c/p\u003e\r\n\u003ch3 id=\"multiple-groupings-and-hierarchical-indices\"\u003eMultiple groupings and hierarchical indices\u003c/h3\u003e\r\n\u003cp\u003eAbove, you grouped the tips dataset according to the feature \u0026#39;smoker\u0026#39;. Sometimes you will need to group a dataset according to two features.  For example, it is natural to group the tips dataset into  smokers/non-smokers \u0026amp; dinner/lunch. To do this, you pass the column names you wish to group by as a list:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Group by two columns\r\ndf = tips.groupby([\u0026#39;smoker\u0026#39;,\u0026#39;time\u0026#39;]).mean()\r\ndf\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003etotal_bill\u003c/th\u003e\r\n      \u003cth\u003etip\u003c/th\u003e\r\n      \u003cth\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003etime\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth rowspan=\"2\" valign=\"top\"\u003eYes\u003c/th\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003ctd\u003e17.399130\u003c/td\u003e\r\n      \u003ctd\u003e2.834348\u003c/td\u003e\r\n      \u003ctd\u003e2.217391\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003ctd\u003e21.859429\u003c/td\u003e\r\n      \u003ctd\u003e3.066000\u003c/td\u003e\r\n      \u003ctd\u003e2.471429\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth rowspan=\"2\" valign=\"top\"\u003eNo\u003c/th\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003ctd\u003e17.050889\u003c/td\u003e\r\n      \u003ctd\u003e2.673778\u003c/td\u003e\r\n      \u003ctd\u003e2.511111\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003ctd\u003e20.095660\u003c/td\u003e\r\n      \u003ctd\u003e3.126887\u003c/td\u003e\r\n      \u003ctd\u003e2.735849\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eLooking at the above, you may be able to see that both \u0026#39;smoker\u0026#39; and \u0026#39;time\u0026#39; are indices of \u003ccode\u003edf\u003c/code\u003e. This is the case and makes sense: if grouping by \u0026#39;smoker\u0026#39; results in the index being the original \u0026#39;smoker\u0026#39; column, grouping by two columns will give you two indices. Check the index to confirm that it\u0026#39;s hierarchical:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out index\r\ndf.index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eMultiIndex(levels=[[\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;], [\u0026#39;Lunch\u0026#39;, \u0026#39;Dinner\u0026#39;]],\r\n           labels=[[0, 0, 1, 1], [0, 1, 0, 1]],\r\n           names=[\u0026#39;smoker\u0026#39;, \u0026#39;time\u0026#39;])\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAnd it is. You can do a bunch of useful things now, such as getting the counts in each grouping:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Group by two features\r\ntips.groupby([\u0026#39;smoker\u0026#39;,\u0026#39;time\u0026#39;]).size()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003esmoker  time  \r\nYes     Lunch      23\r\n        Dinner     70\r\nNo      Lunch      45\r\n        Dinner    106\r\ndtype: int64\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eYou can swap the levels of the hierarchical index also so that \u0026#39;time\u0026#39; occurs before \u0026#39;smoker\u0026#39; in the index:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Swap levels of multi-index\r\ndf.swaplevel()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003etotal_bill\u003c/th\u003e\r\n      \u003cth\u003etip\u003c/th\u003e\r\n      \u003cth\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003etime\u003c/th\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003ctd\u003e17.399130\u003c/td\u003e\r\n      \u003ctd\u003e2.834348\u003c/td\u003e\r\n      \u003ctd\u003e2.217391\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003ctd\u003e21.859429\u003c/td\u003e\r\n      \u003ctd\u003e3.066000\u003c/td\u003e\r\n      \u003ctd\u003e2.471429\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n      \u003ctd\u003e17.050889\u003c/td\u003e\r\n      \u003ctd\u003e2.673778\u003c/td\u003e\r\n      \u003ctd\u003e2.511111\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n      \u003ctd\u003e20.095660\u003c/td\u003e\r\n      \u003ctd\u003e3.126887\u003c/td\u003e\r\n      \u003ctd\u003e2.735849\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eYou may then wish to remove one of these features from the hierarchical index and form different columns with respect to that feature. You can do so using the \u003ccode\u003eunstack\u003c/code\u003e method:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Unstack your multi-index\r\ndf.unstack()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth colspan=\"2\" halign=\"left\"\u003etotal_bill\u003c/th\u003e\r\n      \u003cth colspan=\"2\" halign=\"left\"\u003etip\u003c/th\u003e\r\n      \u003cth colspan=\"2\" halign=\"left\"\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003etime\u003c/th\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003ctd\u003e17.399130\u003c/td\u003e\r\n      \u003ctd\u003e21.859429\u003c/td\u003e\r\n      \u003ctd\u003e2.834348\u003c/td\u003e\r\n      \u003ctd\u003e3.066000\u003c/td\u003e\r\n      \u003ctd\u003e2.217391\u003c/td\u003e\r\n      \u003ctd\u003e2.471429\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n      \u003ctd\u003e17.050889\u003c/td\u003e\r\n      \u003ctd\u003e20.095660\u003c/td\u003e\r\n      \u003ctd\u003e2.673778\u003c/td\u003e\r\n      \u003ctd\u003e3.126887\u003c/td\u003e\r\n      \u003ctd\u003e2.511111\u003c/td\u003e\r\n      \u003ctd\u003e2.735849\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eYou can unstack on the outer feature of the index using the keyword argument \u0026#39;level\u0026#39;:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Unsstack the outer index\r\ndf.unstack(level=0)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth colspan=\"2\" halign=\"left\"\u003etotal_bill\u003c/th\u003e\r\n      \u003cth colspan=\"2\" halign=\"left\"\u003etip\u003c/th\u003e\r\n      \u003cth colspan=\"2\" halign=\"left\"\u003esize\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003esmoker\u003c/th\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n      \u003cth\u003eYes\u003c/th\u003e\r\n      \u003cth\u003eNo\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003etime\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eLunch\u003c/th\u003e\r\n      \u003ctd\u003e17.399130\u003c/td\u003e\r\n      \u003ctd\u003e17.050889\u003c/td\u003e\r\n      \u003ctd\u003e2.834348\u003c/td\u003e\r\n      \u003ctd\u003e2.673778\u003c/td\u003e\r\n      \u003ctd\u003e2.217391\u003c/td\u003e\r\n      \u003ctd\u003e2.511111\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eDinner\u003c/th\u003e\r\n      \u003ctd\u003e21.859429\u003c/td\u003e\r\n      \u003ctd\u003e20.095660\u003c/td\u003e\r\n      \u003ctd\u003e3.066000\u003c/td\u003e\r\n      \u003ctd\u003e3.126887\u003c/td\u003e\r\n      \u003ctd\u003e2.471429\u003c/td\u003e\r\n      \u003ctd\u003e2.735849\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\u003cp\u003eThe result of unstacking has a non-hierarchical index, as you may expect:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Check out index\r\ndf.unstack().index\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eCategoricalIndex([\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;], categories=[\u0026#39;Yes\u0026#39;, \u0026#39;No\u0026#39;], ordered=False, name=\u0026#39;smoker\u0026#39;, dtype=\u0026#39;category\u0026#39;)\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAs a result, you can now perform all types of data analysis with respect to these groupings. I encourage you to do so.\u003c/p\u003e\r\n\u003ch2 id=\"hierarchical-indices-in-daily-use\"\u003eHierarchical Indices in Daily Use\u003c/h2\u003e\r\n\u003cp\u003eIn this post, you have been introduced to hierarchical indices (or multi-indices) and have seen how they arise as a natural consequence of wanting a DataFrame index to uniquely and meaningfully label the rows of your DataFrame. You have also seen how they arise when you need to group your data by multiple columns, invoking the principle of split-apply-combine. I hope that you have fun with hierarchical indices in your work. \u003c/p\u003e\r\n\u003cp\u003eThis post was generated from a Jupyter Notebook; You can find it in \u003ca href=\"https://github.com/datacamp/community-hierarchical-indices\"\u003ethis repository\u003c/a\u003e. If you have any thoughts, responses and/or ruminations, feel free to reach out to me on twitter: \u003ca href=\"https://twitter.com/hugobowne\"\u003e@hugobowne\u003c/a\u003e.\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/pandas-multi-index","userContentUrl":null,"illustrationUrl":null,"seoTitle":"pandas Multi-index and groupbys","seoMetaDescription":"Learn about the pandas multi-index or hierarchical index for DataFrames and how they arise naturally from groupby operations on real-world data sets.","seoKeyword":"pandas multiindex groupby","mustRead":false,"programmingLanguage":null,"submissionDate":"2017-10-02T19:50:55.450Z","publishDate":"2017-10-02T19:51:07.308Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-10-02T19:50:55.444Z","updatedAt":"2019-02-22T19:32:00.984Z","upvoting":{"voteCount":58,"voted":false},"tags":["python","data manipulation","pandas"],"author":{"id":469499,"slug":"hugobowneanderson","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/469/499/square/hugo_bowne-anderson.png?1470132470","fullName":"Hugo Bowne-Anderson","nameFromEmail":"hugobowneanderson","isAdmin":false}},{"id":8243,"externalId":null,"type":"Tutorial","status":"published","authorId":"hugobowneanderson","title":"Kaggle Tutorial: EDA \u0026 Machine Learning","slug":"kaggle-machine-learning-eda","previewSlug":null,"description":"In this Kaggle tutorial, you'll learn how to approach and build supervised learning models with the help of exploratory data analysis (EDA) on the Titanic data.","articles":[89,8239,8322],"courses":[],"redirectSlug":null,"contentHtml":"\u003cp\u003eEarlier this month, I did a Facebook Live Code Along Session in which I (and everybody who coded along) built several algorithms of increasing complexity that predict whether any given passenger on the Titanic survived or not, given data on them such as the fare they paid, where they embarked and their age. \u003c/p\u003e\r\n\u003cp\u003eIn this post, you will go over some of the things we covered in this session. If you want to re-watch or follow this post together with the video, you can watch it here:\u003c/p\u003e\r\n\u003ciframe src=\"https://www.facebook.com/plugins/video.php?href=https%3A%2F%2Fwww.facebook.com%2F726282547396228%2Fvideos%2F1834105493280589%2F\u0026show_text=0\u0026width=560\" width=\"560\" height=\"550\" style=\"border:none;overflow:hidden\" scrolling=\"no\" frameborder=\"0\" allowTransparency=\"true\" allowFullScreen=\"true\"\u003e\u003c/iframe\u003e\r\n\r\n\u003cp\u003e\u003cbr\u003e\r\nIn particular, you might still remember that we built supervised learning models. \u003c/p\u003e\r\n\u003cp\u003eSupervised learning is the branch of Machine Learning (ML) that involves predicting labels, such as \u0026#39;Survived\u0026#39; or \u0026#39;Not\u0026#39;. Such models learn from labelled data, which is data that includes whether a passenger survived (called \u0026quot;model training\u0026quot;), and then predict on unlabelled data.\u003c/p\u003e\r\n\u003cp\u003eOn Kaggle, a platform for predictive modelling and analytics competitions, these are called train and test sets because\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eYou want to build a model that learns patterns in the training set, and\u003c/li\u003e\r\n\u003cli\u003eYou then use the model to make predictions on the test set.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eKaggle then tells you the \u003cstrong\u003epercentage that you got correct\u003c/strong\u003e: this is known as the accuracy of your model.\u003c/p\u003e\r\n\u003ch2 id=\"how-to-start-with-supervised-learning\"\u003eHow To Start with Supervised Learning\u003c/h2\u003e\r\n\u003cp\u003eAs you might already know, a good way to approach supervised learning is the following:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003ePerform an Exploratory Data Analysis (EDA) on your data set;\u003c/li\u003e\r\n\u003cli\u003eBuild a quick and dirty model, or a baseline model, which can serve as a comparison against later models that you will build;\u003c/li\u003e\r\n\u003cli\u003eIterate this process. You will do more EDA and build another model;\u003c/li\u003e\r\n\u003cli\u003eEngineer features: take the features that you already have and combine them or extract more information from them to eventually come to the last point, which is\u003c/li\u003e\r\n\u003cli\u003eGet a model that performs better.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIn this code along session, you did or will do all of these steps! \u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that we also have courses that get you up and running with machine learning for the Titanic dataset in \u003ca href=\"https://campus.datacamp.com/courses/kaggle-python-tutorial-on-machine-learning\"\u003ePython\u003c/a\u003e and \u003ca href=\"https://campus.datacamp.com/courses/kaggle-r-tutorial-on-machine-learning\"\u003eR\u003c/a\u003e.\u003c/p\u003e\r\n\u003ch2 id=\"import-your-data-and-check-it-out\"\u003eImport Your Data and Check it Out\u003c/h2\u003e\r\n\u003cp\u003eA first step is always to import your data to quickly check out the data that you will be working with. In this case, you\u0026#39;ll import the \u003ccode\u003epandas\u003c/code\u003e package and make use of the \u003ccode\u003eread_csv()\u003c/code\u003e function to read in the data:\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e that in the code chunks below, other packages and modules of packages such as \u003ccode\u003ematplotlib\u003c/code\u003e, \u003ccode\u003esklearn\u003c/code\u003e and \u003ccode\u003eseaborn\u003c/code\u003e have already been imported. You\u0026#39;ll be making more extensive use of these later for (statistical) data visualization and machine learning purposes!\u003c/p\u003e\r\n\u003cp\u003eYou also make use of IPython magic command \u003ccode\u003e%matplotlib inline\u003c/code\u003e so that your plots appear inline in your notebook. You also add \u003ccode\u003esns.set()\u003c/code\u003e to your code chunk to change the visualization style to a base Seaborn style:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import modules\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nfrom sklearn import tree\r\nfrom sklearn.metrics import accuracy_score\r\n\r\n# Figures inline and set visualization style\r\n%matplotlib inline\r\nsns.set()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWithout further ado, let\u0026#39;s import the data and already take the first step in examining your data:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# Import test and train datasets\r\ndf_train = pd.read_csv(\u0026#39;../data/train.csv\u0026#39;)\r\ndf_test = pd.read_csv(\u0026#39;../data/test.csv\u0026#39;)\r\n\r\n# View first lines of training data\r\ndf_train.head(n=4)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003ePassengerId\u003c/th\u003e\r\n      \u003cth\u003eSurvived\u003c/th\u003e\r\n      \u003cth\u003ePclass\u003c/th\u003e\r\n      \u003cth\u003eName\u003c/th\u003e\r\n      \u003cth\u003eSex\u003c/th\u003e\r\n      \u003cth\u003eAge\u003c/th\u003e\r\n      \u003cth\u003eSibSp\u003c/th\u003e\r\n      \u003cth\u003eParch\u003c/th\u003e\r\n      \u003cth\u003eTicket\u003c/th\u003e\r\n      \u003cth\u003eFare\u003c/th\u003e\r\n      \u003cth\u003eCabin\u003c/th\u003e\r\n      \u003cth\u003eEmbarked\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eBraund, Mr. Owen Harris\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e22.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003eA/5 21171\u003c/td\u003e\r\n      \u003ctd\u003e7.2500\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e2\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003eCumings, Mrs. John Bradley (Florence Briggs Th...\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e38.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003ePC 17599\u003c/td\u003e\r\n      \u003ctd\u003e71.2833\u003c/td\u003e\r\n      \u003ctd\u003eC85\u003c/td\u003e\r\n      \u003ctd\u003eC\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eHeikkinen, Miss. Laina\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e26.0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003eSTON/O2. 3101282\u003c/td\u003e\r\n      \u003ctd\u003e7.9250\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e4\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003eFutrelle, Mrs. Jacques Heath (Lily May Peel)\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e35.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e113803\u003c/td\u003e\r\n      \u003ctd\u003e53.1000\u003c/td\u003e\r\n      \u003ctd\u003eC123\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\u003cp\u003eIf you want to see what all of these features are, check out the Kaggle data documentation \u003ca href=\"https://www.kaggle.com/c/titanic/data\"\u003ehere\u003c/a\u003e.\u003c/p\u003e\r\n\u003cp\u003eBefore you continue, it\u0026#39;s good to take into account the following when it comes to terminology: \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eThe target variable is the variable you are trying to predict;\u003c/li\u003e\r\n\u003cli\u003eOther variables are known as \u0026quot;features\u0026quot; (or \u0026quot;predictor variables\u0026quot;, the features that you\u0026#39;re using to predict the target variable).\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eWith this in mind, you can continue to check out your data with, for example, the \u003ccode\u003ehead()\u003c/code\u003e function, which you can use to pull up the first five rows of your data set:\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003e# View first lines of test data\r\ndf_test.head()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003ePassengerId\u003c/th\u003e\r\n      \u003cth\u003ePclass\u003c/th\u003e\r\n      \u003cth\u003eName\u003c/th\u003e\r\n      \u003cth\u003eSex\u003c/th\u003e\r\n      \u003cth\u003eAge\u003c/th\u003e\r\n      \u003cth\u003eSibSp\u003c/th\u003e\r\n      \u003cth\u003eParch\u003c/th\u003e\r\n      \u003cth\u003eTicket\u003c/th\u003e\r\n      \u003cth\u003eFare\u003c/th\u003e\r\n      \u003cth\u003eCabin\u003c/th\u003e\r\n      \u003cth\u003eEmbarked\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e892\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eKelly, Mr. James\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e34.5\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e330911\u003c/td\u003e\r\n      \u003ctd\u003e7.8292\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eQ\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e893\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eWilkes, Mrs. James (Ellen Needs)\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e47.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e363272\u003c/td\u003e\r\n      \u003ctd\u003e7.0000\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e894\u003c/td\u003e\r\n      \u003ctd\u003e2\u003c/td\u003e\r\n      \u003ctd\u003eMyles, Mr. Thomas Francis\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e62.0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e240276\u003c/td\u003e\r\n      \u003ctd\u003e9.6875\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eQ\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e895\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eWirz, Mr. Albert\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e27.0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e315154\u003c/td\u003e\r\n      \u003ctd\u003e8.6625\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e4\u003c/th\u003e\r\n      \u003ctd\u003e896\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eHirvonen, Mrs. Alexander (Helga E Lindqvist)\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e22.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e3101298\u003c/td\u003e\r\n      \u003ctd\u003e12.2875\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\u003cp\u003eNote that the \u003ccode\u003edf_test\u003c/code\u003e DataFrame doesn\u0026#39;t have the \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e column because this is what you will try to predict!\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eYou can also use the DataFrame \u003ccode\u003e.info()\u003c/code\u003e method to check out data types, missing values and more (of \u003ccode\u003edf_train\u003c/code\u003e).\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_train.info()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e\u0026lt;class \u0026#39;pandas.core.frame.DataFrame\u0026#39;\u0026gt;\r\nRangeIndex: 891 entries, 0 to 890\r\nData columns (total 12 columns):\r\nPassengerId    891 non-null int64\r\nSurvived       891 non-null int64\r\nPclass         891 non-null int64\r\nName           891 non-null object\r\nSex            891 non-null object\r\nAge            714 non-null float64\r\nSibSp          891 non-null int64\r\nParch          891 non-null int64\r\nTicket         891 non-null object\r\nFare           891 non-null float64\r\nCabin          204 non-null object\r\nEmbarked       889 non-null object\r\ndtypes: float64(2), int64(5), object(5)\r\nmemory usage: 83.6+ KB\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIn this case, you see that there are only 714 non-null values for the \u0026#39;Age\u0026#39; column in a DataFrame with 891 rows. This means that are are 177 null \u003cem\u003eor\u003c/em\u003e missing values. \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eAlso, use the DataFrame \u003ccode\u003e.describe()\u003c/code\u003e method to check out summary statistics of numeric columns (of \u003ccode\u003edf_train\u003c/code\u003e).\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_train.describe()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003ePassengerId\u003c/th\u003e\r\n      \u003cth\u003eSurvived\u003c/th\u003e\r\n      \u003cth\u003ePclass\u003c/th\u003e\r\n      \u003cth\u003eAge\u003c/th\u003e\r\n      \u003cth\u003eSibSp\u003c/th\u003e\r\n      \u003cth\u003eParch\u003c/th\u003e\r\n      \u003cth\u003eFare\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003ecount\u003c/th\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n      \u003ctd\u003e714.000000\u003c/td\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003emean\u003c/th\u003e\r\n      \u003ctd\u003e446.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.383838\u003c/td\u003e\r\n      \u003ctd\u003e2.308642\u003c/td\u003e\r\n      \u003ctd\u003e29.699118\u003c/td\u003e\r\n      \u003ctd\u003e0.523008\u003c/td\u003e\r\n      \u003ctd\u003e0.381594\u003c/td\u003e\r\n      \u003ctd\u003e32.204208\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003estd\u003c/th\u003e\r\n      \u003ctd\u003e257.353842\u003c/td\u003e\r\n      \u003ctd\u003e0.486592\u003c/td\u003e\r\n      \u003ctd\u003e0.836071\u003c/td\u003e\r\n      \u003ctd\u003e14.526497\u003c/td\u003e\r\n      \u003ctd\u003e1.102743\u003c/td\u003e\r\n      \u003ctd\u003e0.806057\u003c/td\u003e\r\n      \u003ctd\u003e49.693429\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003emin\u003c/th\u003e\r\n      \u003ctd\u003e1.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e1.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.420000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e25%\u003c/th\u003e\r\n      \u003ctd\u003e223.500000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e2.000000\u003c/td\u003e\r\n      \u003ctd\u003e20.125000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e7.910400\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e50%\u003c/th\u003e\r\n      \u003ctd\u003e446.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e3.000000\u003c/td\u003e\r\n      \u003ctd\u003e28.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e14.454200\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e75%\u003c/th\u003e\r\n      \u003ctd\u003e668.500000\u003c/td\u003e\r\n      \u003ctd\u003e1.000000\u003c/td\u003e\r\n      \u003ctd\u003e3.000000\u003c/td\u003e\r\n      \u003ctd\u003e38.000000\u003c/td\u003e\r\n      \u003ctd\u003e1.000000\u003c/td\u003e\r\n      \u003ctd\u003e0.000000\u003c/td\u003e\r\n      \u003ctd\u003e31.000000\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003emax\u003c/th\u003e\r\n      \u003ctd\u003e891.000000\u003c/td\u003e\r\n      \u003ctd\u003e1.000000\u003c/td\u003e\r\n      \u003ctd\u003e3.000000\u003c/td\u003e\r\n      \u003ctd\u003e80.000000\u003c/td\u003e\r\n      \u003ctd\u003e8.000000\u003c/td\u003e\r\n      \u003ctd\u003e6.000000\u003c/td\u003e\r\n      \u003ctd\u003e512.329200\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\u003ch2 id=\"visual-exploratory-data-analysis-eda-and-your-first-model\"\u003eVisual Exploratory Data Analysis (EDA) And Your First Model\u003c/h2\u003e\r\n\u003cp\u003eNow that you have an idea about what your data looks like and have checked out some statistics, it\u0026#39;s time to also visualize your data with the help of the \u003ccode\u003eseaborn\u003c/code\u003e package: \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eFor example, use \u003ccode\u003eseaborn\u003c/code\u003e to build a bar plot of Titanic survival, which is your target variable.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.countplot(x=\u0026#39;Survived\u0026#39;, data=df_train);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868559/output_19_0_avn8k2.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e in the training set, less people survived than didn\u0026#39;t. Let\u0026#39;s then build a first model that predicts that nobody survived.\u003c/p\u003e\r\n\u003cp\u003eThis is a bad model as you know that people survived. But it gives us a baseline: any model that we build later needs to do better than this one.\u003c/p\u003e\r\n\u003cp\u003eYou can do this by following these steps:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eCreate a column \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e for \u003ccode\u003edf_test\u003c/code\u003e that encodes \u0026#39;did not survive\u0026#39; for all rows;\u003c/li\u003e\r\n\u003cli\u003eSave \u003ccode\u003e\u0026#39;PassengerId\u0026#39;\u003c/code\u003e and \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e columns of \u003ccode\u003edf_test\u003c/code\u003e to a .csv and submit to Kaggle.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_test[\u0026#39;Survived\u0026#39;] = 0\r\ndf_test[[\u0026#39;PassengerId\u0026#39;, \u0026#39;Survived\u0026#39;]].to_csv(\u0026#39;data/predictions/no_survivors.csv\u0026#39;, index=False)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eWhat accuracy did this give you? The accuracy on Kaggle is 62.7.\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513867360/Screen_Shot_2017-12-21_at_15.41.40_ymf0dk.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eNot too bad!\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eEssential note!\u003c/strong\u003e You will also want to use metrics other than accuracy!\u003c/p\u003e\r\n\u003ch2 id=\"eda-on-feature-variables\"\u003eEDA on Feature Variables\u003c/h2\u003e\r\n\u003cp\u003eNow that you have made a quick-and-dirty model, it\u0026#39;s time to reiterate: let\u0026#39;s do some more Exploratory Data Analysis and build another model soon! \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eYou can use \u003ccode\u003eseaborn\u003c/code\u003e to build a bar plot of the Titanic dataset feature \u003ccode\u003e\u0026#39;Sex\u0026#39;\u003c/code\u003e (of \u003ccode\u003edf_train\u003c/code\u003e).\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.countplot(x=\u0026#39;Sex\u0026#39;, data=df_train);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868559/output_26_0_m7mfgy.png\"/\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eAlso, use \u003ccode\u003eseaborn\u003c/code\u003e to build bar plots of the Titanic dataset feature \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e split (faceted) over the feature \u003ccode\u003e\u0026#39;Sex\u0026#39;\u003c/code\u003e.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.factorplot(x=\u0026#39;Survived\u0026#39;, col=\u0026#39;Sex\u0026#39;, kind=\u0026#39;count\u0026#39;, data=df_train);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868559/output_28_0_rtmxs9.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e Women were more likely to survive than men.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eWith this take-away, you can use \u003ccode\u003epandas\u003c/code\u003e to figure out how many women and how many men survived:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_train.groupby([\u0026#39;Sex\u0026#39;]).Survived.sum()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003eSex\r\nfemale    233\r\nmale      109\r\nName: Survived, dtype: int64\r\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003epandas\u003c/code\u003e to figure out the proportion of women that survived, along with the proportion of men:\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003eprint(df_train[df_train.Sex == \u0026#39;female\u0026#39;].Survived.sum()/df_train[df_train.Sex == \u0026#39;female\u0026#39;].Survived.count())\r\nprint(df_train[df_train.Sex == \u0026#39;male\u0026#39;].Survived.sum()/df_train[df_train.Sex == \u0026#39;male\u0026#39;].Survived.count())\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cpre\u003e\u003ccode\u003e0.742038216561\r\n0.188908145581\r\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e74% of women survived, while 19% of men survived.\u003c/p\u003e\r\n\u003cp\u003eLet\u0026#39;s now build a second model and predict that all women survived and all men didn\u0026#39;t. Once again, this is an unrealistic model, but it will provide a baseline against which to compare future models.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eCreate a column \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e for \u003ccode\u003edf_test\u003c/code\u003e that encodes the above prediction.\u003c/li\u003e\r\n\u003cli\u003eSave \u003ccode\u003e\u0026#39;PassengerId\u0026#39;\u003c/code\u003e and \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e columns of \u003ccode\u003edf_test\u003c/code\u003e to a .csv and submit to Kaggle.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_test[\u0026#39;Survived\u0026#39;] = df_test.Sex == \u0026#39;female\u0026#39;\r\ndf_test[\u0026#39;Survived\u0026#39;] = df_test.Survived.apply(lambda x: int(x))\r\ndf_test.head()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003ePassengerId\u003c/th\u003e\r\n      \u003cth\u003ePclass\u003c/th\u003e\r\n      \u003cth\u003eName\u003c/th\u003e\r\n      \u003cth\u003eSex\u003c/th\u003e\r\n      \u003cth\u003eAge\u003c/th\u003e\r\n      \u003cth\u003eSibSp\u003c/th\u003e\r\n      \u003cth\u003eParch\u003c/th\u003e\r\n      \u003cth\u003eTicket\u003c/th\u003e\r\n      \u003cth\u003eFare\u003c/th\u003e\r\n      \u003cth\u003eCabin\u003c/th\u003e\r\n      \u003cth\u003eEmbarked\u003c/th\u003e\r\n      \u003cth\u003eSurvived\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e892\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eKelly, Mr. James\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e34.5\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e330911\u003c/td\u003e\r\n      \u003ctd\u003e7.8292\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eQ\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e893\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eWilkes, Mrs. James (Ellen Needs)\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e47.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e363272\u003c/td\u003e\r\n      \u003ctd\u003e7.0000\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e2\u003c/th\u003e\r\n      \u003ctd\u003e894\u003c/td\u003e\r\n      \u003ctd\u003e2\u003c/td\u003e\r\n      \u003ctd\u003eMyles, Mr. Thomas Francis\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e62.0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e240276\u003c/td\u003e\r\n      \u003ctd\u003e9.6875\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eQ\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e3\u003c/th\u003e\r\n      \u003ctd\u003e895\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eWirz, Mr. Albert\u003c/td\u003e\r\n      \u003ctd\u003emale\u003c/td\u003e\r\n      \u003ctd\u003e27.0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n      \u003ctd\u003e315154\u003c/td\u003e\r\n      \u003ctd\u003e8.6625\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n      \u003ctd\u003e0\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e4\u003c/th\u003e\r\n      \u003ctd\u003e896\u003c/td\u003e\r\n      \u003ctd\u003e3\u003c/td\u003e\r\n      \u003ctd\u003eHirvonen, Mrs. Alexander (Helga E Lindqvist)\u003c/td\u003e\r\n      \u003ctd\u003efemale\u003c/td\u003e\r\n      \u003ctd\u003e22.0\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n      \u003ctd\u003e3101298\u003c/td\u003e\r\n      \u003ctd\u003e12.2875\u003c/td\u003e\r\n      \u003ctd\u003eNaN\u003c/td\u003e\r\n      \u003ctd\u003eS\u003c/td\u003e\r\n      \u003ctd\u003e1\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_test[[\u0026#39;PassengerId\u0026#39;, \u0026#39;Survived\u0026#39;]].to_csv(\u0026#39;../data/predictions/women_survive.csv\u0026#39;, index=False)\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003eNow, what accuracy did this model give you when you submit it to Kaggle?\u003c/p\u003e\r\n\u003cp\u003eThe accuracy on Kaggle is 76.6%:\u003c/p\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868121/Screen_Shot_2017-12-21_at_15.54.59_woeqjm.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003eWith this submission, you went up about 2,000 places in the leaderboard! Also, you have improved your score, so you\u0026#39;ve done a great job!\u003c/p\u003e\r\n\u003ch2 id=\"explore-your-data-more-\"\u003eExplore Your Data More!\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003eseaborn\u003c/code\u003e to build bar plots of the Titanic dataset feature \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e split (faceted) over the feature \u003ccode\u003e\u0026#39;Pclass\u0026#39;\u003c/code\u003e.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.factorplot(x=\u0026#39;Survived\u0026#39;, col=\u0026#39;Pclass\u0026#39;, kind=\u0026#39;count\u0026#39;, data=df_train);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868559/output_41_0_etfnyx.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e Passengers that travelled in first class were more likely to survive. On the other hand, passengers travelling in third class were more unlikely to survive. \u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003eseaborn\u003c/code\u003e to build bar plots of the Titanic dataset feature \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e split (faceted) over the feature \u003ccode\u003e\u0026#39;Embarked\u0026#39;\u003c/code\u003e.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.factorplot(x=\u0026#39;Survived\u0026#39;, col=\u0026#39;Embarked\u0026#39;, kind=\u0026#39;count\u0026#39;, data=df_train);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868559/output_44_0_q1f76p.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e Passengers that embarked in Southampton were less likely to survive. \u003c/p\u003e\r\n\u003ch2 id=\"eda-with-numeric-variables\"\u003eEDA with Numeric Variables\u003c/h2\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003eseaborn\u003c/code\u003e to plot a histogram of the \u003ccode\u003e\u0026#39;Fare\u0026#39;\u003c/code\u003e column of \u003ccode\u003edf_train\u003c/code\u003e.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.distplot(df_train.Fare, kde=False);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868560/output_48_0_jx6xch.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e Most passengers paid less than 100 for travelling with the Titanic.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse a \u003ccode\u003epandas\u003c/code\u003e plotting method to plot the column \u003ccode\u003e\u0026#39;Fare\u0026#39;\u003c/code\u003e for each value of \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e on the same plot.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_train.groupby(\u0026#39;Survived\u0026#39;).Fare.hist(alpha=0.6);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868560/output_51_0_hzj5qp.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e It looks as though those that paid more had a higher chance of surviving.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003eseaborn\u003c/code\u003e to plot a histogram of the \u003ccode\u003e\u0026#39;Age\u0026#39;\u003c/code\u003e column of \u003ccode\u003edf_train\u003c/code\u003e. You\u0026#39;ll need to drop null values before doing so.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_train_drop = df_train.dropna()\r\nsns.distplot(df_train_drop.Age, kde=False);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868560/output_54_0_rrholt.png\"/\u003e\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003ePlot a strip plot \u0026amp; a swarm plot of \u003ccode\u003e\u0026#39;Fare\u0026#39;\u003c/code\u003e with \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e on the x-axis.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.stripplot(x=\u0026#39;Survived\u0026#39;, y=\u0026#39;Fare\u0026#39;, data=df_train, alpha=0.3, jitter=True);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868561/output_56_0_ucrrht.png\"/\u003e\u003c/p\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.swarmplot(x=\u0026#39;Survived\u0026#39;, y=\u0026#39;Fare\u0026#39;, data=df_train);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868560/output_57_0_yoka36.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e Fare definitely seems to be correlated with survival aboard the Titanic.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse the DataFrame method \u003ccode\u003e.describe()\u003c/code\u003e to check out summary statistics of \u003ccode\u003e\u0026#39;Fare\u0026#39;\u003c/code\u003e as a function of survival.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003edf_train.groupby(\u0026#39;Survived\u0026#39;).Fare.describe()\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cdiv class=\"output_wrapper\"\u003e\r\n\u003cstyle\u003e\r\n    .dataframe thead tr:only-child th {\r\n        text-align: right;\r\n    }\r\n\r\n    .dataframe thead th {\r\n        text-align: left;\r\n    }\r\n\r\n    .dataframe tbody tr th {\r\n        vertical-align: top;\r\n    }\r\n\u003c/style\u003e\r\n\u003ctable border=\"1\" class=\"dataframe\"\u003e\r\n  \u003cthead\u003e\r\n    \u003ctr style=\"text-align: right;\"\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003ecount\u003c/th\u003e\r\n      \u003cth\u003emean\u003c/th\u003e\r\n      \u003cth\u003estd\u003c/th\u003e\r\n      \u003cth\u003emin\u003c/th\u003e\r\n      \u003cth\u003e25%\u003c/th\u003e\r\n      \u003cth\u003e50%\u003c/th\u003e\r\n      \u003cth\u003e75%\u003c/th\u003e\r\n      \u003cth\u003emax\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003eSurvived\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n      \u003cth\u003e\u003c/th\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/thead\u003e\r\n  \u003ctbody\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e0\u003c/th\u003e\r\n      \u003ctd\u003e549.0\u003c/td\u003e\r\n      \u003ctd\u003e22.117887\u003c/td\u003e\r\n      \u003ctd\u003e31.388207\u003c/td\u003e\r\n      \u003ctd\u003e0.0\u003c/td\u003e\r\n      \u003ctd\u003e7.8542\u003c/td\u003e\r\n      \u003ctd\u003e10.5\u003c/td\u003e\r\n      \u003ctd\u003e26.0\u003c/td\u003e\r\n      \u003ctd\u003e263.0000\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n    \u003ctr\u003e\r\n      \u003cth\u003e1\u003c/th\u003e\r\n      \u003ctd\u003e342.0\u003c/td\u003e\r\n      \u003ctd\u003e48.395408\u003c/td\u003e\r\n      \u003ctd\u003e66.596998\u003c/td\u003e\r\n      \u003ctd\u003e0.0\u003c/td\u003e\r\n      \u003ctd\u003e12.4750\u003c/td\u003e\r\n      \u003ctd\u003e26.0\u003c/td\u003e\r\n      \u003ctd\u003e57.0\u003c/td\u003e\r\n      \u003ctd\u003e512.3292\u003c/td\u003e\r\n    \u003c/tr\u003e\r\n  \u003c/tbody\u003e\r\n\u003c/table\u003e\r\n\u003c/div\u003e\r\n\r\n\r\n\r\n\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003eseaborn\u003c/code\u003e to plot a scatter plot of \u003ccode\u003e\u0026#39;Age\u0026#39;\u003c/code\u003e against \u003ccode\u003e\u0026#39;Fare\u0026#39;\u003c/code\u003e, colored by \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.lmplot(x=\u0026#39;Age\u0026#39;, y=\u0026#39;Fare\u0026#39;, hue=\u0026#39;Survived\u0026#39;, data=df_train, fit_reg=False, scatter_kws={\u0026#39;alpha\u0026#39;:0.5});\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868560/output_62_0_fcqefb.png\"/\u003e\u003c/p\u003e\r\n\u003cp\u003e\u003cstrong\u003eTake-away:\u003c/strong\u003e It looks like those who survived either paid quite a bit for their ticket or they were young.\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eUse \u003ccode\u003eseaborn\u003c/code\u003e to create a pairplot of \u003ccode\u003edf_train\u003c/code\u003e, colored by \u003ccode\u003e\u0026#39;Survived\u0026#39;\u003c/code\u003e. A pairplot is a great way to display most of the information that you have already discovered in a single grid of plots.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cpre\u003e\u003ccode class=\"lang-python\"\u003esns.pairplot(df_train_drop, hue=\u0026#39;Survived\u0026#39;);\r\n\u003c/code\u003e\u003c/pre\u003e\r\n\u003cp\u003e\u003cimg src=\"http://res.cloudinary.com/dyd911kmh/image/upload/f_auto,q_auto:best/v1513868561/output_65_0_knd6e9.png\"/\u003e\u003c/p\u003e\r\n\u003ch2 id=\"from-eda-to-machine-learning-model\"\u003eFrom EDA to Machine Learning Model\u003c/h2\u003e\r\n\u003cp\u003eIn this tutorial, you have successfully:\u003c/p\u003e\r\n\u003cul\u003e\r\n\u003cli\u003eloaded our data and had a look at it.\u003c/li\u003e\r\n\u003cli\u003eexplored our target variable visually and made your first predictions.\u003c/li\u003e\r\n\u003cli\u003eexplored some of our feature variables visually and made more predictions that did better based on our EDA.\u003c/li\u003e\r\n\u003cli\u003edone some serious EDA of feature variables, categorical and numeric.\u003c/li\u003e\r\n\u003c/ul\u003e\r\n\u003cp\u003eIn the next post, you\u0026#39;ll take the time to build some Machine Learning models, based on what you\u0026#39;ve learnt from your EDA here. We\u0026#39;ll do this in the next post on this project (to be launched on December 27).\u003c/p\u003e\r\n","contentUrl":"https://www.datacamp.com/community/tutorials/kaggle-machine-learning-eda","userContentUrl":null,"illustrationUrl":null,"seoTitle":"Kaggle Tutorial: EDA \u0026 Machine Learning","seoMetaDescription":"In this Kaggle tutorial, you'll learn how to approach and build supervised learning models with the help of exploratory data analysis (EDA) on the Titanic data.","seoKeyword":"Kaggle Tutorial EDA Machine Learning","mustRead":false,"programmingLanguage":null,"submissionDate":"2017-12-21T15:31:16.431Z","publishDate":"2017-12-21T15:36:34.455Z","episode":null,"isLatest":null,"externalUrl":null,"transcriptUrl":null,"guests":[],"links":null,"isSpam":false,"xp":0,"flaggingUsers":[],"isDisabled":false,"connectedInternalContentId":null,"createdAt":"2017-12-21T15:31:16.427Z","updatedAt":"2019-02-19T15:58:57.645Z","upvoting":{"voteCount":91,"voted":false},"tags":["python","data manipulation","machine learning","data analysis","eda","kaggle","facebook live","scikit-learn","pandas"],"author":{"id":469499,"slug":"hugobowneanderson","avatarUrlSquare":"https://assets.datacamp.com/users/avatars/000/469/499/square/hugo_bowne-anderson.png?1470132470","fullName":"Hugo Bowne-Anderson","nameFromEmail":"hugobowneanderson","isAdmin":false}}]},"isFetched":true,"isFetching":false,"statusMessage":""},"countdownBanner":{"banner":{"showBanner":false,"title":"","text":"","startDate":"","endDate":"","link":"","nonPromo":false},"isBannerOpen":false},"form":{},"list":{"isFetched":false,"isFetching":false,"statusMessage":""},"menu":{"isSidebarMenuOpen":false},"notifications":{"isFetched":false,"isFetching":false,"isReadFetched":false,"isReadFetching":false,"statusMessage":"","readStatusMessage":"","Notifications":[],"NotificationsTotal":0,"unReadCount":0},"preview":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{}},"recommendCS":{"isPosting":false,"isPosted":false,"statusMessage":"","isModalOpen":false,"currentStep":"form"},"spam":{"isFlagging":false,"isSucceeded":false,"statusMessage":"","isSpamModalOpen":false,"isUnSpamModalOpen":false},"tag":{"isRequesting":false,"isSucceeded":false,"statusMessage":"","isDeleteTagModalOpen":false},"tagList":{"isFetched":false,"isFetching":false,"statusMessage":"","list":[],"total":0},"tagSearch":{"isFetching":false,"isFetched":false,"statusMessage":"","content":{}},"user":{"isFetching":false,"isFetched":false,"statusMessage":"","unBan":{"isUnBanning":false,"isSucceeded":false,"statusMessage":"","isUnBanUserModalOpen":false},"ban":{"isBanning":false,"isSucceeded":false,"statusMessage":"","isBanUserModalOpen":false}},"submitArticle":{"isPosting":false,"isPosted":false,"statusMessage":"","timer":0,"articleSlug":"","isModalOpen":false,"currentStep":"form","slug":"","externalUrl":""},"rss":{"isCreating":false,"isSucceeded":false,"statusMessage":""},"rssFeedList":{"isFetched":false,"isFetching":false,"statusMessage":"","list":[],"disconnectModal":{"isFetched":true,"isFetching":false,"isOpen":false,"rssFeedIdToDisconnect":null,"statusMessage":""}},"setAsHomePage":{"isSetAsHomePageModalOpen":false},"analytics":{}},"initialProps":{"asPath":"/community/tutorials/exploratory-data-analysis-python"}},"pathname":"/community/tutorial","query":{"slug":"exploratory-data-analysis-python"},"buildId":"f80eab32-3c58-4b52-a08c-d754687b7a03","buildStats":{"app.js":{"hash":"b782294ddb8d954b4c94ee4c23476b23"}},"assetPrefix":"/community","nextExport":false,"err":null,"chunks":[]}
          module={}
          __NEXT_LOADED_PAGES__ = []
          __NEXT_LOADED_CHUNKS__ = []

          __NEXT_REGISTER_PAGE = function (route, fn) {
            __NEXT_LOADED_PAGES__.push({ route: route, fn: fn })
          }

          __NEXT_REGISTER_CHUNK = function (chunkName, fn) {
            __NEXT_LOADED_CHUNKS__.push({ chunkName: chunkName, fn: fn })
          }
        </script><script async="" id="__NEXT_PAGE__/community/tutorial" type="text/javascript" src="/community/_next/f80eab32-3c58-4b52-a08c-d754687b7a03/page/community/tutorial.js"></script><script async="" id="__NEXT_PAGE__/_error" type="text/javascript" src="/community/_next/f80eab32-3c58-4b52-a08c-d754687b7a03/page/_error.js"></script><script type="text/javascript" src="/community/_next/b782294ddb8d954b4c94ee4c23476b23/app.js" async=""></script></body></html>